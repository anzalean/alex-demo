import{E as oe,cS as nn,cT as _l,cU as cs,bv as Zr,i as Jt,cV as Jr,o as gs,g as ae,a as K,c as J,cW as vd,cX as Nd,cY as Cd,cZ as Td,c_ as Ad,c$ as Dd,d0 as zd,c0 as Wl,c4 as Vl,c2 as Bl,bD as Pl,d1 as Fd,m as A,cP as ii,A as ua,an as Gt,ak as Be,s as pt,am as zt,e as ut,h as ha,d2 as $d,a6 as Fe,d3 as Pt,aj as lt,r as B,j as Gl,n as Hl,aa as Dt,p as Ul,q as da,u as pa,b as X,x as fa,v as ma,y as ga,B as ai,d4 as jl,D as ql,d5 as Kl,C as Zl,I as Jl,K as Xl,d6 as Md,d7 as Rd,P as Ed,R as ba,d8 as Yl,H as Ql,ag as Lt,V as tc,bS as ya,W as ec,d9 as sc,X as nc,Z as wa,_ as ka,a0 as ic,da as we,a3 as ac,z as oi,a5 as oc,db as Ki,dc as Zi,dd as Ia,de as rc,ad as xa,ao as Ld,ap as lc,aq as Od,at as _d,df as Wd,L as cc,au as uc,dg as yn,aw as Vd,dh as Bd,ay as Sa,az as va,aA as Na,di as hc,aH as Ca,aG as Pd,dj as Gd,dk as dc,aF as pc,ah as ts,ae as fc,dl as Hd,dm as mc,aR as gc,dn as bc,aQ as yc,aT as wc,dp as Pe,aO as st,af as kc,aY as Ud,aZ as Ic,a_ as Ta,dq as jd,aI as qd,b1 as xc,aV as Qt,b2 as Sc,br as vc,b3 as Nc,dr as Aa,al as ri,ds as Cc,b6 as Kd,dt as Da,bc as za,du as Fa,dv as $a,dw as Tc,c5 as Ac,dx as Dc,c6 as zc,dy as Fc,bd as $c,be as Ma,bf as Zd,a9 as Mc,bg as Ra,dz as Jd,bi as Ea,bj as La,bk as Oa,S as Xd,bl as Rc,aJ as _a,f as li,b4 as Ec,bo as Lc,dA as Yd,dB as Oc,bp as Qd,dC as Wa,dD as tp,dE as _c,bt as Va,J as Ba,ar as Wc,bF as ep,bC as Vc,bB as Bc,cL as bs,dF as Pc,dG as sp,dH as z,ai as fs,a8 as np,T as re,cI as Pa,cJ as ip,cK as Gc,cM as Hc,c8 as Ps,cO as ap,dI as $s,dJ as op,t as T,dK as wn,dL as kn,dM as O,d as gt,ck as We,dN as Xr,cQ as Oe,Q as rp,G as lp,dO as cp,dP as up,dQ as Yr,cx as hp,cu as Qr,cr as dp,cv as pp,cp as fp,bL as Ga,cR as mp,dR as Ms,dS as Ha,dT as gp,dU as bp,dV as yp,dW as tl,dX as wp,dY as kp,dZ as Uc,as as Bt,d_ as Ip,bK as es,d$ as xp,e0 as ct,bX as Sp,k as vp,e1 as Ge,e2 as ys,e3 as rs,l as Np,b5 as In,e4 as ci,M as Cp,O as Tp,ax as Ap,e5 as Ua,bP as Gs,bh as Zt,bM as Dp,e6 as ja,Y as zp,bY as Fp,$ as $p,e7 as ui,aX as Mp,a1 as Rp,a2 as Ep,bU as Lp,bV as Op,a4 as _p,e8 as qa,e9 as Ka,ea as rn,eb as Za,cG as zs,ec as jc,cE as Wp,ab as Vp,ed as qc,bm as Bp,ee as Pp,ef as Gp,bZ as Hp,bQ as Up,bW as jp,bJ as qp,bn as Kp,aD as Zp,aL as Kc,aM as Zc,aN as Jc,aS as Jp,eg as Xc,a$ as Xp,b$ as Yp,c3 as Qp,c1 as tf,bE as ef,b7 as sf,b8 as nf,b9 as af,ba as of,b_ as rf,bH as lf,eh as Ja,aP as cf,c9 as uf,ca as hf,cb as df,cc as pf,bI as ff,bs as mf,cd as gf,ce as bf,cf as yf,by as wf,bz as kf,c7 as If,ei as Xa,bA as xf,ej as Sf}from"./index-D3B-3C1D.js";import{N as oA,eT as rA,ez as lA,ey as cA,a7 as uA,cF as hA,av as dA,aB as pA,aC as fA,eU as mA,eV as gA,eW as bA,b0 as yA,cH as wA,eX as kA,er as IA,bb as xA,cg as SA,eY as vA,eq as NA,em as CA,aW as TA,eS as AA,aK as DA,eD as zA,ep as FA,eC as $A,eE as MA,eB as RA,eA as EA,eL as LA,eM as OA,eJ as _A,eO as WA,cD as VA,eP as BA,et as PA,eu as GA,cN as HA,eF as UA,eI as jA,eK as qA,eo as KA,ek as ZA,eH as JA,eN as XA,es as YA,en as QA,eG as tD,eR as eD,eQ as sD,el as nD,ev as iD,ew as aD,ex as oD}from"./index-D3B-3C1D.js";import{o as Bn,j as ht,m as pe,n as Ut,k as Yc,w as De,p as ws,q as Hs,r as hi,u as _e,v as Qc,x as vf,y as Pn,z as Nf,A as tu,B as eu,C as su,D as Cf,E as Tf,d as ks,F as nu,G as hs,H as Us,I as iu,J as ke,K as ge,L as au,M as Is,b as Le,N as Ya,O as cn,P as ss,Q as Ji,R as un,S as ou,T as Qa,U as ru,V as to,W as lu,g as xn,X as eo,e as Ve,Y as Af,Z as Df,_ as cu,$ as Xi,a0 as hn,a1 as zf,a2 as Ff,a3 as $f,a4 as Mf,a5 as Rf,a6 as Ef,a7 as uu,a8 as Lf,a9 as Of,h as te,aa as hu,ab as du,ac as _f,ad as pu,ae as Wf,af as Vf,ag as Bf,ah as fu,ai as Pf,aj as Gf,ak as Hf,al as Uf,am as jf,an as qf,ao as Kf,ap as Zf,aq as Jf,ar as Xf,as as mu,at as gu,au as bu,av as Yf,aw as Qf,ax as yu,ay as Rs,az as Ot,aA as wu,aB as so,aC as tm,aD as em,aE as sm,aF as Gn,aG as le,aH as nm,aI as im,aJ as am,aK as om,aL as rm,aM as lm,aN as cm,aO as ku,aP as Iu,aQ as um,aR as no,aS as di,aT as hm,s as pi,aU as dm,aV as pm,aW as fi,aX as fm,aY as mm,aZ as Hn,a_ as io,a$ as xu,b0 as ao,c as dn,b1 as gm,b2 as el,b3 as bm,b4 as ym,b5 as wm,b6 as km,b7 as Im,b8 as mi,b9 as Su,ba as xm,bb as Sm,bc as vm,bd as Nm,be as Cm,bf as Tm,i as Ce,bg as Am,bh as Dm,bi as oo,bj as zm,bk as Fm,bl as $m,bm as Mm,bn as Rm,bo as Em,bp as sl,a as nl,f as Lm}from"./graph_model-D4efRZ2G.js";import{ck as lD,bs as cD,bz as uD,bA as hD,bB as dD,bC as pD,cb as fD,bD as mD,bq as gD,ci as bD,cm as yD,bE as wD,bF as kD,ch as ID,bG as xD,bv as SD,cg as vD,bH as ND,cj as CD,br as TD,bI as AD,l as DD,cl as zD,bt as FD,bJ as $D,bK as MD,bL as RD,cc as ED,bM as LD,bN as OD,bO as _D,bP as WD,bQ as VD,bR as BD,bS as PD,bT as GD,bU as HD,bV as UD,bW as jD,bX as qD,bY as KD,bZ as ZD,b_ as JD,cn as XD,b$ as YD,c0 as QD,c1 as tz,c2 as ez,cd as sz,ce as nz,c3 as iz,bw as az,bx as oz,cf as rz,bu as lz,by as cz,c4 as uz,c5 as hz,c6 as dz,c7 as pz,c8 as fz,c9 as mz,ca as gz}from"./graph_model-D4efRZ2G.js";import{S as vu,a as Nu,p as Om,n as _m,m as gi,b as Q,u as wt,c as xs,i as Ss,s as Wm,d as pn,t as ee,e as js,g as Cu,f as Tu,h as Au,j as Vm,k as Bm,l as Es,o as Du,q as Pm,r as Vi,v as fn,w as Ne,x as Gm,y as Hm,z as ro,A as Um,B as jm,C as qm,D as Km,E as Zm,F as Jm,G as lo,H as Xm,I as Ym,J as Qm,K as tg,L as eg,M as sg,N as zu,O as ng,P as ig,Q as ag,R as og,T as Fu,U as rg,V as lg,W as cg,X as ug,Y as hg,Z as dg,_ as pg,$ as fg,a0 as mg,a1 as gg,a2 as bg,a3 as yg,a4 as wg,a5 as kg,a6 as Ig,a7 as Ds,a8 as xg,a9 as Sg,aa as $u,ab as vg,ac as Ng,ad as Cg,ae as Tg,af as Ag,ag as Dg,ah as zg,ai as Fg,aj as $g,ak as Mg,al as Rg,am as Eg,an as Lg,ao as Og,ap as _g,aq as Wg,ar as Vg,as as Bg,at as Pg,au as Gg,av as Hg,aw as Ug,ax as jg,ay as qg,az as Kg,aA as Zg,aB as Jg,aC as Xg,aD as Yg,aE as Qg,aF as tb,aG as eb,aH as sb,aI as nb,aJ as ib,aK as ab,aL as ob,aM as rb,aN as lb,aO as cb,aP as ub,aQ as hb,aR as db,aS as pb}from"./index-BHco0Jqf.js";import{b1 as yz,a$ as wz,aT as kz,a_ as Iz,aV as xz,aY as Sz,b0 as vz,aW as Nz,aU as Cz,aX as Tz,aZ as Az}from"./index-BHco0Jqf.js";import{s as co}from"./index-DToP8jdU.js";import"./long-CgdJXaQy.js";import"./_commonjsHelpers-CE1G-McA.js";const fb=.001,Mu=.1;function mb(s,t,e){return e==null&&(e=uo()),Yi(s,t,(n,i)=>ho(n,i,e))}function uo(){return oe.backend.floatPrecision()===32?fb:Mu}function Yi(s,t,e){let n=!0;if((cs(s)||cs(t))&&(n=!1),cs(s)&&cs(t)&&(n=!0),n){const o=s.constructor.name,r=t.constructor.name;if(o!==r)throw new Error(`Arrays are of different type. Actual: ${o}. Expected: ${r}`)}if(Array.isArray(s)&&Array.isArray(t)){const o=Zr(s),r=Zr(t);if(!Jt(o,r))throw new Error(`Arrays have different shapes. Actual: [${o}]. Expected: [${r}]`)}const i=cs(s)?s:Jr(s),a=cs(t)?t:Jr(t);if(i.length!==a.length)throw new Error(`Arrays have different lengths actual: ${i.length} vs expected: ${a.length}.
Actual:   ${i}.
Expected: ${a}.`);for(let o=0;o<a.length;++o){const r=i[o],l=a[o];if(!e(r,l))throw new Error(`Arrays differ: actual[${o}] = ${r}, expected[${o}] = ${l}.
Actual:   ${i}.
Expected: ${a}.`)}typeof expect<"u"&&expect().nothing()}function gb(s,t){s().then(()=>t.fail(),()=>t()),typeof expect<"u"&&expect().nothing()}function bb(s,t){const e=typeof t=="string"||typeof t=="number"||typeof t=="boolean"?[t]:t;return nn(s)||nn(s[0])||nn(t)||nn(t[0])?Yi(s,e,(n,i)=>n==i):Yi(s,t,(n,i)=>ho(n,i,0))}function yb(s,t,e){if(e==null&&(e=uo()),!ho(s,t,e))throw new Error(`Numbers differ: actual === ${s}, expected === ${t}`);typeof expect<"u"&&expect().nothing()}function ho(s,t,e){return!isFinite(s)&&!isFinite(t)?!0:!(isNaN(s)||isNaN(t)||Math.abs(s-t)>e)}function wb(s,t,e){for(let n=0;n<s.length;n++)if(s[n]<t||s[n]>e)throw new Error(`Value out of range:${s[n]} low: ${t}, high: ${e}`)}function kb(s,t){const e=new Float32Array(s),n=new Float32Array(t);if(e.length!==n.length)throw new Error(`Expected ArrayBuffer to be of length ${n.length}, but it was ${e.length}`);for(let i=0;i<n.length;i++)if(e[i]!==n[i])throw new Error(`Expected ArrayBuffer value at ${i} to be ${n[i]} but got ${e[i]} instead`)}function Ru(s){for(let t=0;t<s.length;t++){const e=s[t];Array.isArray(e)?Ru(e):s[t]=_l(e)}return s}function Ib(s){const t=document.createElement("video");return"playsInline"in t&&(t.playsInline=!0),t.muted=!0,t.loop=!0,t.style.position="fixed",t.style.left="0px",t.style.top="0px",t.preload="auto",t.appendChild(s),new Promise(e=>{t.addEventListener("loadeddata",n=>e(t)),t.load()})}async function xb(s){await s.play(),"requestVideoFrameCallback"in s&&await new Promise(t=>{s.requestVideoFrameCallback(t)})}const _T=Object.freeze(Object.defineProperty({__proto__:null,TEST_EPSILON_FLOAT16:Mu,createVideoElement:Ib,encodeStrings:Ru,expectArrayBuffersEqual:kb,expectArraysClose:mb,expectArraysEqual:bb,expectNumbersClose:yb,expectPromiseToFail:gb,expectValuesInRange:wb,play:xb,testEpsilon:uo},Symbol.toStringTag,{value:"Module"}));function Sb(s,t,e){const n=ae(s,"labels","confusionMatrix"),i=ae(t,"predictions","confusionMatrix");K(e==null||e>0&&Number.isInteger(e),()=>`If provided, numClasses must be a positive integer, but got ${e}`),K(n.rank===1,()=>`Expected the rank of labels to be 1, but got ${n.rank}`),K(i.rank===1,()=>`Expected the rank of predictions to be 1, but got ${i.rank}`),K(n.shape[0]===i.shape[0],()=>`Mismatch in the number of examples: ${n.shape[0]} vs. ${i.shape[0]}. Labels and predictions should have the same number of elements.`),K(e>0&&Number.isInteger(e),()=>`numClasses is required to be a positive integer, but got ${e}`);const a=Bn(J(n,"int32"),e),o=Bn(J(i,"int32"),e),r=ht(a),l=pe(r,o);return J(l,"int32")}const vb=gs({confusionMatrix_:Sb});const WT=Object.freeze(Object.defineProperty({__proto__:null,confusionMatrix:vb},Symbol.toStringTag,{value:"Module"}));const Nb="4.22.0";class Cb{static sgd(t){return new vd(t)}static momentum(t,e,n=!1){return new Nd(t,e,n)}static rmsprop(t,e=.9,n=0,i=null,a=!1){return new Cd(t,e,n,i,a)}static adam(t=.001,e=.9,n=.999,i=null){return new Td(t,e,n,i)}static adadelta(t=.001,e=.95,n=null){return new Ad(t,e,n)}static adamax(t=.002,e=.9,n=.999,i=null,a=0){return new Dd(t,e,n,i,a)}static adagrad(t,e=.1){return new zd(t,e)}}const Ts=Cb;const VT=Object.freeze(Object.defineProperty({__proto__:null,nonMaxSuppressionV3Impl:Wl,nonMaxSuppressionV4Impl:Vl,nonMaxSuppressionV5Impl:Bl,whereImpl:Pl},Symbol.toStringTag,{value:"Module"}));const Eu={kernelName:Fd,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>A(s,ii(J(e,"float32"),-1))}}};const Tb={kernelName:ua,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>{const n=Gt(J(e,"float32")),i=Be(pt(zt(1),n));return Ut(ut(s,i))}}}};const Ab={kernelName:ha,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>{const n=Be(pt(Gt(J(e,"float32")),1));return ut(s,n)}}}};const Db={kernelName:$d,inputsToSave:["a","b"],gradFunc:(s,t)=>{const[e,n]=t,i=Fe(e.shape,n.shape);return{a:()=>{let r=s;const l=Pt(e.shape,i);return l.length>0&&(r=lt(r,l)),B(r,e.shape)},b:()=>{let r=s;const l=Pt(n.shape,i);return l.length>0&&(r=lt(r,l)),B(r,n.shape)}}}};const zb={kernelName:Gl,saveAllInputs:!0,gradFunc:(s,t)=>{const e={};return t.forEach((n,i)=>{e[i]=()=>s.clone()}),e}};const Fb={kernelName:Hl,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>Dt(e)}}};const $b={kernelName:Ul,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>Dt(e)}}};const Mb={kernelName:da,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>ut(s,Be(pt(zt(1),Gt(J(e,"float32")))))}}};const Rb={kernelName:pa,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>{const n=Be(X(zt(1),Gt(J(e,"float32"))));return ut(s,n)}}}};const Eb={kernelName:fa,inputsToSave:["a","b"],gradFunc:(s,t)=>{const[e,n]=t,i=Fe(e.shape,n.shape);return{a:()=>{const r=X(Gt(e),Gt(n));let l=A(s,ut(n,r));const c=Pt(e.shape,i);return c.length>0&&(l=lt(l,c)),B(l,e.shape)},b:()=>{const r=X(Gt(e),Gt(n));let l=Ut(A(s,ut(e,r)));const c=Pt(n.shape,i);return c.length>0&&(l=lt(l,c)),B(l,n.shape)}}}};const Lb={kernelName:ma,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>ut(s,X(Gt(J(e,"float32")),1))}}};const Ob={kernelName:ga,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>ut(s,pt(zt(1),Gt(J(e,"float32"))))}}};function _b(s,t,e,n,i,a){const o=ae(s,"dy","avgPool3dGrad"),r=ae(t,"input","avgPool3dGrad");let l=o,c=r,u=!1;r.rank===4&&(u=!0,l=B(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]]),c=B(r,[1,r.shape[0],r.shape[1],r.shape[2],r.shape[3]])),K(l.rank===5,()=>`Error in avgPool3dGrad: dy must be rank 5 but got rank ${l.rank}.`),K(c.rank===5,()=>`Error in avgPool3dGrad: input must be rank 5 but got rank ${c.rank}.`),ai("avgPool3dGrad",i,a);const d={dy:l,input:c},h={filterSize:e,strides:n,pad:i,dimRoundingMode:a},p=oe.runKernel(jl,d,h);return u?B(p,[p.shape[1],p.shape[2],p.shape[3],p.shape[4]]):p}const Wb=gs({avgPool3dGrad_:_b});const Vb={kernelName:ql,inputsToSave:["x"],gradFunc:(s,t,e)=>{const[n]=t,{filterSize:i,strides:a,pad:o,dimRoundingMode:r}=e;return{x:()=>Wb(s,n,i,a,o,r)}}};function Bb(s,t,e,n,i){const a=ae(s,"dy","avgPoolGrad"),o=ae(t,"input","avgPoolGrad");K(o.rank===a.rank,()=>`Rank of input (${o.rank}) does not match rank of dy (${a.rank})`);let r=o,l=a,c=!1;o.rank===3&&(c=!0,r=B(o,[1,o.shape[0],o.shape[1],o.shape[2]]),l=B(a,[1,a.shape[0],a.shape[1],a.shape[2]])),K(l.rank===4,()=>`Error in avgPoolGrad: dy must be rank 4 but got rank ${l.rank}.`),K(r.rank===4,()=>`Error in avgPoolGrad: input must be rank 4 but got rank ${r.rank}.`);const u={dy:l,input:r},d={filterSize:e,strides:n,pad:i},h=oe.runKernel(Kl,u,d);return c?B(h,[h.shape[1],h.shape[2],h.shape[3]]):h}const Pb=gs({avgPoolGrad_:Bb});const Gb={kernelName:Zl,inputsToSave:["x"],gradFunc:(s,t,e)=>{const[n]=t,{filterSize:i,strides:a,pad:o}=e;return{x:()=>Pb(s,n,i,a,o)}}};const Hb={kernelName:Jl,inputsToSave:["a","b"],gradFunc:(s,t,e)=>{const[n,i]=t,{transposeA:a,transposeB:o}=e;return!a&&!o?{a:()=>pe(s,i,!1,!0),b:()=>pe(n,s,!0,!1)}:!a&&o?{a:()=>pe(s,i,!1,!1),b:()=>pe(s,n,!0,!1)}:a&&!o?{a:()=>pe(i,s,!1,!0),b:()=>pe(n,s,!1,!1)}:{a:()=>pe(i,s,!0,!0),b:()=>pe(s,n,!0,!0)}}};const Ub={kernelName:Xl,gradFunc:(s,t,e)=>{const{blockShape:n,crops:i}=e;return{x:()=>Yc(s,n,i)}}};const jb={kernelName:Md,gradFunc:(s,t,e)=>{const n=e,i=n.inputShape,a=n.shape,o=Array.from(a);for(let l=i.length-1;l>=0;l--)if(i[l]===a[l])o[l]=1;else if(i[l]!==1)throw new Error(`broadcastTo(): [${i}] cannot be broadcast to [${a}].`);const r=[];for(let l=0;l<o.length;l++)o[l]>1&&r.push(l);return{x:()=>lt(s,r,!0)}}};const qb={kernelName:Rd,gradFunc:s=>({x:()=>s.clone()})};const Kb={kernelName:Ed,gradFunc:s=>({x:()=>Dt(s)})};const Zb={kernelName:ba,inputsToSave:["x"],gradFunc:(s,t,e)=>{const[n]=t,{clipValueMin:i,clipValueMax:a}=e;return{x:()=>De(ws(Hs(n,i),hi(n,a)),s,Dt(s))}}};const Jb={kernelName:Yl,inputsToSave:["x"],gradFunc:Eu.gradFunc};const Xb={kernelName:Ql,saveAllInputs:!0,gradFunc:(s,t,e)=>{const n=t.map(l=>l.shape),{axis:i}=e,a=Lt(i,t[0].shape)[0],o=n.map(l=>l[a]);return _e(s,o,a).map(l=>()=>l)}};const Yb={kernelName:tc,inputsToSave:["x","filter"],gradFunc:(s,t,e)=>{const[n,i]=t,{dilations:a,strides:o,pad:r,dataFormat:l}=e;return K(ya(a),()=>`Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${a}'`),{x:()=>vf(n.shape,s,i,o,r,l),filter:()=>Qc(n,s,i.shape,o,r,l)}}};const Qb={kernelName:ec,inputsToSave:["dy","filter"],gradFunc:(s,t,e)=>{const[n,i]=t,{strides:a,pad:o,dataFormat:r,dimRoundingMode:l}=e;return{dy:()=>Pn(s,i,a,o,r,1,l),filter:()=>Qc(s,n,i.shape,a,o,r,l)}}};function ty(s,t,e,n,i){let a=s;s.rank===4&&(a=B(s,[1,s.shape[0],s.shape[1],s.shape[2],s.shape[3]]));let o=t;o.rank===4&&(o=B(t,[1,t.shape[0],t.shape[1],t.shape[2],t.shape[3]])),K(a.rank===5,()=>`Error in conv3dDerFilter: input must be rank 5, but got shape ${a.shape}.`),K(o.rank===5,()=>`Error in conv3dDerFilter: dy must be rank 5, but got shape ${o.shape}.`),K(e.length===5,()=>`Error in conv3dDerFilter: filterShape must be length 5, but got ${e}.`),K(a.shape[4]===e[3],()=>`Error in conv3dDerFilter: depth of input ${a.shape[4]}) must match input depth in filter (${e[3]}.`),K(o.shape[4]===e[4],()=>`Error in conv3dDerFilter: depth of dy (${o.shape[4]}) must match output depth for filter (${e[4]}).`);const r={x:a,dy:o},l={strides:n,pad:i,filterShape:e};return oe.runKernel(sc,r,l)}const ey=gs({conv3DBackpropFilter_:ty});const sy={kernelName:nc,inputsToSave:["x","filter"],gradFunc:(s,t,e)=>{const{dilations:n,strides:i,pad:a}=e;K(ya(n),()=>`Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${n}'`);const[o,r]=t;return{x:()=>Nf(o.shape,s,r,i,a),filter:()=>ey(o,s,r.shape,i,a)}}};const ny={kernelName:wa,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>A(Ut(tu(J(e,"float32"))),s)}}};const iy={kernelName:ka,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>A(eu(J(e,"float32")),s)}}};const ay={kernelName:ic,inputsToSave:["x"],gradFunc:(s,t,e)=>{const[n]=t,{axis:i,exclusive:a,reverse:o}=e;return{x:()=>{const r=we([i],n.rank);let l=su(s,i,a,!o);return r!=null&&(l=ht(l,r)),l}}}};const oy={kernelName:ac,inputsToSave:["x","filter"],gradFunc:(s,t,e)=>{const{dilations:n,strides:i,pad:a,dimRoundingMode:o}=e,r=n??[1,1];K(ya(r),()=>`Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '${r}'`);const[l,c]=t;return K(l.rank===4,()=>`Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank ${l.rank}.`),K(c.rank===4,()=>`Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank ${c.rank}.`),K(l.shape[3]===c.shape[2],()=>`Error in gradient of depthwiseConv2d: number of input channels (${l.shape[3]}) must match the inChannels dimension in filter ${c.shape[2]}.`),K(oi(i,r),()=>`Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides ${i} and dilations '${r}'.`),ai("depthwiseConv2d",a,o),{x:()=>Tf(l.shape,s,c,i,a,r,o),filter:()=>Cf(l,s,c.shape,i,a,r,o)}}};const ry={kernelName:oc,inputsToSave:["x","filter"],gradFunc:(s,t,e)=>{const[n,i]=t,a={x:n,filter:i,dy:s},o={x:n,filter:i,dy:s};return{x:()=>oe.runKernel(Zi,a,e),filter:()=>oe.runKernel(Ki,o,e)}}};const ly={kernelName:Ia,outputsToSave:[!0],gradFunc:(s,t)=>{const[e]=t,n={dy:s,y:e};return{x:()=>oe.runKernel(rc,n)}}};const cy={kernelName:xa,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t,n=A(ks(Ut(Gt(e))),2/Math.sqrt(Math.PI));return{x:()=>A(s,n)}}};const uy={kernelName:Ld,outputsToSave:[!0],gradFunc:(s,t)=>{const[e]=t;return{x:()=>A(s,e)}}};const hy={kernelName:lc,inputsToSave:["input"],gradFunc:(s,t)=>{const[e]=t;return{input:()=>B(s,e.shape)}}};const dy={kernelName:Od,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>A(s,ks(e))}}};const py={kernelName:_d,gradFunc:s=>({x:()=>Dt(s)})};const fy={kernelName:Wd,inputsToSave:["a","b"],gradFunc:(s,t)=>{const[e,n]=t,i=Fe(e.shape,n.shape);return{a:()=>{const r=ut(s,J(n,"float32")),l=Pt(e.shape,i);return l.length>0?B(lt(r,l),e.shape):r},b:()=>{let r=A(s,J(e,"float32"));const l=Pt(n.shape,i);l.length>0&&(r=B(lt(r,l),n.shape));const c=Gt(n);return Ut(ut(r,J(c,"float32")))}}}};const my={kernelName:cc,inputsToSave:["x","mean","variance","scale"],gradFunc:(s,t,e)=>{const{varianceEpsilon:n}=e,[i,a,o,r]=t,l=r??zt(1),c=Pt(a.shape,i.shape),u=[];if(a.rank===1){for(let y=0;y<i.shape.length-1;++y)u.push(i.shape[y]);u.push(1)}const d=pt(i,a),h=A(s,l),p=nu(X(o,zt(n))),m=A(A(A(p,p),p),zt(-.5));return{x:()=>a.rank===1?B(A(A(s,hs(B(p,[1,1,1,a.shape[0]]),u)),l),i.shape):B(A(A(s,p),l),i.shape),mean:()=>{let y=A(A(p,zt(-1)),h);return a.rank===1&&(y=lt(y,c)),B(y,a.shape)},variance:()=>{let y=A(A(m,d),h);return a.rank===1&&(y=lt(y,c)),B(y,a.shape)},scale:()=>{const y=A(d,p);let I=A(s,y);return a.rank===1&&(I=lt(I,c)),B(I,a.shape)},offset:()=>{let y=s;return a.rank===1&&(y=lt(y,c)),B(y,a.shape)}}}};const gy={kernelName:uc,inputsToSave:["x","indices"],gradFunc:(s,t,e)=>{const[n,i]=t,{axis:a,batchDims:o}=e,r=Lt(a,n.shape)[0],l=(c,u,d)=>()=>{const h=c.shape,p=u.size,m=h.slice(0,r),f=m.length,g=h.slice(a,h.length).slice(1),w=g.length,b=il(0,f),k=il(f+1,f+1+w),y=al([m,[p],g]),I=B(d,y),S=B(u,[p]),v=al([[f],b,k]),N=ht(I,v);let C=iu(N,S,c.shape[r]);const D=yn(v);return C=ht(C,D),C};if(o===1){const c=n.shape[0],u=n.split(c,0);return{x:()=>Us(u.map((p,m)=>l(p,i.slice(m,1),s.slice(m,1))())).reshape(n.shape),indices:()=>i}}else return{x:l(n,i,s),indices:()=>i}}};function il(s,t){const e=[];for(let n=s;n<t;++n)e.push(n);return e}function al(s){const t=[];for(let e=0;e<s.length;++e)for(let n=0;n<s[e].length;++n)t.push(s[e][n]);return t}const by={kernelName:Vd,inputsToSave:["a","b"],gradFunc:(s,t)=>{const[e,n]=t;return{a:()=>Dt(e),b:()=>Dt(n)}}};const yy={kernelName:Bd,gradFunc:s=>({x:()=>J(s,"float32")})};const wy={kernelName:Sa,gradFunc:s=>({x:()=>Dt(s)})};const ky={kernelName:va,gradFunc:s=>({x:()=>Dt(s)})};const Iy={kernelName:Na,gradFunc:s=>({x:()=>Dt(s)})};const xy={kernelName:hc,inputsToSave:["x"],gradFunc:(s,t,e)=>{const[n]=t,{alpha:i}=e,a=ke(n,0);return{x:()=>De(a,s,A(s,i))}}};const Sy={kernelName:Ca,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>ut(s,X(e,1))}}};const vy={kernelName:Pd,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>ut(s,J(e,"float32"))}}};const Ny={kernelName:Gd,inputsToSave:[],outputsToSave:[!0],gradFunc:(s,t,e)=>{const[n]=t,{axis:i}=e;return{logits:()=>{const o=ks(n);return pt(s,A(lt(s,i,!0),o))}}}};function Cy(s,t,e,n=5,i=1,a=1,o=.5){const r={x:s,y:t,dy:e},l={depthRadius:n,bias:i,alpha:a,beta:o};return oe.runKernel(dc,r,l)}const Ty=gs({localResponseNormalizationBackprop_:Cy});const Ay={kernelName:pc,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(s,t,e)=>{const[n,i]=t,{depthRadius:a,bias:o,alpha:r,beta:l}=e;return{x:()=>Ty(n,i,s,a,o,r,l)}}};function Lu(s,t,e,n){return t.rank<e.rank&&(t=B(t,ts(t.shape,n))),s.rank<e.rank&&(s=B(s,ts(s.shape,n))),{x:()=>A(s,J(ge(e,t),s.dtype))}}const ol={kernelName:fc,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(s,t,e)=>{const n=e,{reductionIndices:i}=n,a=t[0],o=t[1],r=Lt(i,a.shape),l=Lu(s,o,a,r);return{x:()=>l.x()}}};const Dy={kernelName:Hd,inputsToSave:["a","b"],gradFunc:(s,t)=>{const[e,n]=t;return{a:()=>A(s,J(Hs(e,n),"float32")),b:()=>A(s,J(au(e,n),"float32"))}}};function zy(s,t,e,n,i,a,o){const r=ae(s,"dy","maxPool3dGrad"),l=ae(t,"input","maxPool3dGrad"),c=ae(e,"output","maxPool3dGrad");let u=r,d=l,h=c,p=!1;l.rank===4&&(p=!0,u=B(r,[1,r.shape[0],r.shape[1],r.shape[2],r.shape[3]]),d=B(l,[1,l.shape[0],l.shape[1],l.shape[2],l.shape[3]]),h=B(c,[1,c.shape[0],c.shape[1],c.shape[2],c.shape[3]])),K(u.rank===5,()=>`Error in maxPool3dGrad: dy must be rank 5 but got rank ${u.rank}.`),K(d.rank===5,()=>`Error in maxPool3dGrad: input must be rank 5 but got rank ${d.rank}.`),K(h.rank===5,()=>`Error in maxPool3dGrad: output must be rank 5 but got rank ${h.rank}.`),ai("maxPool3dGrad",a,o);const m={dy:u,input:d,output:h},f={filterSize:n,strides:i,pad:a,dimRoundingMode:o},g=oe.runKernel(mc,m,f);return p?B(g,[g.shape[1],g.shape[2],g.shape[3],g.shape[4]]):g}const Fy=gs({maxPool3dGrad_:zy});const $y={kernelName:gc,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(s,t,e)=>{const[n,i]=t,{filterSize:a,strides:o,pad:r,dimRoundingMode:l}=e;return{x:()=>Fy(s,n,i,a,o,r,l)}}};function My(s,t,e,n,i,a,o){const r=ae(s,"dy","maxPoolGrad"),l=ae(t,"input","maxPoolGrad"),c=ae(e,"output","maxPoolGrad");K(l.rank===r.rank,()=>`Rank of input (${l.rank}) does not match rank of dy (${r.rank})`),K(r.rank===4,()=>`Error in maxPoolGrad: dy must be rank 4 but got rank ${r.rank}.`),K(l.rank===4,()=>`Error in maxPoolGrad: input must be rank 4 but got rank ${l.rank}.`),ai("maxPoolGrad",a,o);const u={dy:r,input:l,output:c},d={filterSize:n,strides:i,pad:a,dimRoundingMode:o};return oe.runKernel(bc,u,d)}const Ry=gs({maxPoolGrad_:My});const Ey={kernelName:yc,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(s,t,e)=>{const[n,i]=t,{filterSize:a,strides:o,pad:r}=e;return{x:()=>Ry(s,n,i,a,o,r)}}};const Ly={kernelName:wc,inputsToSave:["x"],gradFunc:(s,t,e)=>{const[n]=t,{axis:i}=e,a=Lt(i,n.shape),r=Pe(n.shape,a)[1],l=st(r);return{x:()=>{const u=n.shape.slice();a.forEach(p=>{u[p]=1});const d=B(s,u);return ut(A(d,Is(n.shape,"float32")),l)}}}};const Oy={kernelName:kc,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(s,t,e)=>{const n=e,{axis:i}=n,[a,o]=t,r=Lt(i,a.shape),l=Lu(s,o,a,r);return{x:()=>l.x()}}};const _y={kernelName:Ud,inputsToSave:["a","b"],gradFunc:(s,t)=>{const[e,n]=t;return{a:()=>A(s,J(hi(e,n),"float32")),b:()=>A(s,J(ke(e,n),"float32"))}}};const Wy={kernelName:Ic,inputsToSave:["x"],gradFunc:(s,t,e)=>{const n=t[0],{paddings:i}=e,a=i.map(o=>o[0]);return{x:()=>Le(s,a,n.shape)}}};const Vy={kernelName:Ta,inputsToSave:["a","b"],gradFunc:(s,t)=>{const[e,n]=t,i=Fe(e.shape,n.shape);return{a:()=>{const r=Pt(e.shape,i);return r.length>0?B(lt(s,r),e.shape):s},b:()=>{const r=A(s,Ut(Ya(ut(e,n)))),l=Pt(n.shape,i);return l.length>0?B(lt(r,l),n.shape):r}}}};const By={kernelName:jd,inputsToSave:["a","b"],gradFunc:(s,t)=>{const[e,n]=t,i=Fe(e.shape,n.shape);return{a:()=>{const r=A(s,J(n,"float32")),l=Pt(e.shape,i);return l.length>0?B(lt(r,l),e.shape):r},b:()=>{const r=A(s,J(e,"float32")),l=Pt(n.shape,i);return l.length>0?B(lt(r,l),n.shape):r}}}};const Py={kernelName:qd,gradFunc:s=>({x:()=>Ut(s)})};const Gy={kernelName:xc,inputsToSave:["indices"],gradFunc:(s,t)=>{const e=t[0];return{indices:()=>Qt(e.shape,"float32")}}};const Hy={kernelName:Sc,gradFunc:s=>({x:()=>Dt(s)})};const Uy={kernelName:vc,saveAllInputs:!0,gradFunc:(s,t,e)=>{const{axis:n}=e;return cn(s,n).map(a=>()=>a)}};const rl={kernelName:Nc,inputsToSave:["x"],gradFunc:(s,t,e)=>{const n=t[0],{paddings:i}=e,a=i.map(o=>o[0]);return{x:()=>Le(s,a,n.shape)}}};const jy={kernelName:Aa,inputsToSave:["a","b"],outputsToSave:[!0],gradFunc:(s,t)=>{const[e,n,i]=t,a=e,o=n,r=Fe(a.shape,o.shape);return{a:()=>{const u=J(o,"float32");let d=A(s,A(u,ri(a,pt(u,zt(1)))));const h=Pt(a.shape,r);return h.length>0&&(d=lt(d,h)),B(d,a.shape)},b:()=>{const u=ke(a,0),d=De(u,ss(a),Dt(a));let h=A(s,A(i,d));const p=Pt(o.shape,r);return p.length>0&&(h=lt(h,p)),B(h,o.shape)}}}};const qy={kernelName:Cc,inputsToSave:["x","alpha"],gradFunc:(s,t)=>{const[e,n]=t,i=ke(e,0);return{x:()=>De(i,s,A(s,n)),alpha:()=>{let a=De(i,Dt(s),A(s,e));const o=Pt(n.shape,s.shape);return o.length>0&&(a=lt(a,o)),B(a,n.shape)}}}};function Ky(s,t,e){const n=s.shape.slice();n[e]=1;const i=B(t,n),a=Ji(s,e,!0,!1),o=Ji(s,e,!0,!0),r=A(a,o);return A(i,r)}function Zy(s,t,e){const n=s.shape.length,i=n-e.length,a=we(e,n);let o=s;a!=null&&(o=ht(s,a));const r=o.shape.slice(),c=r.splice(n-e.length,e.length).reduce((h,p)=>h*p,1);r.push(c);const u=o.reshape(r);let d=Ky(u,t,i);if(d=d.reshape(o.shape),a!=null){const h=yn(a);d=ht(d,h)}return d}const Jy={kernelName:Kd,inputsToSave:["x"],gradFunc:(s,t,e)=>{const[n]=t,{axis:i}=e;let a=[];return i==null?a=n.shape.map((o,r)=>r):typeof i=="number"?a=[i]:a=i,{x:()=>Zy(n,s,a)}}};const Xy={kernelName:Da,inputsToSave:["a","b"],gradFunc:(s,t)=>{const[e,n]=t,i=Fe(e.shape,n.shape);return{a:()=>{const r=ut(s,J(n,"float32")),l=Pt(e.shape,i);return l.length>0?B(lt(r,l),e.shape):r},b:()=>{let r=A(s,J(e,"float32"));const l=Pt(n.shape,i);l.length>0&&(r=B(lt(r,l),n.shape));const c=Gt(n);return Ut(ut(r,J(c,"float32")))}}}};const Yy={kernelName:za,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>ut(s,Ut(Gt(e)))}}};const Qy={kernelName:Fa,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t,n=A(hi(e,6),ii(e));return{x:()=>A(s,J(n,"float32"))}}};const tw={kernelName:$a,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>A(s,J(ii(e),"float32"))}}};const ew={kernelName:Tc,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>B(s,e.shape)}}};const sw={kernelName:Ac,inputsToSave:["images"],gradFunc:(s,t,e)=>{const[n]=t,i={dy:s,images:n};return{images:()=>oe.runKernel(Dc,i,e)}}};const nw={kernelName:zc,inputsToSave:["images"],gradFunc:(s,t,e)=>{const[n]=t,i={dy:s,images:n};return{images:()=>oe.runKernel(Fc,i,e)}}};const iw={kernelName:$c,gradFunc:(s,t,e)=>{const{dims:n}=e,i=Lt(n,s.shape);return{x:()=>un(s,i)}}};const aw={kernelName:Ma,gradFunc:s=>({x:()=>Dt(s)})};const ow={kernelName:Zd,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>Ut(ut(s,A(ri(e,1.5),2)))}}};const rw={kernelName:Mc,inputsToSave:["condition"],gradFunc:(s,t)=>{const[e]=t;return{condition:()=>J(Dt(e),"float32"),t:()=>A(s,J(e,s.dtype)),e:()=>A(s,J(ou(e),s.dtype))}}};const lw={kernelName:Ra,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>{const n=ke(e,zt(0)),i=zt(vu),a=zt(Nu),o=A(s,a),r=A(A(s,i),ks(J(e,"float32")));return De(n,o,r)}}}};const cw={kernelName:Jd,outputsToSave:[!0],gradFunc:(s,t)=>{const[e]=t;return{x:()=>A(s,A(e,pt(zt(1),e)))}}};const uw={kernelName:Ea,gradFunc:s=>({x:()=>Dt(s)})};const hw={kernelName:La,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>A(Qa(J(e,"float32")),s)}}};const dw={kernelName:Oa,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>A(ru(J(e,"float32")),s)}}};const pw={kernelName:Xd,inputsToSave:["x"],gradFunc:(s,t,e)=>{const[n]=t,{begin:i,size:a}=e,o=n.shape,[r,l]=Om(n,i,a),c=[];for(let u=0;u<s.rank;u++)c.push([r[u],o[u]-r[u]-l[u]]);return{x:()=>to(s,c)}}};const fw={kernelName:Rc,outputsToSave:[!0],gradFunc:(s,t,e)=>{const[n]=t,{dim:i}=e,a=!0,o=A(s,n);return{logits:()=>pt(o,A(lt(o,[i],a),n))}}};const mw={kernelName:_a,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>A(s,li(e))}}};const ll={kernelName:Ec,gradFunc:(s,t,e)=>{const{blockShape:n,paddings:i}=e;return{x:()=>lu(s,n,i)}}};const cl={kernelName:Lc,gradFunc:(s,t,e)=>{const{axis:n}=e;return{x:()=>xn(s,n)}}};const gw={kernelName:Yd,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>ut(s,A(Be(J(e,"float32")),2))}}};const bw={kernelName:Oc,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>A(s,A(J(e,"float32"),2))}}};const yw={kernelName:Qd,inputsToSave:["a","b"],gradFunc:(s,t)=>{const[e,n]=t,i=zt(2);return{a:()=>A(s,A(i,pt(e,n))),b:()=>A(s,A(i,pt(n,e)))}}};const ww={kernelName:Wa,gradFunc:s=>({x:()=>Dt(s)})};const kw={kernelName:tp,inputsToSave:["a","b"],gradFunc:(s,t)=>{const[e,n]=t,i=Fe(e.shape,n.shape);return{a:()=>{let r=s;const l=Pt(e.shape,i);return l.length>0&&(r=lt(r,l)),B(r,e.shape)},b:()=>{let r=s;const l=Pt(n.shape,i);return l.length>0&&(r=lt(r,l)),B(Ut(r),n.shape)}}}};const Iw={kernelName:_c,inputsToSave:["x"],gradFunc:(s,t,e)=>{const[n]=t,i=n.shape.slice(),{axis:a}=e;Lt(a,n.shape).forEach(c=>{i[c]=1});const r=B(s,i),l=A(r,Is(n.shape,"float32"));return{x:()=>l}}};const xw={kernelName:Va,inputsToSave:["x"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>ut(s,Gt(Qa(e)))}}};const Sw={kernelName:Ba,outputsToSave:[!0],gradFunc:(s,t)=>{const[e]=t;return{x:()=>A(pt(zt(1),Gt(e)),s)}}};const vw={kernelName:Wc,inputsToSave:["x"],gradFunc:(s,t,e)=>{const[n]=t,{reps:i}=e;return{x:()=>{let o=Dt(n);if(n.rank===1)for(let r=0;r<i[0];++r)o=X(o,Le(s,[r*n.shape[0]],[n.shape[0]]));else if(n.rank===2)for(let r=0;r<i[0];++r)for(let l=0;l<i[1];++l)o=X(o,Le(s,[r*n.shape[0],l*n.shape[1]],[n.shape[0],n.shape[1]]));else if(n.rank===3)for(let r=0;r<i[0];++r)for(let l=0;l<i[1];++l)for(let c=0;c<i[2];++c)o=X(o,Le(s,[r*n.shape[0],l*n.shape[1],c*n.shape[2]],[n.shape[0],n.shape[1],n.shape[2]]));else if(n.rank===4)for(let r=0;r<i[0];++r)for(let l=0;l<i[1];++l)for(let c=0;c<i[2];++c)for(let u=0;u<i[3];++u)o=X(o,Le(s,[r*n.shape[0],l*n.shape[1],c*n.shape[2],u*n.shape[3]],[n.shape[0],n.shape[1],n.shape[2],n.shape[3]]));else throw new Error(`Gradient for tile operation is not implemented for rank-${n.rank} tensors yet.`);return o}}}};const Nw={kernelName:ep,gradFunc:(s,t,e)=>{const n=e,{perm:i}=n,a=yn(i);return{x:()=>ht(s,a)}}};const Cw={kernelName:Vc,gradFunc:(s,t,e)=>{const n=e,{axis:i}=n;return{value:()=>Us(s,i)}}};const Tw={kernelName:Bc,inputsToSave:["segmentIds"],gradFunc:(s,t)=>{const[e]=t;return{x:()=>Aw(s,e)}}};function Aw(s,t){const e=bs(t,Dt(t)),n=eo(s,e);let i=Hs(t,zt(0,"int32"));const a=n.rank-i.rank;for(let r=0;r<a;++r)i=Ve(i,r+1);i=ws(i,Is(n.shape,"bool"));const o=Dt(n);return De(i,n,o)}const Dw={kernelName:Pc,gradFunc:s=>({x:()=>Dt(s)})};const zw=[Eu,Tb,Ab,Db,zb,Fb,$b,Mb,Rb,Eb,Lb,Ob,Vb,Gb,Hb,Ub,jb,qb,Kb,Zb,Jb,Xb,Qb,Yb,sy,ny,iy,ay,oy,ry,Xy,ly,cy,uy,hy,dy,fy,py,my,gy,by,yy,wy,ky,Iy,xy,Sy,vy,Ny,Ay,ol,ol,Dy,$y,Ey,Ly,Oy,_y,Wy,Vy,By,Py,Gy,Hy,Uy,rl,rl,jy,qy,Jy,Yy,Qy,tw,ew,sw,nw,iw,aw,ow,rw,lw,cw,uw,hw,dw,pw,fw,mw,ll,ll,cl,cl,gw,yw,bw,ww,kw,Iw,xw,Sw,vw,Nw,Cw,Tw,Dw];for(const s of zw)sp(s);z().prototype.abs=function(){return this.throwIfDisposed(),fs(this)};z().prototype.acos=function(){return this.throwIfDisposed(),Af(this)};z().prototype.acosh=function(){return this.throwIfDisposed(),Df(this)};z().prototype.add=function(s){return this.throwIfDisposed(),X(this,s)};z().prototype.all=function(s,t){return this.throwIfDisposed(),cu(this,s,t)};z().prototype.any=function(s,t){return this.throwIfDisposed(),Xi(this,s,t)};z().prototype.argMax=function(s){return this.throwIfDisposed(),hn(this,s)};z().prototype.argMin=function(s){return this.throwIfDisposed(),zf(this,s)};z().prototype.asScalar=function(){return this.throwIfDisposed(),K(this.size===1,()=>"The array must have only 1 element."),B(this,[])};z().prototype.asType=function(s){return this.throwIfDisposed(),J(this,s)};z().prototype.as1D=function(){return this.throwIfDisposed(),B(this,[this.size])};z().prototype.as2D=function(s,t){return this.throwIfDisposed(),B(this,[s,t])};z().prototype.as3D=function(s,t,e){return this.throwIfDisposed(),B(this,[s,t,e])};z().prototype.as4D=function(s,t,e,n){return this.throwIfDisposed(),B(this,[s,t,e,n])};z().prototype.as5D=function(s,t,e,n,i){return this.throwIfDisposed(),B(this,[s,t,e,n,i])};z().prototype.asin=function(){return this.throwIfDisposed(),Ff(this)};z().prototype.asinh=function(){return this.throwIfDisposed(),$f(this)};z().prototype.atan=function(){return this.throwIfDisposed(),Mf(this)};z().prototype.atan2=function(s){return this.throwIfDisposed(),Rf(this,s)};z().prototype.atanh=function(){return this.throwIfDisposed(),Ef(this)};z().prototype.avgPool=function(s,t,e,n){return this.throwIfDisposed(),uu(this,s,t,e,n)};z().prototype.batchToSpaceND=function(s,t){return this.throwIfDisposed(),lu(this,s,t)};z().prototype.batchNorm=function(s,t,e,n,i){return this.throwIfDisposed(),Lf(this,s,t,e,n,i)};z().prototype.broadcastTo=function(s){return this.throwIfDisposed(),np(this,s)};z().prototype.cast=function(s){return this.throwIfDisposed(),J(this,s)};z().prototype.ceil=function(){return this.throwIfDisposed(),Of(this)};z().prototype.clipByValue=function(s,t){return this.throwIfDisposed(),te(this,s,t)};z().prototype.concat=function(s,t){return this.throwIfDisposed(),s instanceof re&&(s=[s]),xn([this,...s],t)};z().prototype.conv1d=function(s,t,e,n,i,a){return this.throwIfDisposed(),hu(this,s,t,e,n,i,a)};z().prototype.conv2dTranspose=function(s,t,e,n,i){return this.throwIfDisposed(),du(this,s,t,e,n,i)};z().prototype.conv2d=function(s,t,e,n,i,a){return this.throwIfDisposed(),Pn(this,s,t,e,n,i,a)};z().prototype.cos=function(){return this.throwIfDisposed(),Qa(this)};z().prototype.cosh=function(){return this.throwIfDisposed(),ru(this)};z().prototype.cumprod=function(s,t,e){return this.throwIfDisposed(),Ji(this,s,t,e)};z().prototype.cumsum=function(s,t,e){return this.throwIfDisposed(),su(this,s,t,e)};z().prototype.depthToSpace=function(s,t){return this.throwIfDisposed(),_f(this,s,t)};z().prototype.depthwiseConv2d=function(s,t,e,n,i,a){return this.throwIfDisposed(),pu(this,s,t,e,n,i,a)};z().prototype.dilation2d=function(s,t,e,n,i){return this.throwIfDisposed(),Wf(this,s,t,e,n,i)};z().prototype.divNoNan=function(s){return this.throwIfDisposed(),Vf(this,s)};z().prototype.div=function(s){return this.throwIfDisposed(),ut(this,s)};z().prototype.dot=function(s){return this.throwIfDisposed(),Bf(this,s)};z().prototype.elu=function(){return this.throwIfDisposed(),Pa(this)};z().prototype.equal=function(s){return this.throwIfDisposed(),ge(this,s)};z().prototype.erf=function(){return this.throwIfDisposed(),fu(this)};z().prototype.euclideanNorm=function(s,t){return this.throwIfDisposed(),Pf(this,s,t)};z().prototype.exp=function(){return this.throwIfDisposed(),ks(this)};z().prototype.expandDims=function(s){return this.throwIfDisposed(),Ve(this,s)};z().prototype.expm1=function(){return this.throwIfDisposed(),Gf(this)};z().prototype.fft=function(){return this.throwIfDisposed(),Hf(this)};z().prototype.flatten=function(){return this.throwIfDisposed(),B(this,[this.size])};z().prototype.floor=function(){return this.throwIfDisposed(),Ya(this)};z().prototype.floorDiv=function(s){return this.throwIfDisposed(),ip(this,s)};z().prototype.gather=function(s,t,e){return this.throwIfDisposed(),eo(this,s,t,e)};z().prototype.greaterEqual=function(s){return this.throwIfDisposed(),Hs(this,s)};z().prototype.greater=function(s){return this.throwIfDisposed(),ke(this,s)};z().prototype.ifft=function(){return this.throwIfDisposed(),Uf(this)};z().prototype.irfft=function(){return this.throwIfDisposed(),jf(this)};z().prototype.isFinite=function(){return this.throwIfDisposed(),qf(this)};z().prototype.isInf=function(){return this.throwIfDisposed(),Kf(this)};z().prototype.isNaN=function(){return this.throwIfDisposed(),Zf(this)};z().prototype.leakyRelu=function(s){return this.throwIfDisposed(),Gc(this,s)};z().prototype.lessEqual=function(s){return this.throwIfDisposed(),hi(this,s)};z().prototype.less=function(s){return this.throwIfDisposed(),au(this,s)};z().prototype.localResponseNormalization=function(s,t,e,n){return this.throwIfDisposed(),Jf(this,s,t,e,n)};z().prototype.logSigmoid=function(){return this.throwIfDisposed(),Xf(this)};z().prototype.logSoftmax=function(s){return this.throwIfDisposed(),mu(this,s)};z().prototype.logSumExp=function(s,t){return this.throwIfDisposed(),gu(this,s,t)};z().prototype.log=function(){return this.throwIfDisposed(),ss(this)};z().prototype.log1p=function(){return this.throwIfDisposed(),bu(this)};z().prototype.logicalAnd=function(s){return this.throwIfDisposed(),ws(this,s)};z().prototype.logicalNot=function(){return this.throwIfDisposed(),ou(this)};z().prototype.logicalOr=function(s){return this.throwIfDisposed(),Yf(this,s)};z().prototype.logicalXor=function(s){return this.throwIfDisposed(),Qf(this,s)};z().prototype.matMul=function(s,t,e){return this.throwIfDisposed(),pe(this,s,t,e)};z().prototype.maxPool=function(s,t,e,n){return this.throwIfDisposed(),yu(this,s,t,e,n)};z().prototype.max=function(s,t){return this.throwIfDisposed(),Rs(this,s,t)};z().prototype.maximum=function(s){return this.throwIfDisposed(),bs(this,s)};z().prototype.mean=function(s,t){return this.throwIfDisposed(),Ot(this,s,t)};z().prototype.min=function(s,t){return this.throwIfDisposed(),wu(this,s,t)};z().prototype.minimum=function(s){return this.throwIfDisposed(),so(this,s)};z().prototype.mirrorPad=function(s,t){return this.throwIfDisposed(),tm(this,s,t)};z().prototype.mod=function(s){return this.throwIfDisposed(),em(this,s)};z().prototype.mul=function(s){return this.throwIfDisposed(),A(this,s)};z().prototype.neg=function(){return this.throwIfDisposed(),Ut(this)};z().prototype.norm=function(s,t,e){return this.throwIfDisposed(),sm(this,s,t,e)};z().prototype.notEqual=function(s){return this.throwIfDisposed(),Gn(this,s)};z().prototype.oneHot=function(s,t=1,e=0){return this.throwIfDisposed(),Bn(this,s,t,e)};z().prototype.onesLike=function(){return this.throwIfDisposed(),le(this)};z().prototype.pad=function(s,t){return this.throwIfDisposed(),to(this,s,t)};z().prototype.pool=function(s,t,e,n,i,a){return this.throwIfDisposed(),nm(this,s,t,e,n,i,a)};z().prototype.pow=function(s){return this.throwIfDisposed(),ri(this,s)};z().prototype.prelu=function(s){return this.throwIfDisposed(),Hc(this,s)};z().prototype.prod=function(s,t){return this.throwIfDisposed(),im(this,s,t)};z().prototype.reciprocal=function(){return this.throwIfDisposed(),am(this)};z().prototype.relu=function(){return this.throwIfDisposed(),Ps(this)};z().prototype.relu6=function(){return this.throwIfDisposed(),ap(this)};z().prototype.reshapeAs=function(s){return this.throwIfDisposed(),B(this,s.shape)};z().prototype.reshape=function(s){return this.throwIfDisposed(),B(this,s)};z().prototype.resizeBilinear=function(s,t,e){return this.throwIfDisposed(),om(this,s,t,e)};z().prototype.resizeNearestNeighbor=function(s,t,e){return this.throwIfDisposed(),rm(this,s,t,e)};z().prototype.reverse=function(s){return this.throwIfDisposed(),un(this,s)};z().prototype.rfft=function(){return this.throwIfDisposed(),lm(this)};z().prototype.round=function(){return this.throwIfDisposed(),cm(this)};z().prototype.rsqrt=function(){return this.throwIfDisposed(),nu(this)};z().prototype.selu=function(){return this.throwIfDisposed(),ku(this)};z().prototype.separableConv2d=function(s,t,e,n,i,a){return this.throwIfDisposed(),Iu(this,s,t,e,n,i,a)};z().prototype.sigmoid=function(){return this.throwIfDisposed(),li(this)};z().prototype.sign=function(){return this.throwIfDisposed(),um(this)};z().prototype.sin=function(){return this.throwIfDisposed(),tu(this)};z().prototype.sinh=function(){return this.throwIfDisposed(),eu(this)};z().prototype.slice=function(s,t){return this.throwIfDisposed(),Le(this,s,t)};z().prototype.softmax=function(s){return this.throwIfDisposed(),no(this,s)};z().prototype.softplus=function(){return this.throwIfDisposed(),di(this)};z().prototype.spaceToBatchND=function(s,t){return this.throwIfDisposed(),Yc(this,s,t)};z().prototype.split=function(s,t){return this.throwIfDisposed(),_e(this,s,t)};z().prototype.sqrt=function(){return this.throwIfDisposed(),Be(this)};z().prototype.square=function(){return this.throwIfDisposed(),Gt(this)};z().prototype.squaredDifference=function(s){return this.throwIfDisposed(),hm(this,s)};z().prototype.squeeze=function(s){return this.throwIfDisposed(),pi(this,s)};z().prototype.stack=function(s,t){this.throwIfDisposed();const e=s instanceof re?[this,s]:[this,...s];return Us(e,t)};z().prototype.step=function(s){return this.throwIfDisposed(),ii(this,s)};z().prototype.stridedSlice=function(s,t,e,n,i,a,o,r){return this.throwIfDisposed(),dm(this,s,t,e,n,i,a,o,r)};z().prototype.sub=function(s){return this.throwIfDisposed(),pt(this,s)};z().prototype.sum=function(s,t){return this.throwIfDisposed(),lt(this,s,t)};z().prototype.tan=function(){return this.throwIfDisposed(),pm(this)};z().prototype.tanh=function(){return this.throwIfDisposed(),fi(this)};z().prototype.tile=function(s){return this.throwIfDisposed(),hs(this,s)};z().prototype.toBool=function(){return this.throwIfDisposed(),J(this,"bool")};z().prototype.toFloat=function(){return this.throwIfDisposed(),J(this,"float32")};z().prototype.toInt=function(){return this.throwIfDisposed(),J(this,"int32")};z().prototype.topk=function(s,t){return this.throwIfDisposed(),fm(this,s,t)};z().prototype.transpose=function(s){return this.throwIfDisposed(),ht(this,s)};z().prototype.unique=function(s){return this.throwIfDisposed(),mm(this,s)};z().prototype.unsortedSegmentSum=function(s,t){return this.throwIfDisposed(),iu(this,s,t)};z().prototype.unstack=function(s){return this.throwIfDisposed(),cn(this,s)};z().prototype.where=function(s,t){return this.throwIfDisposed(),De(s,this,t)};z().prototype.zerosLike=function(){return this.throwIfDisposed(),Dt(this)};class xe extends Error{constructor(t){super(t),Object.setPrototypeOf(this,xe.prototype)}}class ie extends Error{constructor(t){super(t),Object.setPrototypeOf(this,ie.prototype)}}class x extends Error{constructor(t){super(t),Object.setPrototypeOf(this,x.prototype)}}class it extends Error{constructor(t){super(t),Object.setPrototypeOf(this,it.prototype)}}class po extends Error{constructor(t){super(t),Object.setPrototypeOf(this,po.prototype)}}class Ou{constructor(t){this.maxEntries=t||100,this.cache=new Map}get(t){let e;return this.cache.has(t)&&(e=this.cache.get(t),this.cache.delete(t),this.cache.set(t,e)),e}put(t,e){if(this.cache.has(t))this.cache.delete(t);else if(this.cache.size>=this.maxEntries){const n=this.cache.keys().next().value;this.cache.delete(n)}this.cache.set(t,e)}getMaxEntries(){return this.maxEntries}setMaxEntries(t){if(t<0)throw new Error(`The maxEntries of LRU caches must be at least 0, but got ${t}.`);if(this.maxEntries>t)for(let e=0;e<this.maxEntries-t;e++){const n=this.cache.keys().next().value;this.cache.delete(n)}this.maxEntries=t}}function ms(s,t){if(Array.isArray(s)){let e=[];for(let n=0;n<t;n++)e=e.concat(s);return e}else{const e=new Array(t);return e.fill(s),e}}function Se(s,t){if(!s)throw new po(t)}function ul(s,t){let e=0;for(const n of s)n===t&&e++;return e}function jt(s){return s.length===1?s[0]:s}function mt(s){return Array.isArray(s)?s:[s]}function Ee(s){const e=s.replace(/(.)([A-Z][a-z0-9]+)/g,"$1_$2").replace(/([a-z])([A-Z])/g,"$1_$2").toLowerCase();return e[0]!=="_"?e:"private"+e}function us(s){return s.length<=1||s.indexOf("_")===-1?s:s.replace(/[_]+(\w|$)/g,(t,e)=>e.toUpperCase())}let ne={};function fo(s){if(s==null)return null;const t={};return t.className=s.getClassName(),t.config=s.getConfig(),t}function Qi(s){if(!(s==null||typeof s!="object"))if(Array.isArray(s))s.forEach(t=>Qi(t));else{const t=Object.keys(s);for(const e of t){const n=s[e];n!=null&&typeof n=="object"&&(!Array.isArray(n)&&n.type==="ndarray"&&typeof n.value=="number"?s[e]=n.value:Qi(n))}}}function Sn(s,t={},e={},n="object",i=!1){if(typeof s=="string"){const a=s;let o;if(a in e)o=e[a];else if(a in ne)o=ne[a];else if(o=t[a],o==null)throw new x(`Unknown ${n}: ${s}. This may be due to one of the following reasons:
1. The ${n} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.
2. The custom ${n} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);return o}else{const a=s;if(a.className==null||a.config==null)throw new x(`${n}: Improper config format: ${JSON.stringify(a)}.
'className' and 'config' must set.`);const o=a.className;let r,l;if(o in e?[r,l]=e[o]:o in ne?[r,l]=ne.className:o in t&&([r,l]=t[o]),r==null)throw new x(`Unknown ${n}: ${o}. This may be due to one of the following reasons:
1. The ${n} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.
2. The custom ${n} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);if(l!=null){const c={};for(const p of Object.keys(ne))c[p]=ne[p];for(const p of Object.keys(e))c[p]=e[p];const u=a.config;u.customObjects=c;const d=Object.assign({},ne);for(const p of Object.keys(e))ne[p]=e[p];Qi(a.config);const h=l(r,a.config,e,i);return ne=Object.assign({},d),h}else{const c=Object.assign({},ne);for(const d of Object.keys(e))ne[d]=e[d];const u=new r(a.config);return ne=Object.assign({},c),u}}}function Fw(s,t){return s<t?-1:s>t?1:0}function Rn(s,t){return-1*Fw(s,t)}function Xe(s){if(s==null)return s;const t=[];for(const e of s)t.indexOf(e)===-1&&t.push(e);return t}function $w(s){if(s==null)throw new x(`Invalid value in obj: ${JSON.stringify(s)}`);for(const t in s)if(s.hasOwnProperty(t))return!1;return!0}function vs(s,t,e){if(e!=null&&s.indexOf(e)<0)throw new x(`${e} is not a valid ${t}.  Valid values are ${s} or null/undefined.`)}function mo(s,t,e=0,n=1/0){return Se(e>=0),Se(n>=e),Array.isArray(s)&&s.length>=e&&s.length<=n&&s.every(i=>typeof i===t)}function _t(s,t){Array.isArray(s)?(K(s.length>0,()=>`${t} is unexpectedly an empty array.`),s.forEach((e,n)=>_t(e,`element ${n+1} of ${t}`))):K(Number.isInteger(s)&&s>0,()=>`Expected ${t} to be a positive integer, but got ${_u(s)}.`)}function _u(s){return s===null?"null":Array.isArray(s)?"["+s.map(t=>_u(t)).join(",")+"]":typeof s=="string"?`"${s}"`:`${s}`}function Mw(s,t,e){let n=e!=null?e():$s(),i;return(...o)=>{const r=e!=null?e():$s();return r-n<t||(n=r,i=s(...o)),i}}function Wu(s){return s==="relu"?"relu":s==="linear"?"linear":s==="elu"?"elu":null}let Rw=0;function Vu(){return Rw++}const En={};function bi(s=""){return s in En||(En[s]=0),En[s]+=1,s+En[s].toString()}const Ew=["channelsFirst","channelsLast"],Lw=["nearest","bilinear"],Ow=["valid","same","causal"],_w=["max","avg"],Ww=["sum","mul","concat","ave"];const As=new Map;function Ft(s){vs(Ew,"DataFormat",s)}function Vw(s){vs(Lw,"InterpolationFormat",s)}function se(s){vs(Ow,"PaddingMode",s)}function Bu(s){vs(_w,"PoolMode",s)}const ln=[],hl="/";function ds(s,t){ln.push(s);try{const e=t();return ln.pop(),e}catch(e){throw ln.pop(),e}}function Bw(){return ln.length===0?"":ln.join(hl)+hl}function Pu(s){if(!Hu(s))throw new Error("Not a valid tensor name: '"+s+"'");return Bw()+s}function Gu(s){if(!Hu(s))throw new Error("Not a valid tensor name: '"+s+"'");As.has(s)||As.set(s,0);const t=As.get(s);if(As.set(s,As.get(s)+1),t>0){const e=`${s}_${t}`;return As.set(e,1),e}else return s}const Pw=new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);function Hu(s){return!!s.match(Pw)}function Gw(s){return s===parseInt(s.toString(),10)}function Ye(s,t,e){t==null&&(t=0),e==null&&(e=s.length);let n=1;for(let i=t;i<e;++i)n*=s[i];return n}function Ls(s){if(s.length===0)return Number.NaN;let t=Number.POSITIVE_INFINITY;for(let e=0;e<s.length;e++){const n=s[e];n<t&&(t=n)}return t}function ns(s){if(s.length===0)return Number.NaN;let t=Number.NEGATIVE_INFINITY;for(let e=0;e<s.length;e++){const n=s[e];n>t&&(t=n)}return t}function be(s,t){if(t<s)throw new x(`end (${t}) < begin (${s}) is forbidden.`);const e=[];for(let n=s;n<t;++n)e.push(n);return e}let Bi;function $t(){return Bi==null&&(Bi=op().epsilon()),Bi}function ye(){return"channelsLast"}function Te(s,t){return J(s,t)}function vn(s,t=-1){const e=s.shape.slice();return t<0&&(t=e.length+t+1),e.splice(t,0,1),B(s,e)}function Hw(s,t){return T(()=>{if(s.shape.length!==2)throw new x(`repeat() expects a rank-2 tensor, but received a rank-${s.shape.length} tensor.`);const e=vn(s,1);return ta(e,[1,t,1])})}function Uw(s){const t=[Ye(s.shape)];return B(s,t)}function jw(s){if(s.rank<=1)throw new x(`batchFlatten requires a minimum rank of 2. Got rank: ${s.rank}.`);const t=[s.shape[0],Ye(s.shape,1)];return B(s,t)}function ps(s,t,e){return T(()=>{switch(s.rank){case 1:return ao(s,t,e);case 2:return xu(s,[t,0],[e,s.shape[1]]);case 3:return io(s,[t,0,0],[e,s.shape[1],s.shape[2]]);case 4:return Hn(s,[t,0,0,0],[e,s.shape[1],s.shape[2],s.shape[3]]);case 5:return Le(s,[t,0,0,0,0],[e,s.shape[1],s.shape[2],s.shape[3],s.shape[4]]);case 6:return Le(s,[t,0,0,0,0,0],[e,s.shape[1],s.shape[2],s.shape[3],s.shape[4],s.shape[5]]);default:throw new x(`sliceAlongFirstAxis() received an unsupported tensor rank: ${s.rank}`)}})}function Pi(s,t,e){return T(()=>{switch(s.rank){case 1:return ao(s,t,e);case 2:return xu(s,[0,t],[s.shape[0],e]);case 3:return io(s,[0,0,t],[s.shape[0],s.shape[1],e]);case 4:return Hn(s,[0,0,0,t],[s.shape[0],s.shape[1],s.shape[2],e]);default:throw new x(`sliceAlongLastAxis() received an unsupported tensor rank: ${s.rank}`)}})}function Ln(s,t,e,n){return T(()=>{switch(s.rank){case 1:return ao(s,t,e);case 2:switch(n){case 1:return ps(s,t,e);case 2:return Pi(s,t,e);default:throw new x(`The axis is not within the rank of the tensor ${n}`)}case 3:switch(n){case 1:return ps(s,t,e);case 2:return io(s,[0,t,0],[s.shape[0],e,s.shape[2]]);case 3:return Pi(s,t,e);default:throw new x(`The axis is not within the rank of the tensor ${n}`)}case 4:switch(n){case 1:return ps(s,t,e);case 2:return Hn(s,[0,t,0,0],[s.shape[0],e,s.shape[2],s.shape[3]]);case 3:return Hn(s,[0,0,t,0],[s.shape[0],s.shape[1],e,s.shape[3]]);case 4:return Pi(s,t,e);default:throw new x(`The axis is not within the rank of the tensor ${n}`)}default:throw new x(`sliceAlongLastAxis() received an unsupported tensor rank: ${s.rank}`)}})}function go(s,t=-1){let e;return t<0&&(e=s[0].rank,e!==0?t=e:t=0),t===s[0].rank&&(t=-1),xn(s,t)}function dl(s,t){switch(s.rank){case 1:return km([s,t]);case 2:return wm([s,t],0);case 3:return ym([s,t],0);case 4:return bm([s,t],0);default:throw new x(`concatAlongFirstAxis() received an unsupported tensor rank: ${s.rank}`)}}function ta(s,t){if(Array.isArray(t)||(t=[t]),s.rank!==t.length)throw new x(`The length of input n (${t.length}) does not match the number of dimensions in input x (${s.rank})`);return hs(s,t)}function yi(s,t=0,e=1,n,i){return gm(s,t,e,n,i)}function Ae(s,t,e,n){if(s.rank<2||t.rank<2)throw new it(`dot requires both inputs to be rank >= 2 but got x shape = ${s.shape} and y shape = ${t.shape}`);if(t.rank>=3){const i=s.shape.slice(-1)[0],a=t.shape.slice(-2)[0];if(i!==a)throw new it(`If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ${s.shape} and  y shape = ${t.shape}`)}if(s.rank===2&&t.rank===2)return el({a:s,b:t,transposeA:!1,transposeB:!1,bias:n?ea(s.rank,n,ye()):null,activation:e});{const i=s.shape.slice(),a=i.pop();s=B(s,[-1,a]);const o=t.shape.slice(),r=o.pop(),l=o.pop(),c=[...o,r],u=Array.from({length:t.rank},(m,f)=>f===0?t.rank-2:f<=t.rank-2?f-1:f);t=B(ht(t,u),[l,-1]);const d=[...i,...c];return B(el({a:s,b:t,transposeA:!1,transposeB:!1,bias:n?ea(s.rank,n,ye()):null,activation:e}),d)}}function Uu(s,t,e){return T(()=>(Array.isArray(t)?t=dn(t,"int32"):t=J(t,"int32"),eo(s,t,e)))}function Nn(s){return A(s,s)}function ea(s,t,e){const n=t.shape;if(t.rank!==1&&t.rank!==s)throw new x(`Unexpected bias dimensions: ${t.rank}; expected it to be 1 or ${s}`);if(s===5){if(e==="channelsFirst")return n.length===1?B(t,[1,n[0],1,1,1]):B(t,[1,n[3],n[0],n[1],n[2]]);if(e==="channelsLast")return n.length===1?B(t,[1,1,1,1,n[0]]):B(t,[1].concat(n))}else if(s===4){if(e==="channelsFirst")return n.length===1?B(t,[1,n[0],1,1]):B(t,[1,n[2],n[0],n[1]]);if(e==="channelsLast")return n.length===1?B(t,[1,1,1,n[0]]):B(t,[1].concat(n))}else if(s===3){if(e==="channelsFirst")return n.length===1?B(t,[1,n[0],1]):B(t,[1,n[1],n[0]]);if(e==="channelsLast")return n.length===1?B(t,[1,1,n[0]]):B(t,[1].concat(n))}else if(s<3)return t;throw new x(`Unsupported input rank by biasAdd: ${t.rank}`)}function Ie(s,t,e){return T(()=>(e==null&&(e=ye()),Ft(e),X(s,ea(s.rank,t,e))))}function qw(s,t=1){if(t!==1)throw new it(`Support for alpha values other than 1 (${t}) is not implemented yet.`);return Pa(s)}function Kw(s){return T(()=>ut(s,X(fs(s),1)))}function ju(s,t,e,n){return T(()=>Im(s,t,e,n))}function Zw(s){return T(()=>{const t=X(.5,A(.2,s));return te(t,0,1)})}function Cn(s,t,e=!1){return e?s():t()}const Jw=["fanIn","fanOut","fanAvg"],Xw=["normal","uniform","truncatedNormal"];function Yw(s){vs(Jw,"FanMode",s)}function Qw(s){vs(Xw,"Distribution",s)}class ce extends wn{fromConfigUsesCustomObjects(){return!1}getConfig(){return{}}}class bo extends ce{apply(t,e){return Qt(t,e)}}bo.className="Zeros";O(bo);class wi extends ce{apply(t,e){return Is(t,e)}}wi.className="Ones";O(wi);class yo extends ce{constructor(t){if(super(),typeof t!="object")throw new x(`Expected argument of type ConstantConfig but got ${t}`);if(t.value===void 0)throw new x(`config must have value set but got ${t}`);this.value=t.value}apply(t,e){return T(()=>A(zt(this.value),Is(t,e)))}getConfig(){return{value:this.value}}}yo.className="Constant";O(yo);class wo extends ce{constructor(t){super(),this.DEFAULT_MINVAL=-.05,this.DEFAULT_MAXVAL=.05,this.minval=t.minval||this.DEFAULT_MINVAL,this.maxval=t.maxval||this.DEFAULT_MAXVAL,this.seed=t.seed}apply(t,e){return mi(t,this.minval,this.maxval,e,this.seed)}getConfig(){return{minval:this.minval,maxval:this.maxval,seed:this.seed}}}wo.className="RandomUniform";O(wo);class ko extends ce{constructor(t){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=t.mean||this.DEFAULT_MEAN,this.stddev=t.stddev||this.DEFAULT_STDDEV,this.seed=t.seed}apply(t,e){if(e=e||"float32",e!=="float32"&&e!=="int32")throw new it(`randomNormal does not support dType ${e}.`);return yi(t,this.mean,this.stddev,e,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}ko.className="RandomNormal";O(ko);class Io extends ce{constructor(t){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=t.mean||this.DEFAULT_MEAN,this.stddev=t.stddev||this.DEFAULT_STDDEV,this.seed=t.seed}apply(t,e){if(e=e||"float32",e!=="float32"&&e!=="int32")throw new it(`truncatedNormal does not support dType ${e}.`);return Su(t,this.mean,this.stddev,e,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}Io.className="TruncatedNormal";O(Io);class xo extends ce{constructor(t){super(),this.gain=t.gain!=null?t.gain:1}apply(t,e){return T(()=>{if(t.length!==2||t[0]!==t[1])throw new x("Identity matrix initializer can only be used for 2D square matrices.");return A(this.gain,xm(t[0]))})}getConfig(){return{gain:this.gain}}}xo.className="Identity";O(xo);function tk(s,t="channelsLast"){let e,n;if(Ft(t),s.length===2)e=s[0],n=s[1];else if([3,4,5].indexOf(s.length)!==-1){if(t==="channelsFirst"){const i=Ye(s,2);e=s[1]*i,n=s[0]*i}else if(t==="channelsLast"){const i=Ye(s,0,s.length-2);e=s[s.length-2]*i,n=s[s.length-1]*i}}else{const i=Ye(s);e=Math.sqrt(i),n=Math.sqrt(i)}return[e,n]}class qt extends ce{constructor(t){if(super(),t.scale<0)throw new x(`scale must be a positive float. Got: ${t.scale}`);this.scale=t.scale==null?1:t.scale,this.mode=t.mode==null?"fanIn":t.mode,Yw(this.mode),this.distribution=t.distribution==null?"normal":t.distribution,Qw(this.distribution),this.seed=t.seed}apply(t,e){const n=tk(t),i=n[0],a=n[1];let o=this.scale;if(this.mode==="fanIn"?o/=Math.max(1,i):this.mode==="fanOut"?o/=Math.max(1,a):o/=Math.max(1,(i+a)/2),this.distribution==="normal"){const r=Math.sqrt(o);if(e=e||"float32",e!=="float32"&&e!=="int32")throw new it(`${this.getClassName()} does not support dType ${e}.`);return Su(t,0,r,e,this.seed)}else{const r=Math.sqrt(3*o);return mi(t,-r,r,e,this.seed)}}getConfig(){return{scale:this.scale,mode:this.mode,distribution:this.distribution,seed:this.seed}}}qt.className="VarianceScaling";O(qt);class ki extends qt{constructor(t){super({scale:1,mode:"fanAvg",distribution:"uniform",seed:t==null?null:t.seed})}getClassName(){return qt.className}}ki.className="GlorotUniform";O(ki);class Ii extends qt{constructor(t){super({scale:1,mode:"fanAvg",distribution:"normal",seed:t==null?null:t.seed})}getClassName(){return qt.className}}Ii.className="GlorotNormal";O(Ii);class xi extends qt{constructor(t){super({scale:2,mode:"fanIn",distribution:"normal",seed:t==null?null:t.seed})}getClassName(){return qt.className}}xi.className="HeNormal";O(xi);class Si extends qt{constructor(t){super({scale:2,mode:"fanIn",distribution:"uniform",seed:t==null?null:t.seed})}getClassName(){return qt.className}}Si.className="HeUniform";O(Si);class vi extends qt{constructor(t){super({scale:1,mode:"fanIn",distribution:"normal",seed:t==null?null:t.seed})}getClassName(){return qt.className}}vi.className="LeCunNormal";O(vi);class Ni extends qt{constructor(t){super({scale:1,mode:"fanIn",distribution:"uniform",seed:t==null?null:t.seed})}getClassName(){return qt.className}}Ni.className="LeCunUniform";O(Ni);class So extends ce{constructor(t){super(),this.DEFAULT_GAIN=1,this.ELEMENTS_WARN_SLOW=2e3,this.gain=t.gain==null?this.DEFAULT_GAIN:t.gain,this.seed=t.seed}apply(t,e){return T(()=>{if(t.length<2)throw new it("Shape must be at least 2D.");if(e!=="int32"&&e!=="float32"&&e!==void 0)throw new TypeError(`Unsupported data type ${e}.`);e=e;const n=st(t.slice(0,-1)),i=t[t.length-1],a=n*i;a>this.ELEMENTS_WARN_SLOW&&console.warn(`Orthogonal initializer is being called on a matrix with more than ${this.ELEMENTS_WARN_SLOW} (${a}) elements: Slowness may result.`);const o=[Math.max(i,n),Math.min(i,n)],r=yi(o,0,1,e,this.seed),l=Sm.qr(r,!1);let c=l[0];const d=l[1].flatten().stridedSlice([0],[Math.min(i,n)*Math.min(i,n)],[Math.min(i,n)+1]);return c=A(c,d.sign()),n<i&&(c=c.transpose()),A(zt(this.gain),c.reshape(t))})}getConfig(){return{gain:this.gain,seed:this.seed}}}So.className="Orthogonal";O(So);const pl={constant:"Constant",glorotNormal:"GlorotNormal",glorotUniform:"GlorotUniform",heNormal:"HeNormal",heUniform:"HeUniform",identity:"Identity",leCunNormal:"LeCunNormal",leCunUniform:"LeCunUniform",ones:"Ones",orthogonal:"Orthogonal",randomNormal:"RandomNormal",randomUniform:"RandomUniform",truncatedNormal:"TruncatedNormal",varianceScaling:"VarianceScaling",zeros:"Zeros"};function fl(s,t={}){return Sn(s,kn.getMap().classNameMap,t,"initializer")}function Tt(s){return fo(s)}function vt(s){if(typeof s=="string"){const t=s in pl?pl[s]:s;if(t==="GlorotNormal")return new Ii;if(t==="GlorotUniform")return new ki;if(t==="HeNormal")return new xi;if(t==="HeUniform")return new Si;if(t==="LeCunNormal")return new vi;if(t==="LeCunUniform")return new Ni;{const e={};return e.className=t,e.config={},fl(e)}}else return s instanceof ce?s:fl(s)}function sa(s){return Array.isArray(s)&&Array.isArray(s[0])}function Un(s){return s.length===0?[]:Array.isArray(s[0])?s:[s]}function nt(s){let t;if(Array.isArray(s)){if(s.length!==1)throw new x(`Expected Tensor length to be 1; got ${s.length}`);t=s[0]}else t=s;return t}function dt(s){if(Array.isArray(s)&&Array.isArray(s[0])){if(s.length===1)return s=s,s[0];throw new x(`Expected exactly 1 Shape; got ${s.length}`)}else return s}function jn(s){let t=0;for(const e of s)e.shape.length===0?t+=1:t+=e.shape.reduce((n,i)=>n*i);return t}const ml="Variable";class ek{constructor(t,e="float32",n=ml,i=!0,a=null){this.dtype=e??"float32",this.shape=t.shape,this.id=Vu(),n=n??ml,this.originalName=Pu(n),this.name=Gu(this.originalName),this.trainable_=i,this.constraint=a,this.val=vm(t,this.trainable_,this.name,this.dtype)}read(){return this.assertNotDisposed(),this.val}write(t){return this.assertNotDisposed(),sk(this.val,t),this.val.id!==t.id&&(this.val.assign(t),this.constraint!=null&&this.val.assign(this.constraint.apply(this.val))),this}dispose(){this.assertNotDisposed(),this.val.dispose()}assertNotDisposed(){if(this.val.isDisposed)throw new Error(`LayersVariable ${this.name} is already disposed.`)}get trainable(){return this.trainable_}set trainable(t){this.trainable_=t,this.val.trainable=t}}function sk(s,t){if(s.shape.toString()!==t.shape.toString())throw new Error("Shape mismatch: "+JSON.stringify(s.shape)+" vs. "+JSON.stringify(t.shape))}function na(s){return s.map(t=>t.read())}function vo(s){s.forEach(t=>{t[0].write(t[1])})}class Mt{constructor(t){this.dtype=t.dtype,this.shape=t.shape,t.shape!=null?this.ndim=t.shape.length:this.ndim=t.ndim,this.maxNDim=t.maxNDim,this.minNDim=t.minNDim,this.axes=t.axes||{}}}class ze{constructor(t,e,n,i,a,o,r){this.dtype=t,this.shape=e,this.sourceLayer=n,this.inputs=i,this.callArgs=a,this.outputTensorIndex=r,this.id=Vu(),o!=null&&(this.originalName=Pu(o),this.name=Gu(this.originalName)),this.rank=e.length}}let nk=0;class Ci{constructor(t,e){this.callArgs=e,this.id=nk++,this.outboundLayer=t.outboundLayer,this.inboundLayers=t.inboundLayers,this.nodeIndices=t.nodeIndices,this.tensorIndices=t.tensorIndices,this.inputTensors=t.inputTensors,this.outputTensors=t.outputTensors,this.inputMasks=t.inputMasks,this.outputMasks=t.outputMasks,this.inputShapes=t.inputShapes,this.outputShapes=t.outputShapes;for(const n of t.inboundLayers)n?.outboundNodes.push(this);t.outboundLayer.inboundNodes.push(this)}getConfig(){const t=[];for(const e of this.inboundLayers)e!=null?t.push(e.name):t.push(null);return{outboundLayer:this.outboundLayer?this.outboundLayer.name:null,inboundLayers:t,nodeIndices:this.nodeIndices,tensorIndices:this.tensorIndices}}}let ik=0;class rt extends wn{constructor(t={}){super(),this._callHook=null,this._addedWeightNames=[],this._stateful=!1,this.id=ik++,this.activityRegularizer=null,this.inputSpec=null,this.supportsMasking=!1,this._trainableWeights=[],this._nonTrainableWeights=[],this._losses=[],this._updates=[],this._built=!1,this.inboundNodes=[],this.outboundNodes=[];let e=t.name;if(!e){const n=this.getClassName();e=Ee(n)+"_"+bi(n)}if(this.name=e,this.trainable_=t.trainable==null?!0:t.trainable,t.inputShape!=null||t.batchInputShape!=null){let n;if(t.batchInputShape!=null)n=t.batchInputShape;else if(t.inputShape!=null){let a=null;t.batchSize!=null&&(a=t.batchSize),n=[a].concat(t.inputShape)}this.batchInputShape=n;let i=t.dtype;i==null&&(i=t.inputDType),i==null&&(i="float32"),this.dtype=i}t.weights!=null?this.initialWeights=t.weights:this.initialWeights=null,this._refCount=null,this.fastWeightInitDuringBuild=!1}static nodeKey(t,e){return t.name+"_ib-"+e.toString()}getNodeAtIndex(t,e){if(this.inboundNodes.length===0)throw new ie(`The layer has never been called and thus has no defined ${e}.`);if(this.inboundNodes.length<=t)throw new x(`Asked to get ${e} at node ${t}, but the layer has only ${this.inboundNodes.length} inbound nodes.`);return this.inboundNodes[t]}getInputAt(t){return jt(this.getNodeAtIndex(t,"input").inputTensors)}getOutputAt(t){return jt(this.getNodeAtIndex(t,"output").outputTensors)}get input(){if(this.inboundNodes.length>1)throw new xe(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer input" is ill-defined. Use \`getInputAt(nodeIndex)\` instead.`);if(this.inboundNodes.length===0)throw new xe(`Layer ${this.name} is not connected, no input to return.`);return jt(this.getNodeAtIndex(0,"input").inputTensors)}get output(){if(this.inboundNodes.length===0)throw new xe(`Layer ${this.name} has no inbound nodes.`);if(this.inboundNodes.length>1)throw new xe(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer output" is ill-defined. Use \`getOutputAt(nodeIndex)\` instead.`);return jt(this.getNodeAtIndex(0,"output").outputTensors)}get losses(){return this._losses}calculateLosses(){return this.losses.map(t=>t())}get updates(){return this._updates}get built(){return this._built}set built(t){this._built=t}get trainable(){return this.trainable_}set trainable(t){this._trainableWeights.forEach(e=>e.trainable=t),this.trainable_=t}get trainableWeights(){return this.trainable_?this._trainableWeights.filter(t=>t.trainable):[]}set trainableWeights(t){this._trainableWeights=t}get nonTrainableWeights(){return this.trainable?this._trainableWeights.filter(t=>!t.trainable).concat(this._nonTrainableWeights):this._trainableWeights.concat(this._nonTrainableWeights)}set nonTrainableWeights(t){this._nonTrainableWeights=t}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}get stateful(){return this._stateful}resetStates(){if(!this.stateful)throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.")}assertInputCompatibility(t){const e=mt(t);if(this.inputSpec==null||this.inputSpec.length===0)return;const n=mt(this.inputSpec);if(e.length!==n.length)throw new x(`Layer ${this.name} expects ${n.length} inputs, but it received ${e.length} input tensors. Input received: ${t}`);for(let i=0;i<e.length;i++){const a=e[i],o=n[i];if(o==null)continue;const r=a.rank;if(o.ndim!=null&&r!==o.ndim)throw new x(`Input ${i} is incompatible with layer ${this.name}: expected ndim=${o.ndim}, found ndim=${r}`);if(o.maxNDim!=null&&r>o.maxNDim)throw new x(`Input ${i} is incompatible with layer ${this.name}: expected max_ndim=${o.maxNDim}, found ndim=${r}`);if(o.minNDim!=null&&r<o.minNDim)throw new x(`Input ${i} is incompatible with layer ${this.name}: expected min_ndim=${o.minNDim}, found ndim=${r}.`);if(o.dtype!=null&&a.dtype!==o.dtype)throw new x(`Input ${i} is incompatible with layer ${this.name} : expected dtype=${o.dtype}, found dtype=${a.dtype}.`);if(o.axes){const l=a.shape;for(const c in o.axes){const u=Number(c),d=o.axes[c],h=u>=0?l[u]:l[l.length+u];if(d!=null&&[d,null].indexOf(h)===-1)throw new x(`Input ${i} is incompatible with layer ${this.name}: expected axis ${u} of input shape to have value ${d} but got shape ${l}.`)}}if(o.shape!=null)for(let l=0;l<o.shape.length;++l){const c=o.shape[l],u=a.shape[l];if(c!=null&&u!=null&&c!==u)throw new x(`Input ${i} is incompatible with layer ${this.name}: expected shape=${o.shape}, found shape=${a.shape}.`)}}}call(t,e){return t}invokeCallHook(t,e){this._callHook!=null&&this._callHook(t,e)}setCallHook(t){this._callHook=t}clearCallHook(){this._callHook=null}apply(t,e){e=e||{},this.assertNotDisposed();const n=mt(t),i=rk(t),a=lk(t);if(i===a)throw new x("Arguments to apply() must be all SymbolicTensors or all Tensors");return ds(this.name,()=>{if(!this.built){this.assertInputCompatibility(t);const o=[];for(const r of mt(t))o.push(r.shape);this.build(jt(o)),this.built=!0,this.initialWeights&&this.setWeights(this.initialWeights),this._refCount===null&&a&&(this._refCount=1)}if(this.assertInputCompatibility(t),a){let o=this.call(t,e);this.supportsMasking&&this.setMaskMetadata(t,o);const r=mt(o),l=[];for(let c of r)n.indexOf(c)!==-1&&(c=c.clone()),l.push(c);if(o=jt(l),this.activityRegularizer!=null)throw new it("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return o}else{const o=ak(t),r=this.computeOutputShape(o);let l;const c=ok(t);if(this.warnOnIncompatibleInputShape(Array.isArray(t)?o[0]:o),r!=null&&r.length>0&&Array.isArray(r[0])?l=r.map((u,d)=>new ze(c,u,this,mt(t),e,this.name,d)):l=new ze(c,r,this,mt(t),e,this.name),this.addInboundNode(t,l,null,null,o,r,e),this._refCount++,this.activityRegularizer!=null)throw new it("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return l}})}warnOnIncompatibleInputShape(t){if(this.batchInputShape!=null)if(t.length!==this.batchInputShape.length)console.warn(`The rank of the input tensor provided (shape: ${JSON.stringify(t)}) does not match that of the batchInputShape (${JSON.stringify(this.batchInputShape)}) of the layer ${this.name}`);else{let e=!1;this.batchInputShape.forEach((n,i)=>{n!=null&&t[i]!=null&&t[i]!==n&&(e=!0)}),e&&console.warn(`The shape of the input tensor (${JSON.stringify(t)}) does not match the expectation of layer ${this.name}: ${JSON.stringify(this.batchInputShape)}`)}}get outputShape(){if(this.inboundNodes==null||this.inboundNodes.length===0)throw new xe(`The layer ${this.name} has never been called and thus has no defined output shape.`);const t=[];for(const e of this.inboundNodes){const n=JSON.stringify(e.outputShapes);t.indexOf(n)===-1&&t.push(n)}if(t.length===1){const e=this.inboundNodes[0].outputShapes;return Array.isArray(e)&&Array.isArray(e[0])&&e.length===1?e[0]:e}else throw new xe(`The layer ${this.name} has multiple inbound nodes with different output shapes. Hence the notion of "output shape" is ill-defined for the layer.`)}countParams(){if(!this.built)throw new ie(`You tried to call countParams() on ${this.name}, but the layer is not built yet. Build it first by calling build(batchInputShape).`);return jn(this.weights)}build(t){this.built=!0}getWeights(t=!1){return na(t?this.trainableWeights:this.weights)}setWeights(t){T(()=>{const e=this.weights;if(e.length!==t.length)throw new x(`You called setWeights(weights) on layer "${this.name}" with a weight list of length ${t.length}, but the layer was expecting ${e.length} weights. Provided weights: ${t}...`);if(e.length===0)return;const n=[],i=na(e);for(let a=0;a<i.length;++a){const o=i[a],r=e[a],l=t[a];if(!Jt(o.shape,l.shape))throw new x(`Layer weight shape ${o.shape} not compatible with provided weight shape ${l.shape}`);n.push([r,l])}vo(n)})}addWeight(t,e,n,i,a,o,r,l){if(this._addedWeightNames.indexOf(t)!==-1)throw new x(`Duplicate weight name ${t} for layer ${this.name}`);this._addedWeightNames.push(t),n==null&&(n="float32"),this.fastWeightInitDuringBuild&&(i=l!=null?l():vt("zeros"));const c=i.apply(e,n),u=new ek(c,n,t,o,r);return c.dispose(),a!=null&&this.addLoss(()=>a.apply(u.read())),o==null&&(o=!0),o?this._trainableWeights.push(u):this._nonTrainableWeights.push(u),u}setFastWeightInitDuringBuild(t){this.fastWeightInitDuringBuild=t}addLoss(t){t==null||Array.isArray(t)&&t.length===0||(t=mt(t),this._losses!==void 0&&this._losses!==null&&this.losses.push(...t))}computeOutputShape(t){return t}computeMask(t,e){if(!this.supportsMasking){if(e!=null)if(Array.isArray(e))e.forEach(n=>{if(n!=null)throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`)});else throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);return null}return e}setMaskMetadata(t,e,n){if(!this.supportsMasking)return;const i=this.computeMask(t,n),a=mt(e),o=mt(i);if(a.length!==o.length)throw new Error(`${this.name} outputs ${a.length} tensors but ${a.length} masks for those tensors`);for(let r=0;r<a.length;r++)a[r].kerasMask=o[r]}addInboundNode(t,e,n,i,a,o,r=null){const l=mt(t);e=mt(e),n=mt(n),i=mt(i),a=Un(a),o=Un(o);const c=[],u=[],d=[];for(const h of l)c.push(h.sourceLayer),u.push(h.nodeIndex),d.push(h.tensorIndex);new Ci({outboundLayer:this,inboundLayers:c,nodeIndices:u,tensorIndices:d,inputTensors:l,outputTensors:e,inputMasks:n,outputMasks:i,inputShapes:a,outputShapes:o},r);for(let h=0;h<e.length;h++)e[h].sourceLayer=this,e[h].nodeIndex=this.inboundNodes.length-1,e[h].tensorIndex=h}getConfig(){const t={name:this.name,trainable:this.trainable};return this.batchInputShape!=null&&(t.batchInputShape=this.batchInputShape),this.dtype!=null&&(t.dtype=this.dtype),t}disposeWeights(){return this.weights.forEach(t=>t.dispose()),this.weights.length}assertNotDisposed(){if(this._refCount===0)throw new Error(`Layer '${this.name}' is already disposed.`)}dispose(){if(!this.built)throw new Error(`Cannot dispose Layer ${this.name} because it has not been built yet.`);if(this._refCount===null)throw new Error(`Cannot dispose Layer ${this.name} because it has not been used yet.`);this.assertNotDisposed();let t=0;return--this._refCount===0&&(t=this.disposeWeights()),{refCountAfterDispose:this._refCount,numDisposedVariables:t}}}function ak(s){s=mt(s);const t=[];for(const e of s)t.push(e.shape);return jt(t)}function ok(s){return"float32"}function qu(s,t,e){if((t==null||e!=null&&e>0)&&(t=s.sourceLayer,e=s.nodeIndex),t.inboundNodes.length===0)return[s];{const n=t.inboundNodes[e];if(n.inboundLayers.length===0)return n.inputTensors;{const i=[];for(let a=0;a<n.inboundLayers.length;a++){const o=n.inputTensors[a],r=n.inboundLayers[a],l=n.nodeIndices[a],c=qu(o,r,l);for(const u of c)i.indexOf(u)===-1&&i.push(u)}return i}}}function rk(s){let t=!0;for(const e of mt(s))if(!(e instanceof ze)){t=!1;break}return t}function lk(s){let t=!0;for(const e of mt(s))if(e instanceof ze){t=!1;break}return t}class qs extends rt{constructor(t){if(super({dtype:t.dtype,name:t.name!=null?t.name:bi("input").toString()}),t.batchSize==null&&(t.batchSize=null),t.sparse==null&&(t.sparse=!1),this.trainable=!1,this.built=!0,this.sparse=t.sparse,t.inputShape!=null&&t.batchInputShape!=null)throw new x("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");let e=t.batchInputShape;if(e==null){if(t.inputShape==null)throw new x("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");e=[t.batchSize].concat(t.inputShape)}else if(t.batchSize!=null)throw new x("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");const n=t.dtype||"float32";this.batchInputShape=e,this.dtype=n,this.inputSpec=[{shape:e}];const i=new ze(this.dtype,this.batchInputShape,this,[],{},this.name);i.nodeIndex=0,i.tensorIndex=0,new Ci({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:[i],outputTensors:[i],inputMasks:[null],outputMasks:[null],inputShapes:[e],outputShapes:[e]})}apply(t,e){throw new x(`Cannot pass any input to an InputLayer's apply() method. InputLayer name: ${this.name}`)}dispose(){return{refCountAfterDispose:this._refCount,numDisposedVariables:0}}getConfig(){return{batchInputShape:this.batchInputShape,dtype:this.dtype,sparse:this.sparse,name:this.name}}}qs.className="InputLayer";O(qs);function Ku(s){if(s.batchShape==null&&s.shape==null)throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");if(s.batchShape!=null&&s.shape!=null)throw new x("Please provide either a `shape` or `batchShape` argument to Input, but not both.");let t=s.batchShape;s.shape!=null&&t==null&&(t=[null].concat(s.shape));let e=s.dtype;return e==null&&(e="float32"),new qs({batchInputShape:t,name:s.name,dtype:e,sparse:s.sparse}).inboundNodes[0].outputTensors[0]}function ck(s,t){if(s.dtype==null||s.dtype===t.dtype)return t;try{return J(t,s.dtype)}catch{throw new x(`The dtype of the feed (${t.dtype}) can not be cast to the dtype of the key '${s.name}' (${s.dtype}).`)}}class Ze{constructor(t){if(this.id2Value={},this.id2Mask={},this.name2Id={},t instanceof Ze)for(const e in t.id2Value)this.id2Value[e]=t.id2Value[e],e in t.id2Mask&&(this.id2Mask[e]=t.id2Mask[e]);else{if(t==null)return;for(const e of t)this.add(e.key,e.value)}}add(t,e,n){if(this.id2Value[t.id]==null)this.id2Value[t.id]=ck(t,e),this.name2Id[t.name]=t.id,n!=null&&(this.id2Mask[t.id]=n);else throw new x(`Duplicate key: name=${t.name}, id=${t.id}`);return this}addFeed(t){this.add(t.key,t.value)}hasKey(t){return this.id2Value[t.id]!=null}names(){return Object.keys(this.name2Id)}getValue(t){if(t instanceof ze){if(this.id2Value[t.id]==null)throw new x(`Nonexistent key: ${t.name}`);return this.id2Value[t.id]}else{const e=this.name2Id[t];if(e==null)throw new x(`Feed dict has no SymbolicTensor name: ${t}`);return this.id2Value[e]}}getMask(t){if(t instanceof ze){if(this.id2Value[t.id]==null)throw new x(`Nonexistent key: ${t.name}`);return this.id2Mask[t.id]}else{const e=this.name2Id[t];if(e==null)throw new x(`Feed dict has no SymbolicTensor name: ${t}`);return this.id2Mask[e]}}disposeMasks(){this.id2Mask!=null&&gt(this.id2Mask)}}const qn=new Ou,Kn=new Ou;function uk(s){qn?.setMaxEntries(s),Kn?.setMaxEntries(s)}function an(s,t,e,n){const i=e==null?!1:e.training,a=Array.isArray(s),o=a?s:[s],r=o.map(m=>m.name),l=[],c=t.names();for(const m of r)c.indexOf(m)!==-1?l.push(t.getValue(m)):l.push(null);const u=r.join(",")+"|"+t.names().sort().join(",");let d=qn.get(u),h;if(d==null){const m=hk(o,t);d=m.sorted,h=m.recipientCounts,qn.put(u,d),Kn.put(u,h)}h={},i||Object.assign(h,Kn.get(u));const p=new Ze(t);for(let m=0;m<d.length;++m){const f=d[m],g=f.sourceLayer;if(g instanceof qs)continue;const w=[],b=[],k=[];let y=!1;for(const C of f.inputs){const D=p.getValue(C),E=p.getMask(C);w.push(D),b.push(E),E!=null&&(y=!0),i||(h[C.name]--,h[C.name]===0&&!t.hasKey(C)&&r.indexOf(C.name)===-1&&!D.isDisposed&&C.sourceLayer.stateful!==!0&&k.push(D))}y&&(e=e||{},e.mask=b[0]);const I=mt(g.apply(w,e));let S=null;g.supportsMasking&&(S=g.computeMask(w,b));const v=pk(f),N=Array.isArray(v)?v:[v];for(let C=0;C<N.length;++C){p.hasKey(N[C])||p.add(N[C],I[C],Array.isArray(S)?S[0]:S);const D=r.indexOf(N[C].name);D!==-1&&(l[D]=I[C])}i||gt(k)}return p.disposeMasks(),a?l:l[0]}function hk(s,t){K(s!=null&&s.length>0,()=>"Expected at least one fetch, got none");let e=[],n={};if(s.length===1){const i=gl(s[0],t);e=i.sorted,n=i.recipientMap}else{const i=new Set;for(const a of s){const{sorted:o,recipientMap:r}=gl(a,t);for(const l of o)i.has(l.name)||(e.push(l),i.add(l.name));for(const l in r)n[l]==null&&(n[l]=new Set),r[l].forEach(c=>n[l].add(c))}}return{sorted:e,recipientCounts:dk(n)}}function dk(s){const t={};for(const e in s)t[e]=s[e].size;return t}function gl(s,t){const e=new Set,n=[],i={};for(const r of t.names())e.add(r);const a=[],o=[];for(a.push(s);a.length>0;){const r=a[a.length-1];if(e.has(r.name)){a.pop();continue}const l=o[o.length-1]===a.length-1;if(r.inputs.length===0||l)a.pop(),n.push(r),e.add(r.name),l&&o.pop();else{o.push(a.length-1);for(const c of r.inputs)i[c.name]==null&&(i[c.name]=new Set),i[c.name].add(r.name),!e.has(c.name)&&a.push(c)}}return{sorted:n,recipientMap:i}}function pk(s){let t;if(s.sourceLayer.inboundNodes.length===1)t=s.sourceLayer.output;else{let e=null;for(let n=0;n<s.sourceLayer.inboundNodes.length;++n)for(const i of s.sourceLayer.inboundNodes[n].outputTensors)if(i.id===s.id){e=n;break}t=s.sourceLayer.getOutputAt(e)}return t}const fk=We();fk.registerFlag("TOPOLOGICAL_SORT_CACHE_MAX_ENTRIES",()=>100,uk);function No(s,t){return T(()=>Be(lt(A(s,s),t,!0)))}class Tn extends wn{getConfig(){return{}}}class Co extends Tn{constructor(t){super(),this.defaultMaxValue=2,this.defaultAxis=0,this.maxValue=t.maxValue!=null?t.maxValue:this.defaultMaxValue,this.axis=t.axis!=null?t.axis:this.defaultAxis}apply(t){return T(()=>{const e=No(t,this.axis),n=te(e,0,this.maxValue);return A(t,ut(n,X($t(),e)))})}getConfig(){return{maxValue:this.maxValue,axis:this.axis}}}Co.className="MaxNorm";O(Co);class To extends Tn{constructor(t){super(),this.defaultAxis=0,this.axis=t.axis!=null?t.axis:this.defaultAxis}apply(t){return T(()=>ut(t,X($t(),No(t,this.axis))))}getConfig(){return{axis:this.axis}}}To.className="UnitNorm";O(To);class Ao extends Tn{apply(t){return Ps(t)}}Ao.className="NonNeg";O(Ao);class Do extends Tn{constructor(t){super(),this.defaultMinValue=0,this.defaultMaxValue=1,this.defaultRate=1,this.defaultAxis=0,this.minValue=t.minValue!=null?t.minValue:this.defaultMinValue,this.maxValue=t.maxValue!=null?t.maxValue:this.defaultMaxValue,this.rate=t.rate!=null?t.rate:this.defaultRate,this.axis=t.axis!=null?t.axis:this.defaultAxis}apply(t){return T(()=>{const e=No(t,this.axis),n=X(A(this.rate,te(e,this.minValue,this.maxValue)),A(1-this.rate,e));return A(t,ut(n,X($t(),e)))})}getConfig(){return{minValue:this.minValue,maxValue:this.maxValue,rate:this.rate,axis:this.axis}}}Do.className="MinMaxNorm";O(Do);const bl={maxNorm:"MaxNorm",minMaxNorm:"MinMaxNorm",nonNeg:"NonNeg",unitNorm:"UnitNorm"};function Rt(s){return fo(s)}function yl(s,t={}){return Sn(s,kn.getMap().classNameMap,t,"constraint")}function Et(s){if(s==null)return null;if(typeof s=="string"){const e={className:s in bl?bl[s]:s,config:{}};return yl(e)}else return s instanceof Tn?s:yl(s)}function mk(s){return new Co(s)}function gk(s){return new To(s)}function bk(){return new Ao}function yk(s){return new Do(s)}const BT=Object.freeze(Object.defineProperty({__proto__:null,maxNorm:mk,minMaxNorm:yk,nonNeg:bk,unitNorm:gk},Symbol.toStringTag,{value:"Module"}));function wk(){return new bo}function kk(){return new wi}function Ik(s){return new yo(s)}function xk(s){return new wo(s)}function Sk(s){return new ko(s)}function vk(s){return new Io(s)}function Nk(s){return new xo(s)}function Ck(s){return new qt(s)}function Tk(s){return new ki(s)}function Ak(s){return new Ii(s)}function Dk(s){return new xi(s)}function zk(s){return new Si(s)}function Fk(s){return new vi(s)}function $k(s){return new Ni(s)}function Mk(s){return new So(s)}const PT=Object.freeze(Object.defineProperty({__proto__:null,constant:Ik,glorotNormal:Ak,glorotUniform:Tk,heNormal:Dk,heUniform:zk,identity:Nk,leCunNormal:Fk,leCunUniform:$k,ones:kk,orthogonal:Mk,randomNormal:Sk,randomUniform:xk,truncatedNormal:vk,varianceScaling:Ck,zeros:wk},Symbol.toStringTag,{value:"Module"}));async function Ke(s){if(s==null)return;const t=[],e=[],n=[];for(const i in s){const a=s[i];if(typeof a!="number"){const o=a;t.push(o.data()),e.push(i),n.push(o)}}if(t.length>0){const i=await Promise.all(t);for(let a=0;a<i.length;++a)s[e[a]]=i[a][0];gt(n)}}function Zu(s){if(s!=null)for(const t in s){const e=s[t];typeof e!="number"&&e.dispose()}}var wl;(function(s){s[s.SILENT=0]="SILENT",s[s.VERBOSE=1]="VERBOSE"})(wl||(wl={}));const Rk=125;class Os{constructor(){this.validationData=null}setParams(t){this.params=t}async onEpochBegin(t,e){}async onEpochEnd(t,e){}async onBatchBegin(t,e){}async onBatchEnd(t,e){}async onTrainBegin(t){}async onTrainEnd(t){}setModel(t){}}class Ek{constructor(t,e=10){t==null&&(t=[]),this.callbacks=t,this.queueLength=e}append(t){this.callbacks.push(t)}setParams(t){for(const e of this.callbacks)e.setParams(t)}setModel(t){for(const e of this.callbacks)e.setModel(t)}async onEpochBegin(t,e){e==null&&(e={});for(const n of this.callbacks)await n.onEpochBegin(t,e)}async onEpochEnd(t,e){e==null&&(e={});for(const n of this.callbacks)await n.onEpochEnd(t,e)}async onBatchBegin(t,e){e==null&&(e={});for(const n of this.callbacks)await n.onBatchBegin(t,e)}async onBatchEnd(t,e){e==null&&(e={});for(const n of this.callbacks)await n.onBatchEnd(t,e)}async onTrainBegin(t){t==null&&(t={});for(const e of this.callbacks)await e.onTrainBegin(t)}async onTrainEnd(t){t==null&&(t={});for(const e of this.callbacks)await e.onTrainEnd(t)}}class Lk extends Os{constructor(){super()}async onEpochBegin(t){this.seen=0,this.totals={}}async onBatchEnd(t,e){e==null&&(e={});const n=e.size==null?0:e.size;this.seen+=n;for(const i in e){const a=e[i];if(typeof a=="number")this.totals.hasOwnProperty(i)||(this.totals[i]=0),this.totals[i]=this.totals[i]+a*n;else{let o;i in this.totals?o=this.totals[i]:this.totals[i]=0;const r=T(()=>X(this.totals[i],A(a,n)));this.totals[i]=r,o?.dispose()}}}async onEpochEnd(t,e){if(e!=null)for(const n of this.params.metrics)this.totals[n]!=null&&(typeof this.totals[n]=="number"?e[n]=this.totals[n]/this.seen:T(()=>{const i=A(ut(1,this.seen),this.totals[n]);e[n]=i,this.totals[n].dispose(),Oe(e[n])}))}}class Ok extends Os{async onTrainBegin(t){this.epoch=[],this.history={}}async onEpochEnd(t,e){e==null&&(e={}),this.epoch.push(t);for(const n in e)this.history[n]==null&&(this.history[n]=[]),this.history[n].push(e[n])}async syncData(){const t=[],e=[],n=[];for(const a in this.history){const o=this.history[a];for(let r=0;r<o.length;++r)if(typeof o[r]!="number"){const l=o[r];t.push(l.data()),e.push(a),n.push(r)}}const i=await Promise.all(t);for(let a=0;a<i.length;++a)this.history[e[a]][n[a]].dispose(),this.history[e[a]][n[a]]=i[a][0]}}class _k extends Os{constructor(t,e){if(super(),this.currentEpoch=0,this.nowFunc=t.nowFunc,this.nextFrameFunc=t.nextFrameFunc||_m,this.yieldEvery=e||"auto",this.yieldEvery==="auto"&&(this.yieldEvery=Rk),this.yieldEvery==="never"&&t.onYield!=null)throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");Xr(this.yieldEvery)&&(this.maybeWait=Mw(this.maybeWait.bind(this),this.yieldEvery,this.nowFunc)),this.trainBegin=t.onTrainBegin,this.trainEnd=t.onTrainEnd,this.epochBegin=t.onEpochBegin,this.epochEnd=t.onEpochEnd,this.batchBegin=t.onBatchBegin,this.batchEnd=t.onBatchEnd,this.yield=t.onYield}async maybeWait(t,e,n){const i=[];this.yield!=null&&(await Ke(n),i.push(this.yield(t,e,n))),i.push(this.nextFrameFunc()),await Promise.all(i)}async onEpochBegin(t,e){this.currentEpoch=t,this.epochBegin!=null&&(await Ke(e),await this.epochBegin(t,e))}async onEpochEnd(t,e){const n=[];this.epochEnd!=null&&(await Ke(e),n.push(this.epochEnd(t,e))),this.yieldEvery==="epoch"&&n.push(this.nextFrameFunc()),await Promise.all(n)}async onBatchBegin(t,e){this.batchBegin!=null&&(await Ke(e),await this.batchBegin(t,e))}async onBatchEnd(t,e){const n=[];this.batchEnd!=null&&(await Ke(e),n.push(this.batchEnd(t,e))),this.yieldEvery==="batch"?n.push(this.nextFrameFunc()):Xr(this.yieldEvery)&&n.push(this.maybeWait(this.currentEpoch,t,e)),await Promise.all(n)}async onTrainBegin(t){this.trainBegin!=null&&(await Ke(t),await this.trainBegin(t))}async onTrainEnd(t){this.trainEnd!=null&&(await Ke(t),await this.trainEnd(t))}}function Ju(s,t){return s==null&&(s={}),s instanceof Os?[s]:Array.isArray(s)&&s[0]instanceof Os?s:mt(s).map(n=>new _k(n,t))}class Yt{constructor(){}static registerCallbackConstructor(t,e){K(t>=0&&Number.isInteger(t),()=>`Verbosity level is expected to be an integer >= 0, but got ${t}`),Yt.checkForDuplicate(e),Yt.constructors[t]==null&&(Yt.constructors[t]=[]),Yt.constructors[t].push(e)}static checkForDuplicate(t){for(const e in Yt.constructors)Yt.constructors[+e].forEach(i=>{if(i===t)throw new x("Duplicate callback constructor.")})}static clear(){Yt.constructors={}}static createCallbacks(t){const e=[];for(const n in Yt.constructors){const i=+n;t>=i&&e.push(...Yt.constructors[i])}return e.map(n=>new n)}}Yt.constructors={};function Xu(s,t,e,n,i,a,o,r,l){const c=new Ok,u=[new Lk,...Yt.createCallbacks(t)];s!=null&&u.push(...s),u.push(c);const d=new Ek(u);return d.setParams({epochs:e,initialEpoch:n,samples:i,steps:a,batchSize:o,verbose:t,doValidation:r,metrics:l}),{callbackList:d,history:c}}function fe(s,t={},e=!1){return Sn(s,kn.getMap().classNameMap,t,"layer",e)}function Zn(s,t){return T(()=>{s.dtype!=="float32"&&(s=J(s,"float32"));const e=lt(Nn(s),t,!0),n=rp(e.shape,$t()),i=Be(bs(e,n));return ut(s,i)})}function Ns(s,t){return T(()=>Ot(Nn(pt(t,s)),-1))}function Ti(s,t){return T(()=>Ot(fs(pt(t,s)),-1))}function Ks(s,t){return T(()=>{const e=pt(s,t),n=te(fs(s),$t(),Number.MAX_VALUE),i=fs(ut(e,n));return A(100,Ot(i,-1))})}function Wk(s,t){return T(()=>{const e=te(t,$t(),Number.MAX_VALUE),n=ss(X(1,e)),i=te(s,$t(),Number.MAX_VALUE),a=ss(X(1,i));return Ot(Nn(pt(n,a)),-1)})}function Vk(s,t){return T(()=>{const e=bs(0,pt(1,A(s,t)));return Ot(Nn(e),-1)})}function Bk(s,t){return T(()=>{const e=bs(0,pt(1,A(s,t)));return Ot(e,-1)})}function Pk(s,t){return T(()=>{const e=lt(A(s,t),-1),n=Rs(A(pt(1,s),t),-1);return bs(0,X(1,pt(n,e)))})}function Gk(s,t){return T(()=>{const e=Math.log(2),n=pt(t,s),i=pt(X(n,di(A(-2,n))),e);return Ot(i,-1)})}function mn(s,t,e=!1){return T(()=>{if(e)t=no(t);else{const n=lt(t,t.shape.length-1,!0);t=ut(t,n)}return t=te(t,$t(),1-$t()),Ut(lt(A(J(s,"float32"),ss(t)),t.shape.length-1))})}function Jn(s,t,e=!1){return T(()=>{const n=J(Ya(Uw(s)),"int32");t=te(t,$t(),1-$t());const i=t.shape,a=B(Bn(n,i[i.length-1]),i);return mn(a,t,e)})}function Hk(s,t){if(!Jt(s.shape,t.shape))throw new x(`logits and labels must have the same shape, but got shapes ${JSON.stringify(s.shape)} and ${JSON.stringify(t.shape)}`);return T(()=>{const e=Ps(t),n=Ut(fs(t));return X(pt(e,A(t,s)),bu(ks(n)))})}function Ai(s,t){return T(()=>{let e;return e=te(t,$t(),1-$t()),e=ss(ut(e,pt(1,e))),Ot(Hk(s,e),-1)})}function Uk(s,t){return T(()=>{const e=te(s,$t(),1),n=te(t,$t(),1);return lt(A(s,ss(ut(e,n))),-1)})}function jk(s,t){return T(()=>{const e=ss(X($t(),t));return Ot(pt(t,A(s,e)),-1)})}function zo(s,t){return T(()=>{const e=Zn(s,-1),n=Zn(t,-1),i=A(e,n);return Ut(lt(i,-1))})}const Xn={meanSquaredError:Ns,meanAbsoluteError:Ti,meanAbsolutePercentageError:Ks,meanSquaredLogarithmicError:Wk,squaredHinge:Vk,hinge:Bk,categoricalHinge:Pk,logcosh:Gk,categoricalCrossentropy:mn,sparseCategoricalCrossentropy:Jn,binaryCrossentropy:Ai,kullbackLeiblerDivergence:Uk,poisson:jk,cosineProximity:zo};function Gi(s){if(typeof s=="string"){if(s in Xn)return Xn[s];let t=`Unknown loss ${s}`;throw s.toLowerCase().includes("softmaxcrossentropy")&&(t=`Unknown loss ${s}. Use "categoricalCrossentropy" as the string name for tf.losses.softmaxCrossEntropy`),new x(t)}else return s}function Fo(s,t){return T(()=>{const e=A(.5,le(t)),n=Te(ke(t,e),s.dtype);return Ot(ge(s,n),-1)})}function $o(s,t){return T(()=>Te(ge(hn(s,-1),hn(t,-1)),"float32"))}function Yu(s,t){return T(()=>J(lt(ws(ge(s,1),ge(t,1))),"float32"))}function qk(s,t){return T(()=>J(lt(ws(ge(s,1),ge(t,0))),"float32"))}function Kk(s,t){return T(()=>J(lt(ws(ge(s,0),ge(t,1))),"float32"))}function Qu(s,t){return T(()=>{const e=Yu(s,t),n=Kk(s,t),i=X(e,n);return J(De(ke(i,0),ut(e,i),0),"float32")})}function Zk(s,t){return T(()=>{const e=Yu(s,t),n=qk(s,t),i=X(e,n);return J(De(ke(i,0),ut(e,i),0),"float32")})}function th(s,t){return Ai(s,t)}function eh(s,t){return s.rank===t.rank&&(s=pi(s,[s.rank-1])),t=hn(t,-1),t.dtype!==s.dtype&&(t=J(t,s.dtype)),J(ge(s,t),"float32")}function Jk(s,t){return T(()=>{const e=s.sub(t).square().sum(),n=s.sub(s.mean()).square().sum();return zt(1).sub(e.div(n))})}const Xk=Ns,Yk=Ns,Qk=Ti,tI=Ti,eI=Ks,sI=Ks,Mo=mn,nI=zo,sh=Jn,Yn={binaryAccuracy:Fo,categoricalAccuracy:$o,precision:Qu,categoricalCrossentropy:Mo,sparseCategoricalCrossentropy:sh,mse:Xk,MSE:Yk,mae:Qk,MAE:tI,mape:eI,MAPE:sI,cosine:nI};function iI(s){if(typeof s=="string"&&s in Yn)return Yn[s];if(typeof s!="string"&&s!=null)return s;throw new x(`Unknown metric ${s}`)}function On(s){if(Se(s!==null,`Unknown LossOrMetricFn ${s}`),typeof s=="string")return s;{let t;for(const e of Object.keys(Xn))if(Xn[e]===s){t=e;break}if(t!==void 0)return t;for(const e of Object.keys(Yn))if(Yn[e]===s){t=e;break}return t!==void 0?t:s.name}}function aI(s){const t={Adagrad:()=>Ts.adagrad(.01),Adadelta:()=>Ts.adadelta(1,.95,$t()),Adam:()=>Ts.adam(.001,.9,.999,$t()),Adamax:()=>Ts.adamax(.002,.9,.999,$t(),0),RMSProp:()=>Ts.rmsprop(.001,.9,0,$t()),SGD:()=>Ts.sgd(.01)};if(t.adagrad=t.Adagrad,t.adadelta=t.Adadelta,t.adam=t.Adam,t.adamax=t.Adamax,t.rmsprop=t.RMSProp,t.sgd=t.SGD,s in t)return t[s]();throw new x(`Unknown Optimizer ${s}`)}const kl=1*1024*1024;function Il(s,t,e=!1){if(s==null||typeof s!="object"||Object.getPrototypeOf(s)!==Object.prototype||!ia(s))throw new Error("User-defined metadata is expected to be a JSON object, but is not.");if(e){const n=JSON.stringify(s);n.length>kl&&console.warn(`User-defined metadata of model "${t}" is too large in size (length=${n.length} when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= ${kl}.`)}}function ia(s){if(s===null)return!0;if(typeof s=="object")if(Object.getPrototypeOf(s)===Object.prototype){const t=Object.keys(s);for(const e of t)if(typeof e!="string"||!ia(s[e]))return!1;return!0}else if(Array.isArray(s)){for(const t of s)if(!ia(t))return!1;return!0}else return!1;else{const t=typeof s;return t==="string"||t==="number"||t==="boolean"}}function oI(s,t,e,n=console.log){const i=lI(s),a=["Layer (type)","Input Shape","Output shape","Param #"];i?(t=t||90,e=e||[.32,.61,.89,1]):(t=t||115,e=e||[.24,.48,.7,.8,1]),e[e.length-1]<=1&&(e=e.map(u=>Math.floor(t*u)));let o;if(!i){a.push("Receives inputs"),o=[];for(const u in s.nodesByDepth)o.push(...s.nodesByDepth[u])}n("_".repeat(t)),Qn(a,e,n),n("=".repeat(t));const r=s.layers;for(let u=0;u<r.length;++u)i?cI(r[u],e,n):uI(r[u],e,o,n),n((u===r.length-1?"=":"_").repeat(t));s.checkTrainableWeightsConsistency();const l=rI(s),c=jn(s.nonTrainableWeights);n(`Total params: ${l+c}`),n(`Trainable params: ${l}`),n(`Non-trainable params: ${c}`),n("_".repeat(t))}function rI(s){let t;return s.collectedTrainableWeights!=null?t=jn(s.collectedTrainableWeights):t=jn(s.trainableWeights),t}function lI(s){let t=!0;const e=[],n=[];for(const i in s.nodesByDepth)e.push(s.nodesByDepth[i]);for(const i of e){if(i.length>1||i.length===1&&i[0].inboundLayers.length>1){t=!1;break}n.push(...i)}if(t)for(const i of s.layers){let a=!1;for(const o of i.inboundNodes)if(n.indexOf(o)!==-1)if(a){t=!1;break}else a=!0;if(!t)break}return t}function Qn(s,t,e=console.log){let n="";for(let i=0;i<s.length;++i)i>0&&(n=n.slice(0,n.length-1)+" "),n+=s[i],n=n.slice(0,t[i]),n+=" ".repeat(t[i]-n.length);e(n)}function cI(s,t,e){let n,i;try{i=s.inboundNodes.map(l=>JSON.stringify(l.inputShapes)).join(",")}catch{i="multiple"}try{n=JSON.stringify(s.outputShape)}catch{n="multiple"}const a=s.name,o=s.getClassName(),r=[`${a} (${o})`,i,n,s.countParams().toString()];Qn(r,t,e)}function uI(s,t,e,n){let i,a;try{a=s.inboundNodes.map(d=>JSON.stringify(d.inputShapes)).join(",")}catch{a="multiple"}try{i=JSON.stringify(s.outputShape)}catch{i="multiple"}const o=[];for(const d of s.inboundNodes)if(!(e!=null&&e.length>0&&e.indexOf(d)===-1))for(let h=0;h<d.inboundLayers.length;++h){const p=d.inboundLayers[h].name,m=d.nodeIndices[h],f=d.tensorIndices[h];o.push(`${p}[${m}][${f}]`)}const r=s.name,l=s.getClassName(),c=o.length===0?"":o[0],u=[`${r} (${l})`,a,i,s.countParams().toString(),c];Qn(u,t,n);for(let d=1;d<o.length;++d)Qn(["","","","",o[d]],t,n)}function nh(s,t,e){return(s==="inboundNodes"||s==="outputLayers"||s==="inputLayers")&&t===0&&typeof e=="string"}function gn(s,t){if(s===null)return null;if(typeof s=="string")return us(s);if(typeof s=="number"||typeof s=="boolean")return s;if(s instanceof Array){const e=[],n=s.length;for(let i=0;i<n;++i){const a=s[i];nh(t,i,a)?e.push(a):e.push(gn(a,t))}return e}else{const e={};for(const n of Object.keys(s)){const i=s[n];if(n==="name"&&typeof i=="string")e[n]=i;else{const a=us(n);e[a]=gn(i,a)}}return e}}function aa(s,t){if(s==null)return null;if(typeof s=="string")return Ee(s);if(typeof s=="number"||typeof s=="boolean")return s;if(s instanceof Array){const e=[],n=s.length;for(let i=0;i<n;++i){const a=s[i];nh(t,i,a)?e.push(a):e.push(aa(a,t))}return e}else{const e={};for(const n of Object.keys(s)){const i=s[n],a=Ee(n);(n==="name"||n==="className")&&typeof i=="string"?e[a]=i:e[a]=aa(i,n)}return e}}const Ro="4.22.0";const hI=s=>{const t=Object.keys(s);if(t.length===0)return!1;const e=t[0].split("/");return!isNaN(parseInt(e[e.length-1],10))};class de extends rt{constructor(t){if(super({}),this.containerNodes=new Set,this.name=t.name,this.name==null){const b=this.getClassName().toLowerCase();this.name=bi(b)}if(this.supportsMasking=!1,this.trainable_=!0,Array.isArray(t.inputs)?this.inputs=t.inputs.slice():this.inputs=[t.inputs],Array.isArray(t.outputs)?this.outputs=t.outputs.slice():this.outputs=[t.outputs],Xe(this.inputs).length!==this.inputs.length)throw new x(`The list of inputs passed to the model is redundant. All inputs should only appear once. Found: ${this.inputs.map(b=>b.name)}`);Xe(this.outputs).length!==this.outputs.length&&console.warn(`The list of outputs passed to the model is redundant. All outputs should only appear once. Found: ${this.outputs.map(b=>b.name)}`),this.inputLayers=[],this.inputLayersNodeIndices=[],this.inputLayersTensorIndices=[],this.outputLayers=[],this.outputLayersNodeIndices=[],this.outputLayersTensorIndices=[],this.layers=[],this.internalContainerRefs=[];for(const b of this.outputs){const k=b.sourceLayer,y=b.nodeIndex,I=b.tensorIndex;this.outputLayers.push(k),this.outputLayersNodeIndices.push(y),this.outputLayersTensorIndices.push(I)}for(const b of this.inputs){const k=b.sourceLayer,y=b.nodeIndex,I=b.tensorIndex;Se(y===0,"input layer has >1 nodes"),Se(I===0,"input layer has >1 tensors"),this.inputLayers.push(k),this.inputLayersNodeIndices.push(y),this.inputLayersTensorIndices.push(I)}this.inputNames=[],this.outputNames=[],this.feedInputShapes=[],this.feedInputNames=[],this.feedOutputNames=[];for(let b=0;b<this.inputLayers.length;b++){const k=this.inputLayers[b];if(!(k instanceof qs))throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${t.inputs}. Input ${b} (0-based) originates from layer type ${k.getClassName()}.`);this.inputNames.push(k.name),this.feedInputShapes.push(k.batchInputShape),this.feedInputNames.push(k.name)}for(const b of this.outputLayers)this.outputNames.push(b.name);this.internalInputShapes=this.inputs.map(b=>b.shape),this.internalOutputShapes=this.outputs.map(b=>b.shape);const e={},n={},i={},a={},o={},r=[],l=(b,k,y,I,S,v)=>{(I==null||S==null||v==null)&&(I=b.sourceLayer,S=b.nodeIndex,v=b.tensorIndex);const N=I.inboundNodes[S];if(y.indexOf(N)!==-1)throw new ie(`The tensor ${b.name} at layer "${I.name}" is part of a cycle.`);if(k.indexOf(N)!==-1)return;this.containerNodes.add(de.nodeKey(I,S)),I.id in o||(o[I.id]=Object.keys(o).length),y.indexOf(N)===-1&&y.push(N);const C=N.inboundLayers.length;for(let D=0;D<C;D++){const E=N.inputTensors[D],V=N.inboundLayers[D],M=N.nodeIndices[D],L=N.tensorIndices[D];l(E,k,y,V,M,L)}for(k.push(N);y.indexOf(N)>=0;)y.splice(y.indexOf(N),1);r.push(N)},c=[],u=[];for(const b of this.outputs)l(b,c,u);const d=r.slice().reverse();for(const b of d){n[b.id]=b,b.id in e||(e[b.id]=0);let k=e[b.id];const y=i[b.outboundLayer.id]==null?0:i[b.outboundLayer.id];k=Math.max(k,y),i[b.outboundLayer.id]=k,a[b.outboundLayer.id]=b.outboundLayer,e[b.id]=k;for(let I=0;I<b.inboundLayers.length;I++){const S=b.inboundLayers[I],v=b.nodeIndices[I],N=S.inboundNodes[v],C=e[N.id]==null?0:e[N.id];e[N.id]=Math.max(k+1,C),n[N.id]=N}}const h={};for(const b in e){const k=e[b];k in h||(h[k]=[]),h[k].push(n[b])}const p={};for(const b in i){const k=i[b];k in p||(p[k]=[]),p[k].push(a[b])}let m=Object.keys(p).map(b=>parseInt(b,10)).sort(Rn);this.layers=[];for(const b of m){const k=p[b];k.sort((y,I)=>{const S=o[y.id],v=o[I.id];return S<v?-1:S>v?1:0});for(const y of k)y instanceof de&&this.internalContainerRefs.push(y),this.layers.push(y)}this.layersByDepth=p,m=Object.keys(h).map(b=>parseInt(b,10)).sort(Rn);const f=this.inputs.slice(),g=[];for(const b of m)for(const k of h[b]){const y=k.outboundLayer;if(y!=null){for(const I of k.inputTensors)if(f.indexOf(I)===-1)throw new ie(`Graph disconnected: cannot obtain value for tensor ${I} at layer "${y.name}". The following previous layers were accessed without issue: ${g}`);for(const I of k.outputTensors)f.push(I);g.push(y.name)}}this.nodesByDepth=h;const w=this.layers.map(b=>b.name);for(const b of w){const k=w.filter(y=>y===b).length;if(k!==1)throw new ie(`The name "${b}" is used ${k} times in the model. All layer names should be unique. Layer names: `+JSON.stringify(w))}this.outboundNodes=[],this.inboundNodes=[],new Ci({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:this.inputs.map(b=>null),outputMasks:this.outputs.map(b=>null),inputShapes:this.inputs.map(b=>b.shape),outputShapes:this.outputs.map(b=>b.shape)}),this.built=!0,this._refCount=1}assertNotDisposed(){if(this._refCount===0)throw new Error(`Container '${this.name}' is already disposed.`)}dispose(){this.assertNotDisposed();const t={refCountAfterDispose:null,numDisposedVariables:0};if(--this._refCount===0){for(const e of this.layers)t.numDisposedVariables+=e.dispose().numDisposedVariables;for(const e of this.internalContainerRefs)t.numDisposedVariables+=e.dispose().numDisposedVariables}return t.refCountAfterDispose=this._refCount,t}get trainable(){return this.trainable_}set trainable(t){this.layers.forEach(e=>{e._trainableWeights.forEach(n=>n.trainable=t)}),this.trainable_=t}get trainableWeights(){if(this._trainableWeights.length>0)throw new x("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");if(!this.trainable)return[];let t=[];for(const e of this.layers)t=t.concat(e.trainableWeights);return t}get nonTrainableWeights(){const t=[];for(const e of this.layers)t.push(...e.nonTrainableWeights);if(!this.trainable){const e=[];for(const n of this.layers)e.push(...n.trainableWeights);return e.concat(t)}return t}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}loadWeights(t,e=!0){const n={};let i=0;const a=hI(t);a&&this.parseWeights(t);for(const r of this.layers)for(const[l,c]of r.weights.entries()){const u=a?`${c.name.split("/").slice(0,-1).join("/")+"/"}${l}`:c.originalName;if(n[u]!=null)throw new x(`Duplicate weight name: ${u}`);n[u]=c,i++}const o=[];for(const r in t){let l=r;if(n[r]==null){const c=r.split("/");l=c.slice(0,-2).concat([c[c.length-1]]).join("/")}if(n[l]!=null)o.push([n[l],t[r]]);else if(e)throw new x(`Provided weight data has no target variable: ${r}`);delete n[l]}if(e){const r=[];for(const l in n)r.push(l);if(r.length>0)throw new x(`${r.length} of ${i} weights are not set: ${r}`)}vo(o)}parseWeights(t){for(const e in Object.keys(t)){const n=e.split("/"),i=["vars","layer_checkpoint_dependencies"],a=n.map(o=>o.startsWith("_")?o.slice(1):o).filter(o=>!i.includes(o)).join("/");a!==e&&(t[a]=t[e],delete t[e])}}updatedConfig(){const t=this.getConfig(),e={};return e.className=this.getClassName(),e.config=t,e.kerasVersion=`tfjs-layers ${Ro}`,e.backend="TensorFlow.js",e}toJSON(t,e=!0){const n=aa(this.updatedConfig());return e?JSON.stringify(n):n}call(t,e){return T(()=>{t=mt(t);const n=new Ze;for(let i=0;i<this.inputs.length;++i)n.add(this.inputs[i],t[i]);return an(this.outputs,n,e)})}computeMask(t,e){return T(()=>{t=mt(t);let n;return e==null?n=ms(null,t.length):n=mt(e),this.runInternalGraph(t,n)[1]})}computeOutputShape(t){const e=Un(t);if(e.length!==this.inputLayers.length)throw new x(`Invalid inputShape argument ${t}: model has ${this.inputLayers.length} tensor inputs.`);const n={};for(let r=0;r<e.length;r++){const l=this.inputLayers[r],c=e[r],u=l.name+"_0_0";n[u]=c}const i=Object.keys(this.nodesByDepth).map(r=>parseInt(r,10)).sort(Rn);if(i.length>1)for(const r of i){const l=this.nodesByDepth[r];for(const c of l){const u=c.outboundLayer;if(this.inputLayers.map(f=>f.id).indexOf(u.id)!==-1)continue;const d=[];for(let f=0;f<c.inboundLayers.length;f++){const g=c.inboundLayers[f],w=c.nodeIndices[f],b=c.tensorIndices[f],k=`${g.name}_${w}_${b}`,y=n[k];d.push(y)}const h=u.computeOutputShape(jt(d)),p=Un(h),m=u.inboundNodes.indexOf(c);for(let f=0;f<p.length;f++){const g=`${u.name}_${m}_${f}`;n[g]=p[f]}}}const a=[],o=[];for(let r=0;r<this.outputLayers.length;r++){const l=this.outputLayers[r],c=this.outputLayersNodeIndices[r],u=this.outputLayersTensorIndices[r],d=`${l.name}_${c}_${u}`;o.push(d)}for(let r=0;r<o.length;r++){const l=o[r];Se(l in n),a.push(n[l])}return jt(a)}runInternalGraph(t,e){e==null&&(e=ms(null,t.length));const n={};for(let l=0;l<this.inputs.length;++l){const c=this.inputs[l],u=t[l],d=e[l];n[c.id]=[u,d]}const i=Object.keys(this.nodesByDepth).map(l=>parseInt(l,10)).sort(Rn);for(const l of i){const c=this.nodesByDepth[l];for(const u of c){const d=u.outboundLayer,h=u.inputTensors,p=u.outputTensors,m=new Array;for(const f of h)f.id in n&&m.push(n[f.id]);if(m.length===h.length){let f={},g,w,b,k;if(u.callArgs!=null&&(f=u.callArgs),m.length===1){const[y,I]=m[0];f.mask==null&&(f.mask=I),b=mt(d.call(y,f)),k=mt(d.computeMask(y,I)),g=[y],w=[I]}else g=m.map(y=>y[0]),w=m.map(y=>y[1]),f.mask==null&&(f.mask=w),b=mt(d.call(g,f)),k=mt(d.computeMask(g,w));if(d.activityRegularizer)throw new it("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");for(let y=0;y<p.length;++y){const I=p[y],S=b[y],v=k[y];n[I.id]=[S,v]}}}}const a=[],o=[],r=[];for(const l of this.outputs){Se(l.id in n,`Could not compute output ${l.name} : ${l.id}`);const[c,u]=n[l.id];r.push(c.shape),a.push(c),o.push(u)}return[a,o,r]}buildNodeConversionMap(t){const e={};let n;for(const i of this.layers){n=i instanceof de?1:0;for(let a=0;a<i.inboundNodes.length;a++){const o=de.nodeKey(i,a);this.containerNodes.has(o)&&(e[o]=n,n+=1)}}return e}getLayer(t,e){if(e!=null)return this.findLayer(e);if(t==null)throw new x("Provide either a layer name or layer index");if(typeof t=="number")return this.findLayer(t);for(const n of this.layers)if(n.name===t)return n;throw new x(`No such layer: ${t}`)}findLayer(t){if(this.layers.length<=t)throw new x(`Was asked to retrieve layer at index ${t}, but model only has ${this.layers.length} layer(s).`);return this.layers[t]}calculateLosses(){return T(()=>{const t=[];for(const e of this.layers)for(let n=0;n<e.inboundNodes.length;++n){const i=de.nodeKey(e,n);this.containerNodes.has(i)&&t.push(...e.calculateLosses())}return t})}getConfig(){const t={name:this.name},e=this.buildNodeConversionMap(this.layers),n=[];for(const o of this.layers){const r=o.getClassName(),l=o.getConfig(),c=[];for(let d=0;d<o.inboundNodes.length;d++){const h=o.inboundNodes[d],p=de.nodeKey(o,d);let m={};if(this.containerNodes.has(p)){if(h.callArgs)try{JSON.stringify(h.callArgs),m=h.callArgs}catch{console.warn(`Layer ${o.name} was passed non-serializable keyword arguments: ${h.callArgs}. They will not be included in the serialized model (and thus will be missing at deserialization time).`),m={}}if(h.inboundLayers.length>0){const f=[];for(let g=0;g<h.inboundLayers.length;g++){const w=h.inboundLayers[g],b=h.nodeIndices[g],k=h.tensorIndices[g],y=de.nodeKey(w,b);let I=e[y];I==null&&(I=0),f.push([w.name,I,k,m])}c.push(f)}}}const u={};u.name=o.name,u.className=r,u.config=l,u.inboundNodes=c,n.push(u)}t.layers=n;const i=[];for(let o=0;o<this.inputLayers.length;o++){const r=this.inputLayers[o],l=this.inputLayersNodeIndices[o],c=de.nodeKey(r,l);if(!this.containerNodes.has(c))continue;let u=e[c];u==null&&(u=0);const d=this.inputLayersTensorIndices[o];i.push([r.name,u,d])}t.inputLayers=i;const a=[];for(let o=0;o<this.outputLayers.length;o++){const r=this.outputLayers[o],l=this.outputLayersNodeIndices[o],c=de.nodeKey(r,l);if(!this.containerNodes.has(c))continue;let u=e[c];u==null&&(u=0);const d=this.outputLayersTensorIndices[o];a.push([r.name,u,d])}return t.outputLayers=a,t}static fromConfig(t,e,n={},i=!1){const a={},o={};function r(g,w){g.name in o?o[g.name].push(w):o[g.name]=[w]}function l(g,w){const b=[];let k;for(const y of w){const I=y[0],S=y[1],v=y[2];if(k=y[3]==null?{}:y[3],!(I in a)){r(g,w);return}const N=a[I];if(N.inboundNodes.length<=S){r(g,w);return}const C=N.inboundNodes[S];b.push(C.outputTensors[v])}b.length>0&&g.apply(jt(b),k)}function c(g){const w=g.name,b=fe(g,e.customObjects!=null?e.customObjects:{});b.setFastWeightInitDuringBuild(i),a[w]=b,g.inboundNodes.forEach(y=>{if(!(y instanceof Array))throw new x(`Corrupted configuration, expected array for nodeData: ${y}`);r(b,y)})}const u=e.name,d=e.layers;for(const g of d)c(g);for(;!$w(o);)for(const g of d){const w=a[g.name];if(w.name in o){const b=o[w.name];delete o[w.name];for(const k of b)l(w,k)}}const h=[],p=[],m=e.inputLayers;for(const g of m){const w=g[0],b=g[1],k=g[2];Se(w in a);const I=a[w].inboundNodes[b].outputTensors;h.push(I[k])}const f=e.outputLayers;for(const g of f){const w=g[0],b=g[1],k=g[2];Se(w in a);const I=a[w].inboundNodes[b].outputTensors;p.push(I[k])}return new t({inputs:h,outputs:p,name:u})}get stateful(){if(this._stateful)throw new x("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");for(const t of this.layers)if(t.stateful)return!0;return!1}resetStates(){T(()=>{this.layers.forEach(t=>{t.stateful&&t.resetStates()})})}}function dI(s,t,e){const n=t.length;if(s==null||Array.isArray(s)&&s.length===0)return t.map(i=>null);if(n===1)return Array.isArray(s)&&s.length===1?s:typeof s=="object"&&t[0]in s?[s[t[0]]]:[s];if(Array.isArray(s)){if(s.length!==n)throw new Error(`Provided ${e} is an array of ${s.length} element(s), but the model has ${n} outputs. Make sure a set of weights is provided for each model output.`);return s}else if(typeof s=="object"&&Object.keys(s).length>0&&typeof s[Object.keys(s)[0]]=="object"){const i=[];return t.forEach(a=>{a in s?i.push(s[a]):i.push(null)}),i}else throw new Error(`The model has multiple (${n}) outputs, so ${e} must be either an array with ${n} elements or an object with ${t} keys. Provided ${e} not understood: ${JSON.stringify(s)}`)}function ih(s,t){return dI(s,t,"classWeight")}async function ah(s,t,e,n){if(e!=null){const i=T(()=>{if(s.shape.length===1)return lp(s);if(s.shape.length===2){if(s.shape[1]>1)return hn(s,1);if(s.shape[1]===1)return B(s,[s.shape[0]]);throw new Error(`Encountered unexpected last-dimension size (${s.shape[1]}) during handling of class weights. The size is expected to be >= 1.`)}else throw new Error(`Unexpected rank of target (y) tensor (${s.rank}) during handling of class weights. The rank is expected to be 1 or 2.`)}),a=Array.from(await i.data());gt(i);const o=[];return a.forEach(r=>{if(e[r]==null)throw new Error(`classWeight must contain all classes in the training data. The class ${r} exists in the data but not in classWeight`);o.push(e[r])}),dn(o,"float32")}else return null}function pI(s,t){return A(s,t)}const fI=32;function oh(s,t){let e,n;const i=t;e=i.xs,n=i.ys,K(e!=null&&n!=null,()=>`A Dataset iterator for fitDataset() is expected to generate objects of the form \`{xs: xVal, ys: yVal}\`, where the two values may be \`tf.Tensor\`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates ${t}`);const a=xl("input",s.inputNames,e),o=xl("output",s.outputNames,n),r=a[0].shape[0];K(a.length===s.inputs.length,()=>`LayersModel has ${s.inputs.length} inputs, but the dataset provides ${a.length} inputs.  (Expected input keys: ${JSON.stringify(s.inputNames)})`),K(o.length===s.outputs.length,()=>`LayersModel has ${s.outputs.length} outputs, but the dataset provides ${o.length} outputs.  (Expected output keys: ${JSON.stringify(s.outputNames)})`);for(let l=0;l<a.length;l++)K(a[l].shape[0]===r,()=>`Batch size mismatch: input ${s.inputNames[l]} has ${a[l].shape[0]}; expected  ${r} based on input ${s.inputNames[0]}.`);for(let l=0;l<o.length;l++)K(o[l].shape[0]===r,()=>`Batch size mismatch: output ${s.outputNames[l]} has ${o[l].shape[0]}; expected  ${r} based on input ${s.inputNames[0]}.`);return{xs:a,ys:o}}function xl(s,t,e){if(e instanceof re)return[e];if(Array.isArray(e))return K(e.length===t.length,()=>`Received an array of ${e.length} Tensors, but expected ${t.length} to match the ${s} keys ${t}.`),e;{const n=[];for(const i of t){if(e[i]==null)throw new x(`The feature data generated by the dataset lacks the required ${s} key '${i}'.`);n.push(e[i])}return n}}function mI(s){if(s.length===3)throw new it("Validation with sample weights is not implemented yet.");return{xs:s[0],ys:s[1]}}async function gI(s,t,e){const n=e.batchesPerEpoch!=null;if(K(s.optimizer!=null,()=>"You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig)."),K(e!=null,()=>"For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call."),K(e.epochs!=null&&e.epochs>0&&Number.isInteger(e.epochs),()=>`For fitDataset(), config.epochs is expected to be a positive integer, but got ${e.epochs}`),K(!n||e.batchesPerEpoch>0&&Number.isInteger(e.batchesPerEpoch),()=>`For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got ${e.batchesPerEpoch}`),K(e.validationSplit==null,()=>"`validationSplit` is not supported by `fitDataset()`. Use validationData instead."),s.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");s.isTraining=!0;try{const i=e.validationData!=null;let a,o;if(i)if(Sl(e.validationData))K(e.validationBatches==null||e.validationBatches>0&&Number.isInteger(e.validationBatches),()=>`For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got ${e.validationBatches}`);else{const g=mI(e.validationData);a=g.xs,o=g.ys}const r=s.makeTrainFunction(),l=s.getDedupedMetricsNames();let c;i?c=l.slice().concat(l.map(g=>"val_"+g)):c=l.slice();const u=Ju(e.callbacks,e.yieldEvery),d=e.verbose==null?1:e.verbose,{callbackList:h,history:p}=Xu(u,d,e.epochs,null,null,bI(t,e),null,i,c);h.setModel(s),s.history=p,await h.onTrainBegin(),s.stopTraining_=!1;let m=e.initialEpoch==null?0:e.initialEpoch,f=await t.iterator();for(;m<e.epochs;){const g={};await h.onEpochBegin(m);let w=0,b=0;for(n||(f=await t.iterator());!n||w<e.batchesPerEpoch;){const k=await f.next();if(n&&k.done){console.warn(`You provided \`batchesPerEpoch\` as ${e.batchesPerEpoch}, but your dataset iterator ran out of data after ${w} batches; interrupting training. Make sure that your dataset can generate at least \`batchesPerEpoch * epochs\` batches (in this case, ${e.batchesPerEpoch*e.epochs} batches). You may need to use the repeat() function when building your dataset.`);break}if(k.value!=null){const{xs:y,ys:I}=oh(s,k.value),S={};S.batch=b,S.size=y[0].shape[0],await h.onBatchBegin(b,S);const v=[];if(e.classWeight!=null){const D=ih(e.classWeight,s.outputNames);for(let E=0;E<D.length;++E)v.push(await ah(I[E],null,D[E]))}const N=y.concat(I).concat(v),C=r(N);gt(N);for(let D=0;D<l.length;++D){const E=l[D],V=C[D];S[E]=V,Oe(V)}await h.onBatchEnd(b,S),Zu(S),b++,w++}if(n?w>=e.batchesPerEpoch:k.done){if(i){let y;Sl(e.validationData)?y=mt(await s.evaluateDataset(e.validationData,{batches:e.validationBatches})):y=mt(s.evaluate(a,o,{batchSize:e.validationBatchSize==null?fI:e.validationBatchSize,verbose:0}));for(let I=0;I<s.metricsNames.length;++I)g[`val_${s.metricsNames[I]}`]=y[I]}break}if(s.stopTraining_)break}if(await h.onEpochEnd(m,g),m++,s.stopTraining_)break}return await h.onTrainEnd(),await s.history.syncData(),s.history}finally{s.isTraining=!1}}function bI(s,t){let e=null;return t.batchesPerEpoch!=null?e=t.batchesPerEpoch:Number.isFinite(s.size)&&(e=s.size),e}function Sl(s){return typeof s.iterator=="function"}function yI(s){return typeof s.next=="function"}async function wI(s,t,e){e=e||{};const n=e.batches!=null,i=s.testFunction;let a=[];if(e.verbose>0)throw new it("Verbose mode is not implemented yet.");K(!n||e.batches>0&&Number.isInteger(e.batches),()=>`Test loop expects \`batches\` to be a positive integer, but received ${JSON.stringify(e.batches)}`);const o=yI(t)?t:await t.iterator();let r=0,l=0;for(;!n||l<e.batches;){const c=await o.next();if(a=T(()=>{if(c.value){const{xs:u,ys:d}=oh(s,c.value),h=u.concat(d),p=T(()=>i(h));if(gt(h),l===0)for(let f=0;f<p.length;++f)a.push(zt(0));const m=h[0].shape[0];for(let f=0;f<p.length;++f){const g=p[f],w=a[f];a[f]=T(()=>X(a[f],A(m,g))),l>0&&gt(w)}gt(p),r+=m,++l}return a}),c.done){n&&console.warn(`Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least \`batches\` batches (in this case, ${e.batches} batches). You may need to use the repeat() function when building your dataset.`);break}}for(let c=0;c<a.length;++c){const u=a[c];a[c]=ut(a[c],r),gt(u)}return jt(a)}function Hi(s){K(s>0&&Number.isInteger(s),()=>`batchSize is required to be a positive integer, but got ${s}`)}function tn(s,t,e){return s==null?[null]:Array.isArray(s)?s.map(n=>ps(n,t,e-t)):ps(s,t,e-t)}function oa(s,t){return T(()=>s==null?null:Array.isArray(s)?s.map(e=>oa(e,t)):Uu(s,t.dtype==="int32"?t:J(t,"int32")))}function Ui(s,t){const e=[];let n=0,i=null;for(;n<s;)i=n+t,i>=s&&(i=s),e.push([n,i]),n=i;return e}function rh(s){const t=[];s instanceof re&&(s=[s]);for(let e=0;e<s.length;++e){const n=s[e];if(n.rank===1)t.push(vn(n,1));else{if(n.rank===0)throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");t.push(n)}}return t}function he(s,t){if(s==null)return;const e=[];if(t instanceof re)e.push(t.id);else if(Array.isArray(t))t.forEach(i=>e.push(i.id));else if(t!=null)for(const i in t){const a=t[i];e.push(a.id)}const n=[];if(s instanceof re)e.indexOf(s.id)===-1&&n.push(s);else if(Array.isArray(s))s.forEach(i=>{e.indexOf(i.id)===-1&&n.push(i)});else if(s!=null)for(const i in s){const a=s[i];e.indexOf(a.id)===-1&&n.push(a)}n.forEach(i=>{i.isDisposed||i.dispose()})}function kI(s){return s instanceof re}function ra(s){return Array.isArray(s)}function vl(s){return!kI(s)&&!ra(s)}function Nl(s,t,e,n=!0,i=""){if(t==null||t.length===0){if(s!=null){let o=!1;if(ra(s)&&s.length>0)o=!0;else if(vl(s)){for(const r in s)if(s.hasOwnProperty(r)){o=!0;break}}else o=!0;if(o)throw new x(`Error when checking model ${i} expected no data, but got ${s}`)}return[]}if(s==null)return t.map(o=>null);let a;if(vl(s)){s=s,a=[];for(const o of t){if(s[o]==null)throw new x(`No data provided for "${o}". Need data for each key in: ${t}`);a.push(s[o])}}else if(ra(s)){if(s=s,s.length!==t.length)throw new x(`Error when checking model ${i}: the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ${t.length} Tensor(s), but instead got the following list of Tensor(s): ${s}`);a=s}else{if(s=s,t.length>1)throw new x(`The model ${i} expects ${t.length} Tensor(s), but only received one Tensor. Found: Tensor with shape ${s.shape}`);a=[s]}if(a=rh(a),e!=null)for(let o=0;o<t.length;++o){if(e[o]==null)continue;const r=a[o];if(r.shape.length!==e[o].length)throw new x(`Error when checking ${i}: expected ${t[o]} to have ${e[o].length} dimension(s). but got array with shape ${r.shape}`);for(let l=0;l<e[o].length;++l){if(l===0&&!n)continue;const c=r.shape[l],u=e[o][l];if(u!=null&&u>=0&&c!==u)throw new x(`${i} expected a batch of elements where each example has shape [${e[o].slice(1,e[o].length)}] (i.e.,tensor shape [*,${e[o].slice(1,e[o].length)}]) but the ${i} received an input with ${r.shape[0]} examples, each with shape [${r.shape.slice(1,r.shape.length)}] (tensor shape [${r.shape}])`)}}return a}function II(s,t,e){const n=Xe(s.map(a=>a.shape[0]));n.sort();const i=Xe(t.map(a=>a.shape[0]));if(i.sort(),n.length>1)throw new x(`All input Tensors (x) should have the same number of samples. Got array shapes: ${JSON.stringify(s.map(a=>a.shape))}`);if(i.length>1)throw new x(`All target Tensors (y) should have the same number of samples. Got array shapes: ${JSON.stringify(t.map(a=>a.shape))}`);if(n.length>0&&i.length>0&&!Jt(n,i))throw new x(`Input Tensors should have the same number of samples as target Tensors. Found ${n[0]} input sample(s) and ${i[0]} target sample(s).`)}function xI(s,t,e){const n=[Ns,Ai,mn];for(let i=0;i<s.length;++i){const a=s[i],o=t[i],r=e[i];if(o!=null){if(o===mn&&a.shape[a.shape.length-1]===1)throw new x(`You are passing a target array of shape ${a.shape} while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].`);if(n.indexOf(o)!==-1){const l=a.shape.slice(1),c=r.slice(1);for(let u=0;u<l.length;++u){const d=l[u],h=c[u];if(h!=null&&d!==h)throw new x(`A target Tensor with shape ${a.shape} was passed for an output of shape ${r}, while using a loss function that expects targets to have the same shape as the output.`)}}}}}function Cl(s,t,e,n=!0,i=""){let a;if(Array.isArray(s)){if(s.length!==t.length)throw new x(`Error when checking model ${i}: the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ${t.length} Tensor(s), but instead got ${s.length} Tensors(s).`);a=s}else{if(t.length>1)throw new x(`The model expects ${t.length} ${i} Tensors, but only received one Tensor. Found: array with shape ${JSON.stringify(s.shape)}.`);a=[s]}if(e!=null)for(let o=0;o<t.length;++o){if(e[o]==null)continue;const r=a[o];if(r.shape.length!==e[o].length)throw new x(`Error when checking ${i}: expected ${t[o]} to have ${e[o].length} dimension(s), but got array with shape ${JSON.stringify(r.shape)}`);for(let l=0;l<e[o].length;++l){if(l===0&&!n)continue;const c=r.shape[l],u=e[o][l];if(u!=null&&u!==c)throw new x(`Error when checking ${i}: expected ${t[o]} to have shape ${JSON.stringify(e[o])} but got array with shape ${JSON.stringify(r.shape)}.`)}}}function SI(s,t){if(s==null||Array.isArray(s)&&s.length===0)return t.map(n=>[]);let e;if(typeof s=="string"||typeof s=="function")e=[s];else if(Array.isArray(s)||typeof s=="object")e=s;else throw new TypeError(`Type of metrics argument not understood. Expected an string,function, Array, or Object, found: ${s}`);if(Array.isArray(e))return t.map(n=>e);{const n=[];for(const i of t){let a=e.hasOwnProperty(i)?e[i]:[];Array.isArray(a)||(a=[a]),n.push(a)}return n}}const vI="layers-model";class Qe extends de{constructor(t){super(t),this.isTraining=!1}summary(t,e,n=console.log){if(!this.built)throw new x("This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).");oI(this,t,e,n)}compile(t){if(t.loss==null&&(t.loss=[]),this.loss=t.loss,typeof t.optimizer=="string")this.optimizer_=aI(t.optimizer),this.isOptimizerOwned=!0;else{if(!(t.optimizer instanceof cp))throw new x("User-defined optimizer must be an instance of tf.Optimizer.");this.optimizer_=t.optimizer,this.isOptimizerOwned=!1}let e=[];if(!Array.isArray(t.loss)&&typeof t.loss!="string"&&typeof t.loss!="function"){t.loss=t.loss;for(const o in t.loss)if(this.outputNames.indexOf(o)===-1)throw new x(`Unknown entry in loss dictionary: "${o}". Only expected the following keys: ${this.outputNames}`);for(const o of this.outputNames)t.loss[o]==null&&console.warn(`Output "${o}" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ${o} during training`),e.push(Gi(t.loss[o]))}else if(Array.isArray(t.loss)){if(t.loss.length!==this.outputs.length)throw new x(`When passing an Array as loss, it should have one entry per model output. The model has ${this.outputs.length} output(s), but you passed loss=${t.loss}.`);e=t.loss.map(r=>Gi(r))}else{const o=Gi(t.loss);this.outputs.forEach(r=>{e.push(o)})}this.lossFunctions=e,this.feedOutputNames=[],this.feedOutputShapes=[],this.feedLossFns=[];for(let o=0;o<this.outputs.length;++o){const r=this.internalOutputShapes[o],l=this.outputNames[o];this.feedOutputNames.push(l),this.feedOutputShapes.push(r),this.feedLossFns.push(this.lossFunctions[o])}const n=[];this.metrics=t.metrics,this.metricsNames=["loss"],this.metricsTensors=[],ds("loss",()=>{for(let o=0;o<this.outputs.length;++o){if(n.indexOf(o)!==-1)continue;const r=this.lossFunctions[o];this.outputs.length>1&&(this.metricsTensors.push([r,o]),this.metricsNames.push(this.outputNames[o]+"_loss"))}});const i=SI(t.metrics,this.outputNames),a=(o,r,l)=>{this.outputNames.length>1&&(r=this.outputNames[o]+"_"+r),this.metricsNames.push(r),this.metricsTensors.push([l,o])};ds("metric",()=>{for(let o=0;o<this.outputs.length;++o){if(n.indexOf(o)!==-1)continue;const r=i[o];(c=>{let d,h,p;for(const m of c){if(typeof m=="string"&&["accuracy","acc","crossentropy","ce"].indexOf(m)!==-1){const g=this.internalOutputShapes[o];g[g.length-1]===1||this.lossFunctions[o]===Ai?["accuracy","acc"].indexOf(m)!==-1?h=Fo:["crossentropy","ce"].indexOf(m)!==-1&&(h=th):this.lossFunctions[o]===Jn?["accuracy","acc"].indexOf(m)!==-1?h=eh:["crossentropy","ce"].indexOf(m)!==-1&&(h=sh):["accuracy","acc"].indexOf(m)!==-1?h=$o:["crossentropy","ce"].indexOf(m)!==-1&&(h=Mo);let w;["accuracy","acc"].indexOf(m)!==-1?w="acc":["crossentropy","ce"].indexOf(m)!==-1&&(w="ce"),p=h,d=""+w}else p=iI(m),d=""+On(m);let f;ds(d,()=>{f=p}),a(o,d,f)}})(r)}}),this.collectedTrainableWeights=this.trainableWeights}checkTrainableWeightsConsistency(){this.collectedTrainableWeights!=null&&this.trainableWeights.length!==this.collectedTrainableWeights.length&&console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?")}evaluate(t,e,n={}){const i=n.batchSize==null?32:n.batchSize;Hi(i);const o=this.standardizeUserDataXY(t,e,!0,i);try{const r=o[0].concat(o[1]);this.makeTestFunction();const l=this.testFunction,c=this.testLoop(l,r,i,n.verbose,n.steps);return jt(c)}finally{he(o[0],t),he(o[1],e)}}async evaluateDataset(t,e){return this.makeTestFunction(),wI(this,t,e)}checkNumSamples(t,e,n,i="steps"){let a;if(n!=null){if(a=null,e!=null)throw new x(`If ${i} is set, batchSize must be null or undefined.Got batchSize = ${e}`)}else if(t!=null)Array.isArray(t)?a=t[0].shape[0]:a=t.shape[0];else throw new x(`Either the input data should have a defined shape, or ${i} shoud be specified.`);return a}execute(t,e){if(Array.isArray(e)&&e.length===0)throw new x("`outputs` is an empty Array, which is not allowed.");const n=Array.isArray(e),i=n?e:[e],a=this.retrieveSymbolicTensors(i),o=new Ze;if(t instanceof re&&(t=[t]),Array.isArray(t)){if(t.length!==this.inputs.length)throw new x(`The number of inputs provided (${t.length}) does not match the number of inputs of this model (${this.inputs.length}).`);for(let l=0;l<this.inputs.length;++l)o.add(this.inputs[l],t[l])}else for(const l of this.inputs){const c=t[l.name];if(c==null)throw new x(`No value is provided for the model's input ${l.name}`);o.add(l,c)}const r=an(a,o);return n?r:r[0]}retrieveSymbolicTensors(t){const e=ms(null,t.length);let n=t.length;for(const i of this.layers){const a=Array.isArray(i.output)?i.output:[i.output],o=a.map(r=>r.name);for(let r=0;r<t.length;++r){const l=o.indexOf(t[r]);if(l!==-1&&(e[r]=a[l],n--),n===0)break}if(n===0)break}if(n>0){const i=[];throw e.forEach((a,o)=>{a==null&&i.push(t[o])}),new x(`Cannot find SymbolicTensors for output name(s): ${JSON.stringify(i)}`)}return e}predictLoop(t,e=32,n=!1){return T(()=>{const i=this.checkNumSamples(t);if(n)throw new it("Verbose predictLoop() is not implemented yet.");const a=Ui(i,e),o=this.outputs.map(r=>[]);for(let r=0;r<a.length;++r)T(()=>{const c=a[r][0],u=a[r][1],d=tn(t,c,u),h=[];if(Array.isArray(d))for(let m=0;m<d.length;++m)h.push({key:this.inputs[m],value:d[m]});else h.push({key:this.inputs[0],value:d});const p=new Ze(h);return an(this.outputs,p)}).forEach((c,u)=>o[u].push(c));return jt(o.map(r=>xn(r,0)))})}predict(t,e={}){const n=rh(t);Cl(n,this.inputNames,this.feedInputShapes,!1);try{const i=e.batchSize==null?32:e.batchSize;return Hi(i),this.predictLoop(n,i)}finally{he(n,t)}}predictOnBatch(t){Cl(t,this.inputNames,this.feedInputShapes,!0);const e=(Array.isArray(t)?t[0]:t).shape[0];return this.predictLoop(t,e)}standardizeUserDataXY(t,e,n=!0,i){if(this.optimizer_==null)throw new ie("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");const a=[];for(let o=0;o<this.feedOutputShapes.length;++o){const r=this.feedOutputShapes[o];this.feedLossFns[o]===Jn?a.push(r.slice(0,r.length-1).concat([1])):a.push(r)}if(t=Nl(t,this.feedInputNames,this.feedInputShapes,!1,"input"),e=Nl(e,this.feedOutputNames,a,!1,"target"),II(t,e),xI(e,this.feedLossFns,this.feedOutputShapes),this.stateful&&i!=null&&i>0&&t[0].shape[0]%i!==0)throw new x(`In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ${i}. Found: ${t[0].shape[0]} sample(s).`);return[t,e]}async standardizeUserData(t,e,n,i,a=!0,o){const[r,l]=this.standardizeUserDataXY(t,e,a,o);if(n!=null)throw new Error("sample weight is not supported yet.");let c=null;if(i!=null){const u=ih(i,this.outputNames);c=[];for(let d=0;d<u.length;++d)c.push(await ah(l[d],null,u[d]))}return[r,l,c]}testLoop(t,e,n,i=0,a){return T(()=>{const o=this.checkNumSamples(e,n,a,"steps"),r=[];if(i>0)throw new it("Verbose mode is not implemented yet.");if(a!=null)throw new it("steps mode in testLoop() is not implemented yet");{const l=Ui(o,n),c=dn(be(0,o));for(let u=0;u<l.length;++u){const d=l[u][0],h=l[u][1],p=ps(c,d,h-d),m=oa(e,p),f=t(m);if(u===0)for(let g=0;g<f.length;++g)r.push(zt(0));for(let g=0;g<f.length;++g){const w=f[g];r[g]=X(r[g],A(h-d,w))}}for(let u=0;u<r.length;++u)r[u]=ut(r[u],o)}return r})}getDedupedMetricsNames(){const t=this.metricsNames,e=[];for(let n=0;n<t.length;++n){const i=t[n];let a=i;if(ul(t,i)>1){const o=ul(t.slice(0,n),i);a+=`_${o}`}e.push(a)}return e}makeTrainFunction(){return t=>{const e=[],n=t.slice(0,this.inputs.length),i=t.slice(this.inputs.length,this.inputs.length+this.outputs.length),a=t.slice(this.inputs.length+this.outputs.length,this.inputs.length+this.outputs.length*2),o=[],r=()=>{const d=[];for(let f=0;f<this.inputs.length;++f)d.push({key:this.inputs[f],value:n[f]});const h=new Ze(d),p=an(this.outputs,h,{training:!0});let m;for(let f=0;f<this.lossFunctions.length;++f){const g=this.lossFunctions[f];let w=g(i[f],p[f]);a[f]!=null&&(w=pI(w,a[f]));const b=Ot(w);e.push(b),f===0?m=w:m=X(m,w)}for(let f=0;f<this.metricsTensors.length;++f){let g;if(this.outputs.length>1&&f<this.outputs.length)g=e[f];else{const w=this.metricsTensors[f][0],b=this.metricsTensors[f][1];g=Ot(w(i[b],p[b]))}Oe(g),o.push(g)}return m=Ot(m),this.calculateLosses().forEach(f=>{m=X(m,f)}),m},l=this.collectedTrainableWeights.map(d=>d.read());return[this.optimizer_.minimize(r,!0,l)].concat(o)}}makeTestFunction(){this.testFunction=t=>T(()=>{const e=[];let n;const i=t.slice(0,this.inputs.length),a=t.slice(this.inputs.length,this.inputs.length+this.outputs.length),o=[];for(let c=0;c<this.inputs.length;++c)o.push({key:this.inputs[c],value:i[c]});const r=new Ze(o),l=an(this.outputs,r);for(let c=0;c<this.lossFunctions.length;++c){const u=this.lossFunctions[c],d=Ot(u(a[c],l[c]));c===0?n=d:n=X(n,d),e.push(n)}for(let c=0;c<this.metricsTensors.length;++c){const u=this.metricsTensors[c][0],d=this.metricsTensors[c][1],h=Ot(u(a[d],l[d]));e.push(h)}return e})}async fit(t,e,n={}){if(this.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");this.isTraining=!0;let i,a,o,r,l,c,u,d,h;try{const p=n.batchSize==null?32:n.batchSize;Hi(p);const f=await this.standardizeUserData(t,e,n.sampleWeight,n.classWeight,!1,p);i=f[0],a=f[1],h=f[2];let g=!1,w;if(n.validationData!=null&&n.validationData.length>0){if(g=!0,n.validationData.length===2)l=n.validationData[0],c=n.validationData[1];else throw n.validationData.length===3?new it("validationData including sample weights is not supported yet."):new x(`When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; ${n.validationData} is invalid.`);const D=await this.standardizeUserData(l,c,null,null,!0,p);u=D[0],d=D[1],w=u.concat(d)}else if(n.validationSplit!=null&&n.validationSplit>0&&n.validationSplit<1){g=!0;const C=Math.floor(i[0].shape[0]*(1-n.validationSplit)),D=i[0].shape[0];u=tn(i,C,D),o=i,i=tn(i,0,C),d=tn(a,C,D),r=a,a=tn(a,0,C),w=u.concat(d)}else n.validationSteps!=null&&(g=!0);const b=i.concat(a).concat(h);this.checkTrainableWeightsConsistency();const k=this.makeTrainFunction(),y=this.getDedupedMetricsNames();let I,S;g?(this.makeTestFunction(),I=this.testFunction,S=y.slice().concat(y.map(C=>"val_"+C))):(I=null,w=[],S=y.slice());const v=Ju(n.callbacks,n.yieldEvery);return await this.fitLoop(k,b,y,p,n.epochs,n.verbose,v,I,w,n.shuffle,S,n.initialEpoch,null,null)}finally{this.isTraining=!1,he(i,t),he(a,e),he(o,t),he(r,e),he(u,l),he(d,c),h!=null&&gt(h)}}async fitLoop(t,e,n,i,a,o,r,l,c,u,d,h,p,m){i==null&&(i=32),a==null&&(a=1),u==null&&(u=!0),h==null&&(h=0);let f=!1;if(l!=null&&c!=null&&(f=!0),m!=null&&(f=!0,p==null))throw new x("Can only use `validationSteps` when doing step-wise training, i.e., `stepsPerEpoch` must be set.");const g=this.checkNumSamples(e,i,p,"steps_per_epoch");let w;g!=null&&(w=be(0,g)),o==null&&(o=1);const{callbackList:b,history:k}=Xu(r,o,a,h,g,p,i,f,d);b.setModel(this),this.history=k,await b.onTrainBegin(),this.stopTraining_=!1;for(let y=h;y<a;++y){await b.onEpochBegin(y);const I={};if(p!=null)throw new it("stepsPerEpoch mode is not implemented yet.");{if(u==="batch")throw new it("batch shuffling is not implemneted yet");u&&up(w);const S=dn(w),v=Ui(g,i);for(let N=0;N<v.length;++N){const C={};if(await b.onBatchBegin(N,C),T(()=>{const D=v[N][0],E=v[N][1],V=ps(S,D,E-D);C.batch=N,C.size=E-D;const M=oa(e,V),L=t(M);for(let F=0;F<n.length;++F){const $=n[F],W=L[F];C[$]=W,Oe(W)}if(N===v.length-1&&f){const F=this.testLoop(l,c,i);for(let $=0;$<n.length;++$){const W=n[$],R=F[$];Oe(R),I["val_"+W]=R}}}),await b.onBatchEnd(N,C),Zu(C),this.stopTraining_)break}S.dispose()}if(await b.onEpochEnd(y,I),this.stopTraining_)break}return await b.onTrainEnd(),await this.history.syncData(),this.history}async fitDataset(t,e){return gI(this,t,e)}async trainOnBatch(t,e){const n=await this.standardizeUserData(t,e),i=n[0],a=n[1],r=this.makeTrainFunction()(i.concat(a)),l=[];for(const c of r){const u=await c.data();l.push(u[0])}return gt(r),he(n[0],t),he(n[1],e),jt(l)}getNamedWeights(t){const e=[],n=t!=null&&t.trainableOnly,i=n?this.trainableWeights:this.weights,a=this.getWeights(n);for(let o=0;o<i.length;++o)n&&!i[o].trainable||e.push({name:i[o].originalName,tensor:a[o]});return e}set stopTraining(t){this.stopTraining_=t}get stopTraining(){return this.stopTraining_}get optimizer(){return this.optimizer_}set optimizer(t){this.optimizer_!==t&&(this.optimizer_=t,this.isOptimizerOwned=!1)}dispose(){const t=super.dispose();if(t.refCountAfterDispose===0&&this.optimizer!=null&&this.isOptimizerOwned){const e=Yr().numTensors;this.optimizer_.dispose(),t.numDisposedVariables+=e-Yr().numTensors}return t}getLossIdentifiers(){let t;if(typeof this.loss=="string")t=Ee(this.loss);else if(Array.isArray(this.loss)){for(const e of this.loss)if(typeof e!="string")throw new Error("Serialization of non-string loss is not supported.");t=this.loss.map(e=>Ee(e))}else{const e=Object.keys(this.loss);t={};const n=this.loss;for(const i of e)if(typeof n[i]=="string")t[i]=Ee(n[i]);else throw new Error("Serialization of non-string loss is not supported.")}return t}getMetricIdentifiers(){if(typeof this.metrics=="string"||typeof this.metrics=="function")return[Ee(On(this.metrics))];if(Array.isArray(this.metrics))return this.metrics.map(t=>Ee(On(t)));{const t={};for(const e in this.metrics)t[e]=Ee(On(this.metrics[e]));return t}}getTrainingConfig(){return{loss:this.getLossIdentifiers(),metrics:this.getMetricIdentifiers(),optimizer_config:{class_name:this.optimizer.getClassName(),config:this.optimizer.getConfig()}}}loadTrainingConfig(t){if(t.weighted_metrics!=null)throw new Error("Loading weight_metrics is not supported yet.");if(t.loss_weights!=null)throw new Error("Loading loss_weights is not supported yet.");if(t.sample_weight_mode!=null)throw new Error("Loading sample_weight_mode is not supported yet.");const e=gn(t.optimizer_config),n=fe(e);let i;if(typeof t.loss=="string")i=us(t.loss);else if(Array.isArray(t.loss))i=t.loss.map(o=>us(o));else if(t.loss!=null){i={};for(const o in t.loss)i[o]=us(t.loss[o])}let a;if(Array.isArray(t.metrics))a=t.metrics.map(o=>us(o));else if(t.metrics!=null){a={};for(const o in t.metrics)a[o]=us(t.metrics[o])}this.compile({loss:i,metrics:a,optimizer:n})}async save(t,e){if(typeof t=="string"){const c=hp(t);if(c.length===0)throw new x(`Cannot find any save handlers for URL '${t}'`);if(c.length>1)throw new x(`Found more than one (${c.length}) save handlers for URL '${t}'`);t=c[0]}if(t.save==null)throw new x("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");const n=await Qr(this.getNamedWeights(e)),r={modelTopology:this.toJSON(null,!1),format:vI,generatedBy:`TensorFlow.js tfjs-layers v${Ro}`,convertedBy:null};if((e==null?!1:e.includeOptimizer)&&this.optimizer!=null){r.trainingConfig=this.getTrainingConfig();const c="optimizer",{data:u,specs:d}=await Qr(await this.optimizer.getWeights(),c);n.specs.push(...d),n.data=dp([n.data,u])}return this.userDefinedMetadata!=null&&(Il(this.userDefinedMetadata,this.name,!0),r.userDefinedMetadata=this.userDefinedMetadata),r.weightData=n.data,r.weightSpecs=n.specs,t.save(r)}setUserDefinedMetadata(t){Il(t,this.name),this.userDefinedMetadata=t}getUserDefinedMetadata(){return this.userDefinedMetadata}}Qe.className="Model";O(Qe);class lh extends Qe{}lh.className="Functional";O(lh);async function NI(s,t){"modelTopology"in s||(s={modelTopology:s}),s=s;let e=s.modelTopology;e.model_config!=null&&(e=e.model_config);const n=gn(e),i=fe(n,t);if(s.weightsManifest!=null){const a=await Cm(s.weightsManifest,s.pathPrefix,i.weights.map(r=>r.originalName)),o={};for(const r of i.weights)o[r.originalName]=a[r.originalName];i.loadWeights(o),gt(a)}return i}async function GT(s,t){if(t==null&&(t={}),typeof s=="string"){const e=pp(s,t);if(e.length===0)e.push(Nm(s,t));else if(e.length>1)throw new x(`Found more than one (${e.length}) load handlers for URL '${s}'`);s=e[0]}return CI(s,void 0,t)}async function CI(s,t,e){if(e==null&&(e={}),s.load==null)throw new x("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");const n=await s.load();let i=n.modelTopology;i.model_config!=null&&(i=i.model_config);const a=e.strict==null?!0:e.strict,o=n.weightData!=null&&n.weightSpecs!=null&&a,r=fe(gn(i),t,o),l=n.trainingConfig;if(l!=null&&r.loadTrainingConfig(l),n.userDefinedMetadata!=null&&r.setUserDefinedMetadata(n.userDefinedMetadata),n.weightData!=null){if(n.weightSpecs==null)throw new x("LayersModel artifacts contains weight data, but not weight specs. Therefore loading of weights cannot proceed.");const{modelWeights:c,optimizerWeights:u}=TI(n.weightData,n.weightSpecs);r.loadWeights(c,a),r.optimizer!=null&&u.length>0&&await r.optimizer.setWeights(u),gt(c),gt(u.map(d=>d.tensor))}return r}function TI(s,t){const e=fp(s,t),n={},i=[];return t.forEach(a=>{a.group==="optimizer"?i.push({name:a.name,tensor:e[a.name]}):n[a.name]=e[a.name]}),{modelWeights:n,optimizerWeights:i}}class _s extends Qe{constructor(t){if(super({inputs:[],outputs:[]}),t=t||{},this.trainable=!0,this.built=!1,this.name=t.name!=null?t.name:bi("sequential_"),t.layers!=null)for(const e of t.layers)this.add(e)}checkShape(t){if(t.inboundNodes[0].outputTensors[0].shape.some(n=>n<0))throw new x(`Negative dimension size caused by adding layer ${t.name} with input shape [${t.inboundNodes[0].inputTensors[0].shape}]`)}add(t){const e=t instanceof _s||t instanceof Qe;let n;if(e){if(n=t,n.outputs.length!==1)throw new x("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");if(n.inputs.length!==1)throw new x("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.")}if(this.outputs.length===0){if(t.inboundNodes.length===0){if(t.batchInputShape==null)throw new x("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");const i=Ku({batchShape:t.batchInputShape,dtype:t.dtype,name:t.name+"_input"});t.apply(i)}if(e)this.outputs=n.outputs,this.inputs=n.inputs;else{if(t.inboundNodes.length!==1)throw new x(`A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ${t.name} which has ${t.inboundNodes.length} pre-existing inbound connections.`);if(t.inboundNodes[0].outputTensors.length!==1)throw new x("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(t),this.outputs=[t.inboundNodes[0].outputTensors[0]],this.inputs=qu(this.outputs[0])}this.inboundNodes=[],new Ci({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:ms(null,this.inputs.length),outputMasks:[null],inputShapes:this.inputs.map(i=>i.shape),outputShapes:this.outputs[0].shape})}else{const i=t.apply(this.outputs[0]);if(Array.isArray(i))throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(t),this.outputs=[i],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}this.layers.push(t),this.built=!1}pop(){if(this.layers.length===0)throw new TypeError("There are no layers in the model.");if(this.layers.pop(),this.layers.length===0)this.outputs=[],this.inboundNodes=[],this.outboundNodes=[];else{const t=this.layers.length-1;this.layers[t].outboundNodes=[],this.outputs=[this.layers[t].output],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}}call(t,e){return this.model==null&&this.build(),this.model.call(t,e)}build(t){if(dt(t),this.inputs.length===0||this.outputs.length===0)throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");this.model=new Qe({inputs:this.inputs,outputs:this.outputs[0],name:this.name+"_model"}),this.model.trainable=this.trainable,this.supportsMasking=this.model.supportsMasking,this.inputLayers=this.model.inputLayers,this.inputLayersNodeIndices=this.model.inputLayersNodeIndices,this.inputLayersTensorIndices=this.model.inputLayersTensorIndices,this.outputLayers=this.model.outputLayers,this.outputLayersNodeIndices=this.model.outputLayersNodeIndices,this.outputLayersTensorIndices=this.model.outputLayersTensorIndices,this.nodesByDepth=this.model.nodesByDepth,this.containerNodes=this.model.containerNodes,this.outputNames=this.model.outputNames,this.inputNames=this.model.inputNames,this.built=!0}countParams(){return this.built||this.build(),super.countParams()}summary(t,e,n=console.log){this.built||this.build(),super.summary(t,e,n)}setWeights(t){this.model==null&&this.build(),this.model.setWeights(t)}evaluate(t,e,n={}){if(!this.built)throw new ie("The model needs to be compiled before being used.");return this.model.evaluate(t,e,n)}async evaluateDataset(t,e){if(!this.built)throw new ie("The model needs to be compiled before being used.");return this.model.evaluateDataset(t,e)}predict(t,e={}){return this.model==null&&this.build(),this.model.predict(t,e)}predictOnBatch(t){return this.model==null&&this.build(),this.model.predictOnBatch(t)}compile(t){this.build(),this.model.compile(t),this.optimizer_=this.model.optimizer,this.isOptimizerOwned=this.model.isOptimizerOwned,this.loss=this.model.loss,this.metrics=this.model.metrics,this.metricsTensors=this.model.metricsTensors,this.metricsNames=this.model.metricsNames}get optimizer(){return this.model==null?void 0:this.model.optimizer}set optimizer(t){this.model.optimizer=t}async fit(t,e,n={}){if(!this.built)throw new ie("The model needs to be compiled before being used.");return this.model.fit(t,e,n)}async fitDataset(t,e){if(!this.built)throw new ie("The model needs to be compiled before being used.");return this.model.fitDataset(t,e)}async trainOnBatch(t,e){return this.model.trainOnBatch(t,e)}static fromConfig(t,e,n={},i=!1){let a,o={};if(e instanceof Array){if(e[0].className==null||e[0].className==="Merge")throw new x("Legacy serialization format not supported yet.");a=e}else K(e.layers!=null,()=>"When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field."),a=e.layers,delete e.layers,o=e;const r=new t(o);if(!(r instanceof _s))throw new it(`Sequential.fromConfig called on non-Sequential input: ${r}`);for(const l of a){const u=fe(l,void 0,i);i&&u.setFastWeightInitDuringBuild(!0),r.add(u)}return r}set stopTraining(t){if(this.model==null)throw new x("Cannot set the stopTraining property of a sequential model before it is compiled.");this.model.stopTraining=t}get stopTraining(){if(this.model==null)throw new x("Cannot get the stopTraining property of a sequential model before it is compiled.");return this.model.stopTraining}getConfig(){const t=[];for(const e of this.layers){const n={};n.className=e.getClassName(),n.config=e.getConfig(),t.push(n)}return{name:this.name,layers:t}}}_s.className="Sequential";O(_s);function HT(s){return new Qe(s)}function UT(s){return new _s(s)}function AI(s){return Ku(s)}function jT(s,t){Yt.registerCallbackConstructor(s,t)}let Ht=class extends wn{getConfig(){return{}}};class ch extends Ht{apply(t,e=1){return qw(t,e)}}ch.className="elu";O(ch);class uh extends Ht{apply(t){return ku(t)}}uh.className="selu";O(uh);class hh extends Ht{apply(t){return Ps(t)}}hh.className="relu";O(hh);class dh extends Ht{apply(t){return T(()=>so(6,Ps(t)))}}dh.className="relu6";O(dh);class ph extends Ht{apply(t){return t}}ph.className="linear";O(ph);class fh extends Ht{apply(t){return li(t)}}fh.className="sigmoid";O(fh);class mh extends Ht{apply(t){return Zw(t)}}mh.className="hardSigmoid";O(mh);class gh extends Ht{apply(t){return di(t)}}gh.className="softplus";O(gh);class bh extends Ht{apply(t){return Kw(t)}}bh.className="softsign";O(bh);class yh extends Ht{apply(t){return fi(t)}}yh.className="tanh";O(yh);let Eo=class extends Ht{apply(t,e=-1){return no(t,e)}};Eo.className="softmax";O(Eo);class wh extends Ht{apply(t,e=-1){return mu(t,e)}}wh.className="logSoftmax";O(wh);class kh extends Ht{apply(t){return T(()=>T(()=>{const e=Math.sqrt(2),n=A(.5,X(1,fu(ut(t,e))));return A(t,n)}))}}kh.className="gelu";O(kh);class Ih extends Ht{apply(t){return T(()=>A(.5,A(t,X(1,fi(A(Be(ut(2,Math.PI)),X(t,A(.044715,ri(t,3)))))))))}}Ih.className="gelu_new";O(Ih);class xh extends Ht{apply(t){return T(()=>A(t,fi(di(t))))}}xh.className="mish";O(xh);class Sh extends Ht{apply(t,e=1){return T(()=>A(li(A(t,e)),t))}}Sh.className="swish";O(Sh);function is(s){return s.getClassName()}function ji(s,t={}){return Sn(s,kn.getMap().classNameMap,t,"activation")}function as(s){if(s==null){const t={};return t.className="linear",t.config={},ji(t)}if(typeof s=="string"){const t={};return t.className=s,t.config={},ji(t)}else return s instanceof Ht?s:ji(s)}function Lo(s){if(s!=null&&typeof s!="object")throw new Error(`Argument to L1L2 regularizer's constructor is expected to be an object, but received: ${s}`)}class vh extends wn{}class An extends vh{constructor(t){super(),Lo(t),this.l1=t==null||t.l1==null?.01:t.l1,this.l2=t==null||t.l2==null?.01:t.l2,this.hasL1=this.l1!==0,this.hasL2=this.l2!==0}apply(t){return T(()=>{let e=Qt([1]);return this.hasL1&&(e=X(e,lt(A(this.l1,fs(t))))),this.hasL2&&(e=X(e,lt(A(this.l2,Nn(t))))),B(e,[])})}getConfig(){return{l1:this.l1,l2:this.l2}}static fromConfig(t,e){return new t({l1:e.l1,l2:e.l2})}}An.className="L1L2";O(An);function DI(s){return Lo(s),new An({l1:s!=null?s.l1:null,l2:0})}function zI(s){return Lo(s),new An({l2:s!=null?s.l2:null,l1:0})}const Tl={l1l2:"L1L2"};function yt(s){return fo(s)}function Al(s,t={}){return Sn(s,kn.getMap().classNameMap,t,"regularizer")}function Nt(s){if(s==null)return null;if(typeof s=="string"){const e={className:s in Tl?Tl[s]:s,config:{}};return Al(e)}else return s instanceof vh?s:Al(s)}class Oo extends rt{constructor(t){super(t??{}),this.supportsMasking=!0,t!=null&&(this.maxValue=t.maxValue)}call(t,e){t=nt(t);let n=Ps(t);return this.maxValue!=null&&(n=te(n,0,this.maxValue)),n}computeOutputShape(t){return t}getConfig(){const t={maxValue:this.maxValue},e=super.getConfig();return Object.assign(t,e),t}}Oo.className="ReLU";O(Oo);class _o extends rt{constructor(t){super(t??{}),this.DEFAULT_ALPHA=.3,t==null&&(t={}),this.alpha=t.alpha==null?this.DEFAULT_ALPHA:t.alpha}call(t,e){const n=nt(t);return Gc(n,this.alpha)}computeOutputShape(t){return t}getConfig(){const t={alpha:this.alpha},e=super.getConfig();return Object.assign(t,e),t}}_o.className="LeakyReLU";O(_o);class Wo extends rt{constructor(t){if(super(t??{}),this.DEFAULT_ALPHA_INITIALIZER="zeros",t==null&&(t={}),this.supportsMasking=!0,this.alphaInitializer=vt(t.alphaInitializer||this.DEFAULT_ALPHA_INITIALIZER),this.alphaRegularizer=Nt(t.alphaRegularizer),this.alphaConstraint=Et(t.alphaConstraint),t.sharedAxes==null)this.sharedAxes=null;else if(Array.isArray(t.sharedAxes))this.sharedAxes=t.sharedAxes;else if(typeof t.sharedAxes=="number")this.sharedAxes=[t.sharedAxes];else throw new x(`Expected sharedAxes to be a number or an array of numbers, but got ${t.sharedAxes}`)}build(t){t=dt(t);const e=t.slice(1);if(this.sharedAxes!=null)for(const i of this.sharedAxes)e[i-1]=1;this.alpha=this.addWeight("alpha",e,"float32",this.alphaInitializer,this.alphaRegularizer,!0,this.alphaConstraint);const n={};if(this.sharedAxes!=null)for(let i=1;i<t.length;++i)n[i]=t[i];this.inputSpec=[new Mt({ndim:t.length,axes:n})],this.built=!0}call(t,e){return t=nt(t),Hc(t,this.alpha.read())}getConfig(){const t={alphaInitializer:Tt(this.alphaInitializer),alphaRegularizer:yt(this.alphaRegularizer),alphaConstraint:Rt(this.alphaConstraint),sharedAxes:this.sharedAxes},e=super.getConfig();return Object.assign(t,e),t}}Wo.className="PReLU";O(Wo);class Vo extends rt{constructor(t){if(super(t??{}),this.DEFAULT_ALPHA=1,t==null&&(t={}),t.alpha!=null&&t.alpha!==this.DEFAULT_ALPHA)throw new it(`Non-default alpha value (${t.alpha}) is not supported by the ELU layer yet.`);this.alpha=t.alpha==null?this.DEFAULT_ALPHA:t.alpha}call(t,e){const n=nt(t);return Pa(n)}computeOutputShape(t){return t}getConfig(){const t={alpha:this.alpha},e=super.getConfig();return Object.assign(t,e),t}}Vo.className="ELU";O(Vo);class Bo extends rt{constructor(t){super(t??{}),this.DEFAULT_THETA=1,t==null&&(t={}),this.theta=t.theta==null?this.DEFAULT_THETA:t.theta}call(t,e){const n=nt(t);return A(n,J(ke(n,this.theta),"float32"))}computeOutputShape(t){return t}getConfig(){const t={theta:this.theta},e=super.getConfig();return Object.assign(t,e),t}}Bo.className="ThresholdedReLU";O(Bo);class Po extends rt{constructor(t){super(t??{}),this.DEFAULT_AXIS=1,t==null&&(t={}),this.softmax=new Eo().apply,this.axis=t.axis==null?this.DEFAULT_AXIS:t.axis}call(t,e){return T(()=>{let n=nt(t);const i=e.mask;if(i!=null){const a=A(pt(Is(n.shape),J(i,n.dtype)),zt(-1e9));n=X(n,a)}return this.axis instanceof Array?this.axis.length>1?ks(pt(n,gu(n,this.axis,!0))):this.softmax(n,this.axis[0]):this.softmax(n,this.axis)})}computeOutputShape(t){return t}getConfig(){const t={axis:this.axis},e=super.getConfig();return Object.assign(t,e),t}}Po.className="Softmax";O(Po);function Fs(s,t,e){if(typeof s=="number")return ms(s,t);if(s.length!==t)throw new x(`The ${e} argument must be an integer or tuple of ${t} integers. Received: ${s.length} elements.`);for(let n=0;n<t;++n){const i=s[n];if(!Gw(i))throw new x(`The ${e} argument must be an integer or tuple of ${t} integers. Received: ${JSON.stringify(s)} including a non-integer number ${i}`)}return s}function me(s,t,e,n,i=1){if(s==null)return s;const a=t+(t-1)*(i-1);let o;return e==="same"?o=s:o=s-a+1,Math.floor((o+n-1)/n)}function ve(s,t,e,n){if(s==null)return null;if(n==="valid")s=s*t+ns([e-t,0]);else if(n==="same")s=s*t;else throw new x(`Unsupport padding mode: ${n}.`);return s}function Go(s,t){return T(()=>(Ft(t),t==="channelsFirst"?ht(s,[0,2,3,1]):s))}function Nh(s,t){return T(()=>(Ft(t),t==="channelsFirst"?ht(s,[0,2,3,4,1]):s))}function FI(s,t,e,n=1,i="valid",a,o=1){return T(()=>{if(a==null&&(a=ye()),Ft(a),s.shape.length!==3)throw new x(`The input of a conv1dWithBias operation should be 3, but is ${s.shape.length} instead.`);if(t.shape.length!==3)throw new x(`The kernel for a conv1dWithBias operation should be 3, but is ${t.shape.length} instead`);if(e!=null&&e.shape.length!==1)throw new x(`The bias for a conv1dWithBias operation should be 1, but is ${e.shape.length} instead`);if(a==="channelsFirst"&&(s=ht(s,[0,2,1])),i==="causal")throw new it("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");let r=hu(s,t,n,i==="same"?"same":"valid","NWC",o);return e!=null&&(r=Ie(r,e)),r})}function Dl(s,t,e,n=[1,1],i="valid",a,o,r=null){return T(()=>{if(a==null&&(a=ye()),Ft(a),s.rank!==3&&s.rank!==4)throw new x(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${s.rank}.`);if(t.rank!==3&&t.rank!==4)throw new x(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${s.rank}.`);let l=Go(s,a);if(i==="causal")throw new it("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");return l=Am({x:l,filter:t,strides:n,pad:i==="same"?"same":"valid",dilations:o,dataFormat:"NHWC",bias:e,activation:r}),a==="channelsFirst"&&(l=ht(l,[0,3,1,2])),l})}function $I(s,t,e,n=[1,1,1],i="valid",a,o){return T(()=>{if(a==null&&(a=ye()),Ft(a),s.rank!==4&&s.rank!==5)throw new x(`conv3dWithBias expects input to be of rank 4 or 5, but received ${s.rank}.`);if(t.rank!==4&&t.rank!==5)throw new x(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${s.rank}.`);let r=Nh(s,a);if(i==="causal")throw new it("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");return r=Dm(r,t,n,i==="same"?"same":"valid","NDHWC",o),e!=null&&(r=Ie(r,e)),a==="channelsFirst"&&(r=ht(r,[0,4,1,2,3])),r})}class Di extends rt{constructor(t,e){if(super(e),this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",Di.verifyArgs(e),this.rank=t,_t(this.rank,"rank"),this.rank!==1&&this.rank!==2&&this.rank!==3)throw new it(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);if(this.kernelSize=Fs(e.kernelSize,t,"kernelSize"),this.strides=Fs(e.strides==null?1:e.strides,t,"strides"),this.padding=e.padding==null?"valid":e.padding,se(this.padding),this.dataFormat=e.dataFormat==null?"channelsLast":e.dataFormat,Ft(this.dataFormat),this.activation=as(e.activation),this.useBias=e.useBias==null?!0:e.useBias,this.biasInitializer=vt(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.biasConstraint=Et(e.biasConstraint),this.biasRegularizer=Nt(e.biasRegularizer),this.activityRegularizer=Nt(e.activityRegularizer),this.dilationRate=Fs(e.dilationRate==null?1:e.dilationRate,t,"dilationRate"),this.rank===1&&Array.isArray(this.dilationRate)&&this.dilationRate.length!==1)throw new x(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);if(this.rank===2){if(typeof this.dilationRate=="number")this.dilationRate=[this.dilationRate,this.dilationRate];else if(this.dilationRate.length!==2)throw new x(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`)}else if(this.rank===3){if(typeof this.dilationRate=="number")this.dilationRate=[this.dilationRate,this.dilationRate,this.dilationRate];else if(this.dilationRate.length!==3)throw new x(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`)}}static verifyArgs(t){if(Se("kernelSize"in t,"required key 'kernelSize' not in config"),typeof t.kernelSize!="number"&&!mo(t.kernelSize,"number",1,3))throw new x(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(t.kernelSize)}.`)}getConfig(){const t={kernelSize:this.kernelSize,strides:this.strides,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,activation:is(this.activation),useBias:this.useBias,biasInitializer:Tt(this.biasInitializer),biasRegularizer:yt(this.biasRegularizer),activityRegularizer:yt(this.activityRegularizer),biasConstraint:Rt(this.biasConstraint)},e=super.getConfig();return Object.assign(t,e),t}}class Zs extends Di{constructor(t,e){super(t,e),this.kernel=null,Zs.verifyArgs(e),this.filters=e.filters,_t(this.filters,"filters"),this.kernelInitializer=vt(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.kernelConstraint=Et(e.kernelConstraint),this.kernelRegularizer=Nt(e.kernelRegularizer)}build(t){t=dt(t);const e=this.dataFormat==="channelsFirst"?1:t.length-1;if(t[e]==null)throw new x(`The channel dimension of the input should be defined. Found ${t[e]}`);const n=t[e],i=this.kernelSize.concat([n,this.filters]);this.kernel=this.addWeight("kernel",i,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[{ndim:this.rank+2,axes:{[e]:n}}],this.built=!0}call(t,e){return T(()=>{t=nt(t);let n;const i=this.bias==null?null:this.bias.read(),a=Wu(this.activation.getClassName());if(a!=null&&this.rank===2)n=Dl(t,this.kernel.read(),i,this.strides,this.padding,this.dataFormat,this.dilationRate,a);else{if(this.rank===1)n=FI(t,this.kernel.read(),i,this.strides[0],this.padding,this.dataFormat,this.dilationRate[0]);else if(this.rank===2)n=Dl(t,this.kernel.read(),i,this.strides,this.padding,this.dataFormat,this.dilationRate);else if(this.rank===3)n=$I(t,this.kernel.read(),i,this.strides,this.padding,this.dataFormat,this.dilationRate);else throw new it("convolutions greater than 3D are not implemented yet.");this.activation!=null&&(n=this.activation.apply(n))}return n})}computeOutputShape(t){t=dt(t);const e=[],n=this.dataFormat==="channelsLast"?t.slice(1,t.length-1):t.slice(2);for(let a=0;a<n.length;++a){const o=me(n[a],this.kernelSize[a],this.padding,this.strides[a],typeof this.dilationRate=="number"?this.dilationRate:this.dilationRate[a]);e.push(o)}let i=[t[0]];return this.dataFormat==="channelsLast"?(i=i.concat(e),i.push(this.filters)):(i.push(this.filters),i=i.concat(e)),i}getConfig(){const t={filters:this.filters,kernelInitializer:Tt(this.kernelInitializer),kernelRegularizer:yt(this.kernelRegularizer),kernelConstraint:Rt(this.kernelConstraint)},e=super.getConfig();return Object.assign(t,e),t}static verifyArgs(t){if(!("filters"in t)||typeof t.filters!="number"||t.filters<1)throw new x(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(t.filters)}`)}}class Js extends Zs{constructor(t){super(2,t),Js.verifyArgs(t)}getConfig(){const t=super.getConfig();return delete t.rank,t}static verifyArgs(t){if(typeof t.kernelSize!="number"&&!mo(t.kernelSize,"number",1,2))throw new x(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(t.kernelSize)}.`)}}Js.className="Conv2D";O(Js);class Xs extends Zs{constructor(t){super(3,t),Xs.verifyArgs(t)}getConfig(){const t=super.getConfig();return delete t.rank,t}static verifyArgs(t){if(typeof t.kernelSize!="number"&&!(Array.isArray(t.kernelSize)&&(t.kernelSize.length===1||t.kernelSize.length===3)))throw new x(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(t.kernelSize)}.`)}}Xs.className="Conv3D";O(Xs);class Ho extends Js{constructor(t){if(super(t),this.inputSpec=[new Mt({ndim:4})],this.padding!=="same"&&this.padding!=="valid")throw new x(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(t){if(t=dt(t),t.length!==4)throw new x("Input should have rank 4; Received input shape: "+JSON.stringify(t));const e=this.dataFormat==="channelsFirst"?1:t.length-1;if(t[e]==null)throw new x("The channel dimension of the inputs should be defined. Found `None`.");const n=t[e],i=this.kernelSize.concat([this.filters,n]);this.kernel=this.addWeight("kernel",i,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new Mt({ndim:4,axes:{[e]:n}})],this.built=!0}call(t,e){return T(()=>{let n=nt(t);if(n.shape.length!==4)throw new x(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${n.shape.length}`);const i=n.shape,a=i[0];let o,r;this.dataFormat==="channelsFirst"?(o=2,r=3):(o=1,r=2);const l=i[o],c=i[r],u=this.kernelSize[0],d=this.kernelSize[1],h=this.strides[0],p=this.strides[1],m=ve(l,h,u,this.padding),f=ve(c,p,d,this.padding),g=[a,m,f,this.filters];this.dataFormat!=="channelsLast"&&(n=ht(n,[0,2,3,1]));let w=du(n,this.kernel.read(),g,this.strides,this.padding);return this.dataFormat!=="channelsLast"&&(w=ht(w,[0,3,1,2])),this.bias!=null&&(w=Ie(w,this.bias.read(),this.dataFormat)),this.activation!=null&&(w=this.activation.apply(w)),w})}computeOutputShape(t){t=dt(t);const e=t.slice();let n,i,a;this.dataFormat==="channelsFirst"?(n=1,i=2,a=3):(n=3,i=1,a=2);const o=this.kernelSize[0],r=this.kernelSize[1],l=this.strides[0],c=this.strides[1];return e[n]=this.filters,e[i]=ve(e[i],l,o,this.padding),e[a]=ve(e[a],c,r,this.padding),e}getConfig(){const t=super.getConfig();return delete t.dilationRate,t}}Ho.className="Conv2DTranspose";O(Ho);class Uo extends Xs{constructor(t){if(super(t),this.inputSpec=[new Mt({ndim:5})],this.padding!=="same"&&this.padding!=="valid")throw new x(`Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(t){if(t=dt(t),t.length!==5)throw new x("Input should have rank 5; Received input shape: "+JSON.stringify(t));const e=this.dataFormat==="channelsFirst"?1:t.length-1;if(t[e]==null)throw new x("The channel dimension of the inputs should be defined. Found `None`.");const n=t[e],i=this.kernelSize.concat([this.filters,n]);this.kernel=this.addWeight("kernel",i,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new Mt({ndim:5,axes:{[e]:n}})],this.built=!0}call(t,e){return T(()=>{let n=nt(t);if(n.shape.length!==5)throw new x(`Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${n.shape.length}`);const i=n.shape,a=i[0];let o,r,l;this.dataFormat==="channelsFirst"?(l=2,o=3,r=4):(l=1,o=2,r=3);const c=i[l],u=i[o],d=i[r],h=this.kernelSize[0],p=this.kernelSize[1],m=this.kernelSize[2],f=this.strides[0],g=this.strides[1],w=this.strides[2],b=ve(c,f,h,this.padding),k=ve(u,g,p,this.padding),y=ve(d,w,m,this.padding),I=[a,b,k,y,this.filters];this.dataFormat!=="channelsLast"&&(n=ht(n,[0,2,3,4,1]));let S=Tm(n,this.kernel.read(),I,this.strides,this.padding);return this.dataFormat!=="channelsLast"&&(S=ht(S,[0,4,1,2,3])),this.bias!==null&&(S=Ie(S,this.bias.read(),this.dataFormat)),this.activation!==null&&(S=this.activation.apply(S)),S})}computeOutputShape(t){t=dt(t);const e=t.slice();let n,i,a,o;this.dataFormat==="channelsFirst"?(n=1,i=2,a=3,o=4):(n=4,i=1,a=2,o=3);const r=this.kernelSize[0],l=this.kernelSize[1],c=this.kernelSize[2],u=this.strides[0],d=this.strides[1],h=this.strides[2];return e[n]=this.filters,e[i]=ve(e[i],u,r,this.padding),e[a]=ve(e[a],d,l,this.padding),e[o]=ve(e[o],h,c,this.padding),e}getConfig(){const t=super.getConfig();return delete t.dilationRate,t}}Uo.className="Conv3DTranspose";O(Uo);class Ch extends Zs{constructor(t,e){if(super(t,e),this.DEFAULT_DEPTHWISE_INITIALIZER="glorotUniform",this.DEFAULT_POINTWISE_INITIALIZER="glorotUniform",this.depthwiseKernel=null,this.pointwiseKernel=null,e.filters==null)throw new x("The `filters` configuration field is required by SeparableConv, but is unspecified.");if(e.kernelInitializer!=null||e.kernelRegularizer!=null||e.kernelConstraint!=null)throw new x("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");if(e.padding!=null&&e.padding!=="same"&&e.padding!=="valid")throw new x(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(e.padding)}`);this.depthMultiplier=e.depthMultiplier==null?1:e.depthMultiplier,this.depthwiseInitializer=vt(e.depthwiseInitializer||this.DEFAULT_DEPTHWISE_INITIALIZER),this.depthwiseRegularizer=Nt(e.depthwiseRegularizer),this.depthwiseConstraint=Et(e.depthwiseConstraint),this.pointwiseInitializer=vt(e.depthwiseInitializer||this.DEFAULT_POINTWISE_INITIALIZER),this.pointwiseRegularizer=Nt(e.pointwiseRegularizer),this.pointwiseConstraint=Et(e.pointwiseConstraint)}build(t){if(t=dt(t),t.length<this.rank+2)throw new x(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank+2}, but received input shape: ${JSON.stringify(t)}`);const e=this.dataFormat==="channelsFirst"?1:t.length-1;if(t[e]==null||t[e]<0)throw new x(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(t[e])}`);const n=t[e],i=this.kernelSize.concat([n,this.depthMultiplier]),a=[];for(let r=0;r<this.rank;++r)a.push(1);a.push(n*this.depthMultiplier,this.filters);const o=!0;this.depthwiseKernel=this.addWeight("depthwise_kernel",i,"float32",this.depthwiseInitializer,this.depthwiseRegularizer,o,this.depthwiseConstraint),this.pointwiseKernel=this.addWeight("pointwise_kernel",a,"float32",this.pointwiseInitializer,this.pointwiseRegularizer,o,this.pointwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,o,this.biasConstraint):this.bias=null,this.inputSpec=[new Mt({ndim:this.rank+2,axes:{[e]:n}})],this.built=!0}call(t,e){return T(()=>{t=nt(t);let n;if(this.rank===1)throw new it("1D separable convolution is not implemented yet.");return this.rank===2&&(this.dataFormat==="channelsFirst"&&(t=ht(t,[0,2,3,1])),n=Iu(t,this.depthwiseKernel.read(),this.pointwiseKernel.read(),this.strides,this.padding,this.dilationRate,"NHWC")),this.useBias&&(n=Ie(n,this.bias.read(),this.dataFormat)),this.activation!=null&&(n=this.activation.apply(n)),this.dataFormat==="channelsFirst"&&(n=ht(n,[0,3,1,2])),n})}getConfig(){const t=super.getConfig();return delete t.rank,delete t.kernelInitializer,delete t.kernelRegularizer,delete t.kernelConstraint,t.depthwiseInitializer=Tt(this.depthwiseInitializer),t.pointwiseInitializer=Tt(this.pointwiseInitializer),t.depthwiseRegularizer=yt(this.depthwiseRegularizer),t.pointwiseRegularizer=yt(this.pointwiseRegularizer),t.depthwiseConstraint=Rt(this.depthwiseConstraint),t.pointwiseConstraint=Rt(this.pointwiseConstraint),t}}Ch.className="SeparableConv";class jo extends Ch{constructor(t){super(2,t)}}jo.className="SeparableConv2D";O(jo);class Dn extends Zs{constructor(t){super(1,t),Dn.verifyArgs(t),this.inputSpec=[{ndim:3}]}getConfig(){const t=super.getConfig();return delete t.rank,delete t.dataFormat,t}static verifyArgs(t){if(typeof t.kernelSize!="number"&&!mo(t.kernelSize,"number",1,1))throw new x(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(t.kernelSize)}.`)}}Dn.className="Conv1D";O(Dn);class qo extends rt{constructor(t){super(t),typeof t.cropping=="number"?this.cropping=[[t.cropping,t.cropping],[t.cropping,t.cropping]]:typeof t.cropping[0]=="number"?this.cropping=[[t.cropping[0],t.cropping[0]],[t.cropping[1],t.cropping[1]]]:this.cropping=t.cropping,this.dataFormat=t.dataFormat===void 0?"channelsLast":t.dataFormat,this.inputSpec=[{ndim:4}]}computeOutputShape(t){return this.dataFormat==="channelsFirst"?[t[0],t[1],t[2]-this.cropping[0][0]-this.cropping[0][1],t[3]-this.cropping[1][0]-this.cropping[1][1]]:[t[0],t[1]-this.cropping[0][0]-this.cropping[0][1],t[2]-this.cropping[1][0]-this.cropping[1][1],t[3]]}call(t,e){return T(()=>{if(t=nt(t),this.dataFormat==="channelsLast"){const n=Ln(t,this.cropping[0][0],t.shape[1]-this.cropping[0][0]-this.cropping[0][1],2);return Ln(n,this.cropping[1][0],t.shape[2]-this.cropping[1][1]-this.cropping[1][0],3)}else{const n=Ln(t,this.cropping[0][0],t.shape[2]-this.cropping[0][0]-this.cropping[0][1],3);return Ln(n,this.cropping[1][0],t.shape[3]-this.cropping[1][1]-this.cropping[1][0],4)}})}getConfig(){const t={cropping:this.cropping,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}qo.className="Cropping2D";O(qo);class Ko extends rt{constructor(t){super(t),this.DEFAULT_SIZE=[2,2],this.inputSpec=[{ndim:4}],this.size=t.size==null?this.DEFAULT_SIZE:t.size,this.dataFormat=t.dataFormat==null?"channelsLast":t.dataFormat,Ft(this.dataFormat),this.interpolation=t.interpolation==null?"nearest":t.interpolation,Vw(this.interpolation)}computeOutputShape(t){if(this.dataFormat==="channelsFirst"){const e=t[2]==null?null:this.size[0]*t[2],n=t[3]==null?null:this.size[1]*t[3];return[t[0],t[1],e,n]}else{const e=t[1]==null?null:this.size[0]*t[1],n=t[2]==null?null:this.size[1]*t[2];return[t[0],e,n,t[3]]}}call(t,e){return T(()=>{let n=nt(t);const i=n.shape;if(this.dataFormat==="channelsFirst"){n=ht(n,[0,2,3,1]);const a=this.size[0]*i[2],o=this.size[1]*i[3],r=this.interpolation==="nearest"?Ce.resizeNearestNeighbor(n,[a,o]):Ce.resizeBilinear(n,[a,o]);return ht(r,[0,3,1,2])}else{const a=this.size[0]*i[1],o=this.size[1]*i[2];return this.interpolation==="nearest"?Ce.resizeNearestNeighbor(n,[a,o]):Ce.resizeBilinear(n,[a,o])}})}getConfig(){const t={size:this.size,dataFormat:this.dataFormat,interpolation:this.interpolation},e=super.getConfig();return Object.assign(t,e),t}}Ko.className="UpSampling2D";O(Ko);function MI(s,t,e=[1,1],n="valid",i,a){return T(()=>{i==null&&(i=ye()),Ft(i);let o=Go(s,i);if(s.rank!==4)throw new x(`Input for depthwiseConv2d is required to be 4-D, but is instead ${s.rank}-D`);if(t.rank!==4)throw new x(`depthwiseKernel is required to be 4-D, but is instead ${t.rank}-D`);return o=pu(o,t,e,n==="same"?"same":"valid","NHWC",a),i==="channelsFirst"&&(o=ht(o,[0,3,1,2])),o})}class Zo extends Di{constructor(t){super(2,t),this.depthwiseKernel=null,this.depthMultiplier=t.depthMultiplier==null?1:t.depthMultiplier,this.depthwiseInitializer=vt(t.depthwiseInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.depthwiseConstraint=Et(t.depthwiseConstraint),this.depthwiseRegularizer=Nt(t.depthwiseRegularizer)}build(t){if(t=dt(t),t.length<4)throw new x(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(t)}.`);const e=this.dataFormat==="channelsFirst"?1:3;if(t[e]==null||t[e]<0)throw new x(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${t[e]}).`);const n=t[e],i=[this.kernelSize[0],this.kernelSize[1],n,this.depthMultiplier];this.depthwiseKernel=this.addWeight("depthwise_kernel",i,null,this.depthwiseInitializer,this.depthwiseRegularizer,!0,this.depthwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[n*this.depthMultiplier],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(t,e){return T(()=>{t=nt(t);let n=MI(t,this.depthwiseKernel.read(),this.strides,this.padding,this.dataFormat,null);return this.useBias&&(n=Ie(n,this.bias.read(),this.dataFormat)),this.activation!=null&&(n=this.activation.apply(n)),n})}computeOutputShape(t){t=dt(t);const e=this.dataFormat==="channelsFirst"?t[2]:t[1],n=this.dataFormat==="channelsFirst"?t[3]:t[2],i=this.dataFormat==="channelsFirst"?t[1]*this.depthMultiplier:t[3]*this.depthMultiplier,a=me(e,this.kernelSize[0],this.padding,this.strides[0]),o=me(n,this.kernelSize[1],this.padding,this.strides[1]);return this.dataFormat==="channelsFirst"?[t[0],i,a,o]:[t[0],a,o,i]}getConfig(){const t=super.getConfig();return t.depthMultiplier=this.depthMultiplier,t.depthwiseInitializer=Tt(this.depthwiseInitializer),t.depthwiseRegularizer=yt(this.depthwiseRegularizer),t.depthwiseConstraint=Rt(this.depthwiseRegularizer),t}}Zo.className="DepthwiseConv2D";O(Zo);function Th(s,t,e,n){if(Array.isArray(s)){if(t!=null||e!=null)throw new x("When inputs is an array, neither initialState or constants should be provided");n!=null&&(e=s.slice(s.length-n,s.length),s=s.slice(0,s.length-n)),s.length>1&&(t=s.slice(1,s.length)),s=s[0]}function i(a){return a==null||Array.isArray(a)?a:[a]}return t=i(t),e=i(e),{inputs:s,initialState:t,constants:e}}function Ah(s,t,e,n=!1,i,a,o=!1,r=!1){return T(()=>{const l=t.shape.length;if(l<3)throw new x(`Input should be at least 3D, but is ${l}D.`);const c=[1,0].concat(be(2,l));t=ht(t,c),o&&console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend."),i!=null&&(i=J(J(i,"bool"),"float32"),i.rank===l-1&&(i=Ve(i,-1)),i=ht(i,c)),n&&(t=un(t,0),i!=null&&(i=un(i,0)));const u=[];let d,h=e;const p=t.shape[0],m=cn(t);let f;i!=null&&(f=cn(i));for(let w=0;w<p;++w){const b=m[w],k=T(()=>s(b,h));if(i==null)d=k[0],h=k[1];else{const y=T(()=>{const I=f[w],S=pt(le(I),I),v=X(A(k[0],I),A(h[0],S)),N=h.map((C,D)=>X(A(k[1][D],I),A(C,S)));return{output:v,newStates:N}});d=y.output,h=y.newStates}r&&u.push(d)}let g;return r&&(g=Us(u,1)),[d,g,h]})}class $e extends rt{constructor(t){super(t);let e;if(t.cell==null)throw new x("cell property is missing for the constructor of RNN.");if(Array.isArray(t.cell)?e=new $i({cells:t.cell}):e=t.cell,e.stateSize==null)throw new x("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");this.cell=e,this.returnSequences=t.returnSequences==null?!1:t.returnSequences,this.returnState=t.returnState==null?!1:t.returnState,this.goBackwards=t.goBackwards==null?!1:t.goBackwards,this._stateful=t.stateful==null?!1:t.stateful,this.unroll=t.unroll==null?!1:t.unroll,this.supportsMasking=!0,this.inputSpec=[new Mt({ndim:3})],this.stateSpec=null,this.states_=null,this.numConstants=null,this.keptStates=[]}getStates(){if(this.states_==null){const t=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1;return be(0,t).map(e=>null)}else return this.states_}setStates(t){this.states_=t}computeOutputShape(t){sa(t)&&(t=t[0]),t=t;let e=this.cell.stateSize;Array.isArray(e)||(e=[e]);const n=e[0];let i;if(this.returnSequences?i=[t[0],t[1],n]:i=[t[0],n],this.returnState){const a=[];for(const o of e)a.push([t[0],o]);return[i].concat(a)}else return i}computeMask(t,e){return T(()=>{Array.isArray(e)&&(e=e[0]);const n=this.returnSequences?e:null;if(this.returnState){const i=this.states.map(a=>null);return[n].concat(i)}else return n})}get states(){if(this.states_==null){const t=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1,e=[];for(let n=0;n<t;++n)e.push(null);return e}else return this.states_}set states(t){this.states_=t}build(t){if(this.numConstants!=null)throw new it("Constants support is not implemented in RNN yet.");sa(t)&&(t=t[0]),t=t;const e=this.stateful?t[0]:null,n=t.slice(2);this.inputSpec[0]=new Mt({shape:[e,null,...n]});const i=[t[0]].concat(t.slice(2));this.cell.build(i);let a;if(Array.isArray(this.cell.stateSize)?a=this.cell.stateSize:a=[this.cell.stateSize],this.stateSpec!=null){if(!Jt(this.stateSpec.map(o=>o.shape[o.shape.length-1]),a))throw new x(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is ${this.cell.stateSize}`)}else this.stateSpec=a.map(o=>new Mt({shape:[null,o]}));this.stateful&&this.resetStates()}resetStates(t,e=!1){T(()=>{if(!this.stateful)throw new xe("Cannot call resetStates() on an RNN Layer that is not stateful.");const n=this.inputSpec[0].shape[0];if(n==null)throw new x("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(this.states_==null)Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(i=>Qt([n,i])):this.states_=[Qt([n,this.cell.stateSize])];else if(t==null)gt(this.states_),this.keptStates!=null&&(gt(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(i=>Qt([n,i])):this.states_[0]=Qt([n,this.cell.stateSize]);else{if(Array.isArray(t)||(t=[t]),t.length!==this.states_.length)throw new x(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: ${t}`);e===!0?this.keptStates.push(this.states_.slice()):gt(this.states_);for(let i=0;i<this.states_.length;++i){const a=t[i],o=Array.isArray(this.cell.stateSize)?this.cell.stateSize[i]:this.cell.stateSize,r=[n,o];if(!Jt(a.shape,r))throw new x(`State ${i} is incompatible with layer ${this.name}: expected shape=${r}, received shape=${a.shape}`);this.states_[i]=a}}this.states_=this.states_.map(i=>Oe(i.clone()))})}apply(t,e){let n=e==null?null:e.initialState,i=e==null?null:e.constants;e==null&&(e={});const a=Th(t,n,i,this.numConstants);t=a.inputs,n=a.initialState,i=a.constants;let o=[],r=[];if(n!=null){e.initialState=n,o=o.concat(n),this.stateSpec=[];for(const c of n)this.stateSpec.push(new Mt({shape:c.shape}));r=r.concat(this.stateSpec)}if(i!=null&&(e.constants=i,o=o.concat(i),this.numConstants=i.length),o[0]instanceof ze){const c=[t].concat(o),u=this.inputSpec.concat(r),d=this.inputSpec;this.inputSpec=u;const h=super.apply(c,e);return this.inputSpec=d,h}else return super.apply(t,e)}call(t,e){return T(()=>{const n=e==null?null:e.mask,i=e==null?null:e.training;let a=e==null?null:e.initialState;t=nt(t),a==null&&(this.stateful?a=this.states_:a=this.getInitialState(t));const o=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1;if(a.length!==o)throw new x(`RNN Layer has ${o} state(s) but was passed ${a.length} initial state(s).`);this.unroll&&console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");const r={training:i},c=Ah((m,f)=>{const g=this.cell.call([m].concat(f),r);return[g[0],g.slice(1)]},t,a,this.goBackwards,n,null,this.unroll,this.returnSequences),u=c[0],d=c[1],h=c[2];this.stateful&&this.resetStates(h,i);const p=this.returnSequences?d:u;return this.returnState?[p].concat(h):p})}getInitialState(t){return T(()=>{let e=Qt(t.shape);return e=lt(e,[1,2]),e=vn(e),Array.isArray(this.cell.stateSize)?this.cell.stateSize.map(n=>n>1?ta(e,[1,n]):e):this.cell.stateSize>1?[ta(e,[1,this.cell.stateSize])]:[e]})}get trainableWeights(){return this.trainable?this.cell.trainableWeights:[]}get nonTrainableWeights(){return this.trainable?this.cell.nonTrainableWeights:this.cell.weights}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),this.cell!=null&&this.cell.setFastWeightInitDuringBuild(t)}getConfig(){const t=super.getConfig(),e={returnSequences:this.returnSequences,returnState:this.returnState,goBackwards:this.goBackwards,stateful:this.stateful,unroll:this.unroll};this.numConstants!=null&&(e.numConstants=this.numConstants);const n=this.cell.getConfig();return this.getClassName()===$e.className&&(e.cell={className:this.cell.getClassName(),config:n}),Object.assign(Object.assign(Object.assign({},n),t),e)}static fromConfig(t,e,n={}){const i=e.cell,a=fe(i,n);return new t(Object.assign(e,{cell:a}))}}$e.className="RNN";O($e);class zn extends rt{}class zi extends zn{constructor(t){super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=t.units,_t(this.units,"units"),this.activation=as(t.activation==null?this.DEFAULT_ACTIVATION:t.activation),this.useBias=t.useBias==null?!0:t.useBias,this.kernelInitializer=vt(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=vt(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=vt(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=Nt(t.kernelRegularizer),this.recurrentRegularizer=Nt(t.recurrentRegularizer),this.biasRegularizer=Nt(t.biasRegularizer),this.kernelConstraint=Et(t.kernelConstraint),this.recurrentConstraint=Et(t.recurrentConstraint),this.biasConstraint=Et(t.biasConstraint),this.dropout=Ls([1,ns([0,t.dropout==null?0:t.dropout])]),this.recurrentDropout=Ls([1,ns([0,t.recurrentDropout==null?0:t.recurrentDropout])]),this.dropoutFunc=t.dropoutFunc,this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){t=dt(t),this.kernel=this.addWeight("kernel",[t[t.length-1],this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias?this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(t,e){return T(()=>{if(t=t,t.length!==2)throw new x(`SimpleRNNCell expects 2 input Tensors, got ${t.length}.`);let n=t[1];t=t[0];const i=e.training==null?!1:e.training;0<this.dropout&&this.dropout<1&&this.dropoutMask==null&&(this.dropoutMask=os({ones:()=>le(t),rate:this.dropout,training:i,dropoutFunc:this.dropoutFunc})),0<this.recurrentDropout&&this.recurrentDropout<1&&this.recurrentDropoutMask==null&&(this.recurrentDropoutMask=os({ones:()=>le(n),rate:this.recurrentDropout,training:i,dropoutFunc:this.dropoutFunc}));let a;const o=this.dropoutMask,r=this.recurrentDropoutMask;o!=null?a=Ae(A(t,o),this.kernel.read()):a=Ae(t,this.kernel.read()),this.bias!=null&&(a=Ie(a,this.bias.read())),r!=null&&(n=A(n,r));let l=X(a,Ae(n,this.recurrentKernel.read()));return this.activation!=null&&(l=this.activation.apply(l)),[l,l]})}getConfig(){const t=super.getConfig(),e={units:this.units,activation:is(this.activation),useBias:this.useBias,kernelInitializer:Tt(this.kernelInitializer),recurrentInitializer:Tt(this.recurrentInitializer),biasInitializer:Tt(this.biasInitializer),kernelRegularizer:yt(this.kernelRegularizer),recurrentRegularizer:yt(this.recurrentRegularizer),biasRegularizer:yt(this.biasRegularizer),activityRegularizer:yt(this.activityRegularizer),kernelConstraint:Rt(this.kernelConstraint),recurrentConstraint:Rt(this.recurrentConstraint),biasConstraint:Rt(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout};return Object.assign(Object.assign({},t),e)}}zi.className="SimpleRNNCell";O(zi);class Jo extends $e{constructor(t){t.cell=new zi(t),super(t)}call(t,e){return T(()=>{this.cell.dropoutMask!=null&&(gt(this.cell.dropoutMask),this.cell.dropoutMask=null),this.cell.recurrentDropoutMask!=null&&(gt(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const n=e==null?null:e.mask,i=e==null?null:e.training,a=e==null?null:e.initialState;return super.call(t,{mask:n,training:i,initialState:a})})}static fromConfig(t,e){return new t(e)}}Jo.className="SimpleRNN";O(Jo);class Fi extends zn{constructor(t){if(super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",t.resetAfter)throw new x("GRUCell does not support reset_after parameter set to true.");this.units=t.units,_t(this.units,"units"),this.activation=as(t.activation===void 0?this.DEFAULT_ACTIVATION:t.activation),this.recurrentActivation=as(t.recurrentActivation===void 0?this.DEFAULT_RECURRENT_ACTIVATION:t.recurrentActivation),this.useBias=t.useBias==null?!0:t.useBias,this.kernelInitializer=vt(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=vt(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=vt(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=Nt(t.kernelRegularizer),this.recurrentRegularizer=Nt(t.recurrentRegularizer),this.biasRegularizer=Nt(t.biasRegularizer),this.kernelConstraint=Et(t.kernelConstraint),this.recurrentConstraint=Et(t.recurrentConstraint),this.biasConstraint=Et(t.biasConstraint),this.dropout=Ls([1,ns([0,t.dropout==null?0:t.dropout])]),this.recurrentDropout=Ls([1,ns([0,t.recurrentDropout==null?0:t.recurrentDropout])]),this.dropoutFunc=t.dropoutFunc,this.implementation=t.implementation,this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){t=dt(t);const e=t[t.length-1];this.kernel=this.addWeight("kernel",[e,this.units*3],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,this.units*3],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias?this.bias=this.addWeight("bias",[this.units*3],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(t,e){return T(()=>{if(t=t,t.length!==2)throw new x(`GRUCell expects 2 input Tensors (inputs, h, c), got ${t.length}.`);const n=e.training==null?!1:e.training;let i=t[1];t=t[0],0<this.dropout&&this.dropout<1&&this.dropoutMask==null&&(this.dropoutMask=os({ones:()=>le(t),rate:this.dropout,training:n,count:3,dropoutFunc:this.dropoutFunc})),0<this.recurrentDropout&&this.recurrentDropout<1&&this.recurrentDropoutMask==null&&(this.recurrentDropoutMask=os({ones:()=>le(i),rate:this.recurrentDropout,training:n,count:3,dropoutFunc:this.dropoutFunc}));const a=this.dropoutMask,o=this.recurrentDropoutMask;let r,l,c;0<this.dropout&&this.dropout<1&&(t=A(t,a[0]));let u=Ae(t,this.kernel.read());this.useBias&&(u=Ie(u,this.bias.read())),0<this.recurrentDropout&&this.recurrentDropout<1&&(i=A(i,o[0]));const d=this.recurrentKernel.read(),[h,p]=_e(d,[2*this.units,this.units],d.rank-1),m=Ae(i,h),[f,g,w]=_e(u,3,u.rank-1),[b,k]=_e(m,2,m.rank-1);r=this.recurrentActivation.apply(X(f,b)),l=this.recurrentActivation.apply(X(g,k));const y=Ae(A(l,i),p);c=this.activation.apply(X(w,y));const I=X(A(r,i),A(X(1,Ut(r)),c));return[I,I]})}getConfig(){const t=super.getConfig(),e={units:this.units,activation:is(this.activation),recurrentActivation:is(this.recurrentActivation),useBias:this.useBias,kernelInitializer:Tt(this.kernelInitializer),recurrentInitializer:Tt(this.recurrentInitializer),biasInitializer:Tt(this.biasInitializer),kernelRegularizer:yt(this.kernelRegularizer),recurrentRegularizer:yt(this.recurrentRegularizer),biasRegularizer:yt(this.biasRegularizer),activityRegularizer:yt(this.activityRegularizer),kernelConstraint:Rt(this.kernelConstraint),recurrentConstraint:Rt(this.recurrentConstraint),biasConstraint:Rt(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation,resetAfter:!1};return Object.assign(Object.assign({},t),e)}}Fi.className="GRUCell";O(Fi);class Xo extends $e{constructor(t){t.implementation===0&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),t.cell=new Fi(t),super(t)}call(t,e){return T(()=>{this.cell.dropoutMask!=null&&(gt(this.cell.dropoutMask),this.cell.dropoutMask=null),this.cell.recurrentDropoutMask!=null&&(gt(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const n=e==null?null:e.mask,i=e==null?null:e.training,a=e==null?null:e.initialState;return super.call(t,{mask:n,training:i,initialState:a})})}static fromConfig(t,e){return e.implmentation===0&&(e.implementation=1),new t(e)}}Xo.className="GRU";O(Xo);class Fn extends zn{constructor(t){super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=t.units,_t(this.units,"units"),this.activation=as(t.activation===void 0?this.DEFAULT_ACTIVATION:t.activation),this.recurrentActivation=as(t.recurrentActivation===void 0?this.DEFAULT_RECURRENT_ACTIVATION:t.recurrentActivation),this.useBias=t.useBias==null?!0:t.useBias,this.kernelInitializer=vt(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=vt(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=vt(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.unitForgetBias=t.unitForgetBias,this.kernelRegularizer=Nt(t.kernelRegularizer),this.recurrentRegularizer=Nt(t.recurrentRegularizer),this.biasRegularizer=Nt(t.biasRegularizer),this.kernelConstraint=Et(t.kernelConstraint),this.recurrentConstraint=Et(t.recurrentConstraint),this.biasConstraint=Et(t.biasConstraint),this.dropout=Ls([1,ns([0,t.dropout==null?0:t.dropout])]),this.recurrentDropout=Ls([1,ns([0,t.recurrentDropout==null?0:t.recurrentDropout])]),this.dropoutFunc=t.dropoutFunc,this.implementation=t.implementation,this.stateSize=[this.units,this.units],this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){var e;t=dt(t);const n=t[t.length-1];this.kernel=this.addWeight("kernel",[n,this.units*4],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,this.units*4],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint);let i;if(this.useBias){if(this.unitForgetBias){const a=this.biasInitializer,o=this.units;i=new(e=class extends ce{apply(l,c){const u=a.apply([o]),d=new wi().apply([o]),h=a.apply([o*2]);return dl(dl(u,d),h)}},e.className="CustomInit",e)}else i=this.biasInitializer;this.bias=this.addWeight("bias",[this.units*4],null,i,this.biasRegularizer,!0,this.biasConstraint)}else this.bias=null;this.built=!0}call(t,e){return T(()=>{const n=e.training==null?!1:e.training;if(t=t,t.length!==3)throw new x(`LSTMCell expects 3 input Tensors (inputs, h, c), got ${t.length}.`);let i=t[1];const a=t[2];t=t[0],0<this.dropout&&this.dropout<1&&this.dropoutMask==null&&(this.dropoutMask=os({ones:()=>le(t),rate:this.dropout,training:n,count:4,dropoutFunc:this.dropoutFunc})),0<this.recurrentDropout&&this.recurrentDropout<1&&this.recurrentDropoutMask==null&&(this.recurrentDropoutMask=os({ones:()=>le(i),rate:this.recurrentDropout,training:n,count:4,dropoutFunc:this.dropoutFunc}));const o=this.dropoutMask,r=this.recurrentDropoutMask;let l,c,u,d;0<this.dropout&&this.dropout<1&&(t=A(t,o[0]));let h=Ae(t,this.kernel.read());0<this.recurrentDropout&&this.recurrentDropout<1&&(i=A(i,r[0])),h=X(h,Ae(i,this.recurrentKernel.read())),this.useBias&&(h=Ie(h,this.bias.read()));const[p,m,f,g]=_e(h,4,h.rank-1);l=this.recurrentActivation.apply(p),c=this.recurrentActivation.apply(m),u=X(A(c,a),A(l,this.activation.apply(f))),d=this.recurrentActivation.apply(g);const w=A(d,this.activation.apply(u));return[w,w,u]})}getConfig(){const t=super.getConfig(),e={units:this.units,activation:is(this.activation),recurrentActivation:is(this.recurrentActivation),useBias:this.useBias,kernelInitializer:Tt(this.kernelInitializer),recurrentInitializer:Tt(this.recurrentInitializer),biasInitializer:Tt(this.biasInitializer),unitForgetBias:this.unitForgetBias,kernelRegularizer:yt(this.kernelRegularizer),recurrentRegularizer:yt(this.recurrentRegularizer),biasRegularizer:yt(this.biasRegularizer),activityRegularizer:yt(this.activityRegularizer),kernelConstraint:Rt(this.kernelConstraint),recurrentConstraint:Rt(this.recurrentConstraint),biasConstraint:Rt(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation};return Object.assign(Object.assign({},t),e)}}Fn.className="LSTMCell";O(Fn);class Yo extends $e{constructor(t){t.implementation===0&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),t.cell=new Fn(t),super(t)}call(t,e){return T(()=>{this.cell.dropoutMask!=null&&(gt(this.cell.dropoutMask),this.cell.dropoutMask=null),this.cell.recurrentDropoutMask!=null&&(gt(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const n=e==null?null:e.mask,i=e==null?null:e.training,a=e==null?null:e.initialState;return super.call(t,{mask:n,training:i,initialState:a})})}static fromConfig(t,e){return e.implmentation===0&&(e.implementation=1),new t(e)}}Yo.className="LSTM";O(Yo);class $i extends zn{constructor(t){super(t),this.cells=t.cells}get stateSize(){const t=[];for(const e of this.cells.slice().reverse())Array.isArray(e.stateSize)?t.push(...e.stateSize):t.push(e.stateSize);return t}call(t,e){return T(()=>{t=t;let n=t.slice(1);const i=[];for(const r of this.cells.slice().reverse())Array.isArray(r.stateSize)?i.push(n.splice(0,r.stateSize.length)):i.push(n.splice(0,1));i.reverse();const a=[];let o;for(let r=0;r<this.cells.length;++r){const l=this.cells[r];n=i[r],r===0?o=[t[0]].concat(n):o=[o[0]].concat(n),o=l.call(o,e),a.push(o.slice(1))}n=[];for(const r of a.slice().reverse())n.push(...r);return[o[0]].concat(n)})}build(t){sa(t)&&(t=t[0]),t=t;let e;this.cells.forEach((n,i)=>{ds(`RNNCell_${i}`,()=>{n.build(t),Array.isArray(n.stateSize)?e=n.stateSize[0]:e=n.stateSize,t=[t[0],e]})}),this.built=!0}getConfig(){const t=super.getConfig(),e=a=>({className:a.getClassName(),config:a.getConfig()}),i={cells:this.cells.map(e)};return Object.assign(Object.assign({},t),i)}static fromConfig(t,e,n={}){const i=[];for(const a of e.cells)i.push(fe(a,n));return new t({cells:i})}get trainableWeights(){if(!this.trainable)return[];const t=[];for(const e of this.cells)t.push(...e.trainableWeights);return t}get nonTrainableWeights(){const t=[];for(const e of this.cells)t.push(...e.nonTrainableWeights);if(!this.trainable){const e=[];for(const n of this.cells)e.push(...n.trainableWeights);return e.concat(t)}return t}getWeights(){const t=[];for(const e of this.cells)t.push(...e.weights);return na(t)}setWeights(t){const e=[];for(const n of this.cells){const i=n.weights.length,a=t.splice(i);for(let o=0;o<n.weights.length;++o)e.push([n.weights[o],a[o]])}vo(e)}}$i.className="StackedRNNCells";O($i);function os(s){const{ones:t,rate:e,training:n=!1,count:i=1,dropoutFunc:a}=s,o=()=>a!=null?a(t(),e):ju(t(),e),r=()=>Cn(o,t,n);return!i||i<=1?Oe(r().clone()):Array(i).fill(void 0).map(r).map(c=>Oe(c.clone()))}var RI=function(s,t){var e={};for(var n in s)Object.prototype.hasOwnProperty.call(s,n)&&t.indexOf(n)<0&&(e[n]=s[n]);if(s!=null&&typeof Object.getOwnPropertySymbols=="function")for(var i=0,n=Object.getOwnPropertySymbols(s);i<n.length;i++)t.indexOf(n[i])<0&&Object.prototype.propertyIsEnumerable.call(s,n[i])&&(e[n[i]]=s[n[i]]);return e};class Dh extends $e{constructor(t){if(t.unroll)throw new it("Unrolling is not possible with convolutional RNNs.");if(Array.isArray(t.cell))throw new it("It is not possible at the moment to stack convolutional cells.");super(t),this.inputSpec=[new Mt({ndim:5})]}call(t,e){return T(()=>{if(this.cell.dropoutMask!=null&&(gt(this.cell.dropoutMask),this.cell.dropoutMask=null),this.cell.recurrentDropoutMask!=null&&(gt(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),e&&e.constants)throw new x("ConvRNN2D cell does not support constants");const n=e==null?null:e.mask,i=e==null?null:e.training,a=e==null?null:e.initialState;return super.call(t,{mask:n,training:i,initialState:a})})}computeOutputShape(t){let e=this.computeSingleOutputShape(t);return this.returnSequences||(e=[e[0],...e.slice(2)]),this.returnState&&(e=[e,...Array(2).fill([t[0],...e.slice(-3)])]),e}getInitialState(t){return T(()=>{const{stateSize:e}=this.cell,n=t.shape,i=this.computeSingleOutputShape(n),a=[i[0],...i.slice(2)],o=Qt(a);return Array.isArray(e)?Array(e.length).fill(o):[o]})}resetStates(t,e=!1){T(()=>{if(!this.stateful)throw new xe("Cannot call resetStates() on an RNN Layer that is not stateful.");const n=this.inputSpec[0].shape,i=this.computeSingleOutputShape(n),a=[i[0],...i.slice(2)];if(n[0]==null)throw new x("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(this.getStates()==null)Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(()=>Qt(a)):this.states_=[Qt(a)];else if(t==null)gt(this.states_),this.keptStates!=null&&(gt(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(()=>Qt(a)):this.states_[0]=Qt(a);else{if(Array.isArray(t)||(t=[t]),t.length!==this.states_.length)throw new x(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: ${t}`);e?this.keptStates.push(this.states_.slice()):gt(this.states_);for(let r=0;r<this.states_.length;++r){const l=t[r],c=a;if(!Jt(l.shape,c))throw new x(`State ${r} is incompatible with layer ${this.name}: expected shape=${c}, received shape=${l.shape}`);this.states_[r]=l}}this.states_=this.states_.map(r=>Oe(r.clone()))})}computeSingleOutputShape(t){const{dataFormat:e,filters:n,kernelSize:i,padding:a,strides:o,dilationRate:r}=this.cell,l=e==="channelsFirst",c=t[l?3:2],u=t[l?4:3],d=me(c,i[0],a,o[0],r[0]),h=me(u,i[1],a,o[1],r[1]);return[...t.slice(0,2),...l?[n,d,h]:[d,h,n]]}}Dh.className="ConvRNN2D";class Mi extends Fn{constructor(t){const{filters:e,kernelSize:n,strides:i,padding:a,dataFormat:o,dilationRate:r}=t;super(Object.assign(Object.assign({},t),{units:e})),this.filters=e,_t(this.filters,"filters"),this.kernelSize=Fs(n,2,"kernelSize"),this.kernelSize.forEach(l=>_t(l,"kernelSize")),this.strides=Fs(i||1,2,"strides"),this.strides.forEach(l=>_t(l,"strides")),this.padding=a||"valid",se(this.padding),this.dataFormat=o||"channelsLast",Ft(this.dataFormat),this.dilationRate=Fs(r||1,2,"dilationRate"),this.dilationRate.forEach(l=>_t(l,"dilationRate"))}build(t){var e;t=dt(t);const n=this.dataFormat==="channelsFirst"?1:t.length-1;if(t[n]==null)throw new x(`The channel dimension of the input should be defined. Found ${t[n]}`);const i=t[n],a=4,o=this.kernelSize.concat([i,this.filters*a]);this.kernel=this.addWeight("kernel",o,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint);const r=this.kernelSize.concat([this.filters,this.filters*a]);if(this.recurrentKernel=this.addWeight("recurrent_kernel",r,null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){let l;if(this.unitForgetBias){const c=this.biasInitializer,u=this.filters;l=new(e=class extends ce{apply(h,p){const m=c.apply([u]),f=Is([u]),g=c.apply([u*2]);return go([m,f,g])}},e.className="CustomInit",e)}else l=this.biasInitializer;this.bias=this.addWeight("bias",[this.filters*a],null,l,this.biasRegularizer,!0,this.biasConstraint)}this.built=!0}call(t,e){return T(()=>{if(t.length!==3)throw new x(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ${t.length}.`);const n=e.training||!1,i=t[0],a=t[1],o=t[2],r=4;0<this.dropout&&this.dropout<1&&this.dropoutMask==null&&(this.dropoutMask=os({ones:()=>le(i),rate:this.dropout,training:n,count:r,dropoutFunc:this.dropoutFunc}));const l=this.dropoutMask,c=(G,P,U)=>!P||!P[U]?G:A(P[U],G);let u=c(i,l,0),d=c(i,l,1),h=c(i,l,2),p=c(i,l,3);0<this.recurrentDropout&&this.recurrentDropout<1&&this.recurrentDropoutMask==null&&(this.recurrentDropoutMask=os({ones:()=>le(a),rate:this.recurrentDropout,training:n,count:r,dropoutFunc:this.dropoutFunc}));const m=this.recurrentDropoutMask;let f=c(a,m,0),g=c(a,m,1),w=c(a,m,2),b=c(a,m,3);const k=3,[y,I,S,v]=_e(this.kernel.read(),r,k),[N,C,D,E]=this.useBias?_e(this.bias.read(),r):[null,null,null,null];u=this.inputConv(u,y,N,this.padding),d=this.inputConv(d,I,C,this.padding),h=this.inputConv(h,S,D,this.padding),p=this.inputConv(p,v,E,this.padding);const[V,M,L,F]=_e(this.recurrentKernel.read(),r,k);f=this.recurrentConv(f,V),g=this.recurrentConv(g,M),w=this.recurrentConv(w,L),b=this.recurrentConv(b,F);const $=this.recurrentActivation.apply(X(u,f)),W=this.recurrentActivation.apply(X(d,g)),R=X(A(W,o),A($,this.activation.apply(X(h,w)))),_=A(this.recurrentActivation.apply(X(p,b)),this.activation.apply(R));return[_,_,R]})}getConfig(){const t=super.getConfig(),{units:e}=t,n=RI(t,["units"]),i={filters:this.filters,kernelSize:this.kernelSize,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,strides:this.strides};return Object.assign(Object.assign({},n),i)}inputConv(t,e,n,i){const a=Pn(t,e,this.strides,i||"valid",this.dataFormat==="channelsFirst"?"NCHW":"NHWC",this.dilationRate);return n?Ie(a,n,this.dataFormat):a}recurrentConv(t,e){return Pn(t,e,1,"same",this.dataFormat==="channelsFirst"?"NCHW":"NHWC")}}Mi.className="ConvLSTM2DCell";O(Mi);class Qo extends Dh{constructor(t){const e=new Mi(t);super(Object.assign(Object.assign({},t),{cell:e}))}static fromConfig(t,e){return new t(e)}}Qo.className="ConvLSTM2D";O(Qo);class Ri extends rt{constructor(t){super(t),this.rate=Math.max(Math.min(t.rate,1),0),this.noiseShape=t.noiseShape,this.seed=t.seed,this.supportsMasking=!0}getNoiseShape(t){if(this.noiseShape==null)return this.noiseShape;const e=t.shape,n=[];for(let i=0;i<this.noiseShape.length;++i)n.push(this.noiseShape[i]==null?e[i]:this.noiseShape[i]);return n}call(t,e){return T(()=>{this.invokeCallHook(t,e);const n=nt(t);if(0<this.rate&&this.rate<1){const i=e.training==null?!1:e.training,a=this.getNoiseShape(n);return Cn(()=>ju(n,this.rate,a,this.seed),()=>n,i)}return t})}getConfig(){const t={rate:this.rate,noiseShape:this.noiseShape,seed:this.seed},e=super.getConfig();return Object.assign(t,e),t}dispose(){return super.dispose()}}Ri.className="Dropout";O(Ri);class tr extends Ri{constructor(t){super(t),this.inputSpec=[{ndim:3}]}getNoiseShape(t){const e=t.shape;return[e[0],1,e[2]]}}tr.className="SpatialDropout1D";O(tr);class er extends rt{constructor(t){if(super(t),this.activation=null,this.useBias=!0,this.kernel=null,this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",t.batchInputShape==null&&t.inputShape==null&&t.inputDim!=null){let e=null;t.batchSize!=null&&(e=t.batchSize),this.batchInputShape=[e,t.inputDim]}this.units=t.units,_t(this.units,"units"),this.activation=as(t.activation),t.useBias!=null&&(this.useBias=t.useBias),this.kernelInitializer=vt(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.biasInitializer=vt(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelConstraint=Et(t.kernelConstraint),this.biasConstraint=Et(t.biasConstraint),this.kernelRegularizer=Nt(t.kernelRegularizer),this.biasRegularizer=Nt(t.biasRegularizer),this.activityRegularizer=Nt(t.activityRegularizer),this.supportsMasking=!0,this.inputSpec=[{minNDim:2}]}build(t){t=dt(t);const e=t[t.length-1];this.kernel==null&&(this.kernel=this.addWeight("kernel",[e,this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint))),this.inputSpec=[{minNDim:2,axes:{[-1]:e}}],this.built=!0}computeOutputShape(t){t=dt(t);const e=t.slice();return e[e.length-1]=this.units,e}call(t,e){return T(()=>{this.invokeCallHook(t,e);const n=nt(t),i=Wu(this.activation.getClassName());let a;return i!=null?a=Ae(n,this.kernel.read(),i,this.bias?this.bias.read():null):(a=Ae(n,this.kernel.read()),this.bias!=null&&(a=Ie(a,this.bias.read())),this.activation!=null&&(a=this.activation.apply(a))),a})}getConfig(){const t={units:this.units,activation:is(this.activation),useBias:this.useBias,kernelInitializer:Tt(this.kernelInitializer),biasInitializer:Tt(this.biasInitializer),kernelRegularizer:yt(this.kernelRegularizer),biasRegularizer:yt(this.biasRegularizer),activityRegularizer:yt(this.activityRegularizer),kernelConstraint:Rt(this.kernelConstraint),biasConstraint:Rt(this.biasConstraint)},e=super.getConfig();return Object.assign(t,e),t}}er.className="Dense";O(er);class sr extends rt{constructor(t){t=t||{},super(t),this.inputSpec=[{minNDim:3}],this.dataFormat=t.dataFormat}computeOutputShape(t){t=dt(t);for(const e of t.slice(1))if(e==null)throw new x(`The shape of the input to "Flatten" is not fully defined (got ${t.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);return[t[0],Ye(t,1)]}call(t,e){return T(()=>{this.invokeCallHook(t,e);let n=nt(t);if(this.dataFormat==="channelsFirst"&&n.rank>1){const i=[0];for(let a=2;a<n.rank;++a)i.push(a);i.push(1),n=ht(n,i)}return jw(n)})}getConfig(){const t={};this.dataFormat!=null&&(t.dataFormat=this.dataFormat);const e=super.getConfig();return Object.assign(t,e),t}}sr.className="Flatten";O(sr);class nr extends rt{constructor(t){super(t),this.supportsMasking=!0,this.activation=as(t.activation)}call(t,e){return T(()=>{this.invokeCallHook(t,e);const n=nt(t);return this.activation.apply(n)})}getConfig(){const t={activation:is(this.activation)},e=super.getConfig();return Object.assign(t,e),t}}nr.className="Activation";O(nr);class ir extends rt{constructor(t){super(t),this.n=t.n,this.inputSpec=[{ndim:2}]}computeOutputShape(t){return[t[0],this.n,t[1]]}call(t,e){return T(()=>(t=nt(t),Hw(t,this.n)))}getConfig(){const t={n:this.n},e=super.getConfig();return Object.assign(t,e),t}}ir.className="RepeatVector";O(ir);class ar extends rt{constructor(t){super(t),this.targetShape=t.targetShape;for(let e=0;e<this.targetShape.length;++e)this.isUnknown(this.targetShape[e])&&(this.targetShape[e]=null)}isUnknown(t){return t<0||t==null}fixUnknownDimension(t,e){const n="Total size of new array must be unchanged.",i=e.slice();let a=1,o=null;for(let l=0;l<i.length;++l){const c=i[l];if(this.isUnknown(c))if(o===null)o=l;else throw new x("Can only specifiy one unknown dimension.");else a*=c}const r=Ye(t);if(o!==null){if(a===0||r%a!==0)throw new x(n);i[o]=r/a}else if(r!==a)throw new x(n);return i}computeOutputShape(t){let e=!1;for(let n=0;n<t.length;++n)if(this.isUnknown(t[n])){e=!0;break}return e?t.slice(0,1).concat(this.targetShape):t.slice(0,1).concat(this.fixUnknownDimension(t.slice(1),this.targetShape))}call(t,e){return T(()=>{this.invokeCallHook(t,e);const n=nt(t),i=n.shape,a=i.slice(0,1).concat(this.fixUnknownDimension(i.slice(1),this.targetShape));return B(n,a)})}getConfig(){const t={targetShape:this.targetShape},e=super.getConfig();return Object.assign(t,e),t}}ar.className="Reshape";O(ar);class or extends rt{constructor(t){if(super(t),t.dims==null)throw new Error("Required configuration field `dims` is missing during Permute constructor call.");if(!Array.isArray(t.dims))throw new Error(`Permute constructor requires \`dims\` to be an Array, but received ${t.dims} instead.`);const e=be(1,t.dims.length+1);if(!Jt(t.dims.slice().sort(),e))throw new Error("Invalid permutation `dims`: "+JSON.stringify(t.dims)+" `dims` must contain consecutive integers starting from 1.");this.dims=t.dims,this.dimsIncludingBatch=[0].concat(this.dims),this.inputSpec=[new Mt({ndim:this.dims.length+1})]}computeOutputShape(t){t=dt(t);const e=t.slice();return this.dims.forEach((n,i)=>{e[i+1]=t[n]}),e}call(t,e){return ht(nt(t),this.dimsIncludingBatch)}getConfig(){const t={dims:this.dims},e=super.getConfig();return Object.assign(t,e),t}}or.className="Permute";O(or);class rr extends rt{constructor(t){super(t??{}),this.supportsMasking=!0,t!=null?this.maskValue=t.maskValue==null?0:t.maskValue:this.maskValue=0}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={maskValue:this.maskValue};return Object.assign(e,t),e}computeMask(t,e){const n=nt(t);return Xi(Gn(n,this.maskValue),-1)}call(t,e){return T(()=>{this.invokeCallHook(t,e);const n=nt(t),o=Xi(Gn(n,this.maskValue),-1,!0);return A(n,J(o,n.dtype))})}}rr.className="Masking";O(rr);class lr extends rt{constructor(t){if(super(t),this.embeddings=null,this.DEFAULT_EMBEDDINGS_INITIALIZER="randomUniform",t.batchInputShape==null&&t.inputShape==null){let e=null;t.batchSize!=null&&(e=t.batchSize),t.inputLength==null?this.batchInputShape=[e,null]:this.batchInputShape=[e].concat(mt(t.inputLength))}this.inputDim=t.inputDim,_t(this.inputDim,"inputDim"),this.outputDim=t.outputDim,_t(this.outputDim,"outputDim"),this.embeddingsInitializer=vt(t.embeddingsInitializer||this.DEFAULT_EMBEDDINGS_INITIALIZER),this.embeddingsRegularizer=Nt(t.embeddingsRegularizer),this.activityRegularizer=Nt(t.activityRegularizer),this.embeddingsConstraint=Et(t.embeddingsConstraint),this.maskZero=t.maskZero,this.supportsMasking=t.maskZero,this.inputLength=t.inputLength}build(t){this.embeddings=this.addWeight("embeddings",[this.inputDim,this.outputDim],this.dtype,this.embeddingsInitializer,this.embeddingsRegularizer,!0,this.embeddingsConstraint),this.built=!0}warnOnIncompatibleInputShape(t){}computeMask(t,e){return T(()=>this.maskZero?(t=nt(t),Gn(t,Dt(t))):null)}computeOutputShape(t){if(t=dt(t),this.inputLength==null)return[...t,this.outputDim];const e=mt(this.inputLength);if(e.length!==t.length-1)throw new x(`"inputLength" is ${this.inputLength}, but received input shape has shape ${t}`);{let n=0;for(let i=0;i<e.length;++i){const a=e[i],o=t[i+1];if(a!=null&&o!=null&&a!==o)throw new x(`"inputLength" is ${this.inputLength}, but received input shape has shape ${t}`);a==null&&(e[n]=o),n++}}return[t[0],...e,this.outputDim]}call(t,e){return T(()=>{this.invokeCallHook(t,e);let n=nt(t);n.dtype!=="int32"&&(n=Te(n,"int32"));const i=Uu(this.embeddings.read(),B(n,[n.size]));return B(i,dt(this.computeOutputShape(n.shape)))})}getConfig(){const t={inputDim:this.inputDim,outputDim:this.outputDim,embeddingsInitializer:Tt(this.embeddingsInitializer),embeddingsRegularizer:yt(this.embeddingsRegularizer),activityRegularizer:yt(this.activityRegularizer),embeddingsConstraint:Rt(this.embeddingsConstraint),maskZero:this.maskZero,inputLength:this.inputLength},e=super.getConfig();return Object.assign(t,e),t}}lr.className="Embedding";O(lr);class Cs extends rt{constructor(t){super(t||{}),this.supportsMasking=!0}mergeFunction(t){throw new it}computeElementwiseOpOutputShape(t,e){if(t==null||e==null)return null;if(t.length<e.length)return this.computeElementwiseOpOutputShape(e,t);if(e.length===0)return t;const n=t.slice(0,t.length-e.length);for(let i=0;i<e.length;++i){const a=t[t.length-e.length+i],o=e[i];if(a==null||o==null||a<0||o<0)n.push(null);else if(a===1)n.push(o);else if(o===1)n.push(a);else{if(a!==o)throw new x("Operands could not be broadcast together with shapes "+JSON.stringify(t)+" "+JSON.stringify(e));n.push(a)}}return n}build(t){if(Array.isArray(t)&&!Array.isArray(t[0])&&(t=[dt(t)]),t=t,t.length<2)throw new x(`A merge layer should be called on an Array of at least 2 inputs. Got ${t.length} input(s).`);let e=[];for(const a of t)a!=null&&a[0]!==null&&e.push(a[0]);if(e=Xe(e),e.length>1)throw new x(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(t)}.`);let n=t[0]==null?null:t[0].slice(1);for(let a=1;a<t.length;++a){const o=t[a]==null?null:t[a].slice(1);n=this.computeElementwiseOpOutputShape(n,o)}const i=t.map(a=>a.length);t.indexOf(null)===-1&&Xe(i).length===1?this.reshapeRequired=!1:this.reshapeRequired=!0}call(t,e){return T(()=>{if(t=t,this.reshapeRequired){const n=[],i=t.map(a=>a.rank);if(i.indexOf(null)===-1){const a=ns(i);for(let o of t){const r=o.rank;for(let l=0;l<a-r;++l)o=vn(o,1);n.push(o)}return this.mergeFunction(n)}else{let a=!1;for(const l of t){const c=l.rank;if(c==null){const u=l.shape,d=u[0],h=u.slice(1).concat([d]);let p=B(l,[d].concat(Ye(u.slice(1))));p=ht(p,[1,0]),p=B(p,h),n.push(p),a=!0}else if(c>1){const u=be(1,c).concat([0]);n.push(ht(l,u)),a=!0}else n.push(l)}let o=this.mergeFunction(n);const r=o.rank;if(a){if(r==null){const l=o.shape,c=l.length,u=l[c-1],d=[u].concat(l.slice(0,l.length-1));o=B(ht(B(o,[-1,u]),[1,0]),d)}else if(r>1){const l=[r-1].concat(be(0,r-1));o=ht(o,l)}}return o}}else return this.mergeFunction(t)})}computeOutputShape(t){t=t;let e;t[0]==null?e=null:e=t[0].slice(1);for(let i=1;i<t.length;++i){const a=t[i]==null?null:t[i].slice(1);e=this.computeElementwiseOpOutputShape(e,a)}let n=[];for(const i of t)i!=null&&i[0]!==null&&n.push(i[0]);return n=Xe(n),n.length===1?e=n.concat(e):e=[null].concat(e),e}computeMask(t,e){return T(()=>{if(e==null)return null;if(!Array.isArray(e))throw new x("`mask` should be an Array");if(!Array.isArray(t))throw new x("`inputs` should be an Array");if(e.length!==t.length)throw new x(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${t.length} vs ${e.length})`);if(e.every(i=>i==null))return null;e=e.map(i=>i==null?i:Ve(i,0));let n=e[0];for(let i=1;i<e.length-1;++i)n=ws(n,e[i]);return n})}}class cr extends Cs{constructor(t){super(t)}mergeFunction(t){return T(()=>{let e=t[0].clone();for(let n=1;n<t.length;++n)e=X(e,t[n]);return e})}}cr.className="Add";O(cr);class ur extends Cs{constructor(t){super(t)}mergeFunction(t){return T(()=>{let e=t[0].clone();for(let n=1;n<t.length;++n)e=A(e,t[n]);return e})}}ur.className="Multiply";O(ur);class hr extends Cs{constructor(t){super(t)}mergeFunction(t){return T(()=>{let e=t[0].clone();for(let n=1;n<t.length;++n)e=X(e,t[n]);return A(1/t.length,e)})}}hr.className="Average";O(hr);class dr extends Cs{constructor(t){super(t)}mergeFunction(t){return T(()=>{let e=t[0];for(let n=1;n<t.length;++n)e=bs(e,t[n]);return e})}}dr.className="Maximum";O(dr);class pr extends Cs{constructor(t){super(t)}mergeFunction(t){return T(()=>{let e=t[0];for(let n=1;n<t.length;++n)e=so(e,t[n]);return e})}}pr.className="Minimum";O(pr);class fr extends Cs{constructor(t){super(t),this.DEFAULT_AXIS=-1,t==null&&(t={}),this.axis=t.axis==null?this.DEFAULT_AXIS:t.axis,this.supportsMasking=!0,this.reshapeRequired=!1}build(t){if(!(Array.isArray(t)&&Array.isArray(t[0]))||t.length===1)throw new x("A `Concatenate` layer should be called on a list of at least 2 inputs");t=t;let e=!0;for(const i of t)if(i!=null){e=!1;break}if(e)return;const n=[];for(let i=0;i<t.length;++i){const a=t[i].slice();a.splice(this.axis,1);let o=!1;for(const r of n)if(Jt(r,a)){o=!0;break}o||n.push(a)}if(n.length>1)throw new x("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: "+JSON.stringify(t))}mergeFunction(t){return T(()=>go(t,this.axis))}computeOutputShape(t){if(!(Array.isArray(t)&&Array.isArray(t[0])))throw new x("A `Concatenate` layer should be called on a list of inputs.");const e=t,n=e[0].slice(),i=this.axis<0?n.length+this.axis:this.axis;for(const a of e.slice(1)){if(n[i]==null||a[i]==null){n[i]=null;break}n[i]+=a[i]}return n}computeMask(t,e){if(e==null)return null;if(!Array.isArray(e))throw new x("`mask` should be an array for Concatenate");if(!Array.isArray(t))throw new x("`inputs` should be an array for Concatenate");if(e.length!==t.length)throw new x(`Mismatch in the length of mask (${e.length}) and the legnth of inputs (${t.length})`);return T(()=>{let n=!0;if(e.forEach(o=>{if(o!=null){n=!1;return}}),n)return null;const i=[];for(let o=0;o<t.length;++o)e[o]==null?i.push(J(le(t[o]),"bool")):e[o].rank<t[o].rank?i.push(Ve(e[o],-1)):i.push(e[o]);const a=xn(i,this.axis);return cu(a,-1,!1)})}getConfig(){const t={axis:this.axis},e=super.getConfig();return Object.assign(t,e),t}}fr.className="Concatenate";O(fr);function en(s,t){for(;s<0;)s+=t;return s}function EI(s,t,e){if(s.shape.length>3||t.shape.length>3)throw new it("batchDot is not implemented for tensors of 4D or higher rank yet");if(K(s.shape.length>=2,()=>`batchDot requires the rank of x to be >= 2, but got ${s.shape.length}`),K(s.shape.length>=2,()=>`batchDot requires the rank of y to be >= 2, but got ${t.shape.length}`),typeof e=="number"&&(e=[e,e]),s.dtype==="complex64"||t.dtype==="complex64")throw new it("batchDot is not implemented for complex64-type Tensors yet.");const n=s.shape.length,i=t.shape.length;e==null&&(e=[n-1,i-2]);const a=e;return T(()=>{let o;if(n>i){o=n-i;const l=[];for(let c=0;c<o;++c)l.push(1);t=B(t,t.shape.concat(l))}else if(i>n){o=i-n;const l=[];for(let c=0;c<o;++c)l.push(1);s=B(s,s.shape.concat(l))}else o=0;let r;if(s.shape.length===2&&t.shape.length===2)a[0]===a[1]?r=lt(A(s,t),a[0]):r=lt(A(ht(s,[1,0]),t),a[1]);else{const l=a[0]!==s.shape.length-1,c=a[1]===t.shape.length-1;r=pe(s,t,l,c)}if(o>0){let l;n>i?l=n+i-3:l=n-1;const c=[];for(let u=l;u<l+o;++u)c.push(u);r=pi(r,c)}return r.shape.length===1&&(r=Ve(r,1)),r})}class mr extends Cs{constructor(t){super(t),this.axes=t.axes,this.normalize=t.normalize==null?!1:t.normalize,this.supportsMasking=!0,this.reshapeRequired=!1}build(t){K(Array.isArray(t)&&t.length===2&&Array.isArray(t[0])&&Array.isArray(t[1]),()=>"A `Dot` layer should be called on a list of exactly 2 inputs.");const e=t[0],n=t[1];if(e.length>3||n.length>3)throw new it("Dot layer does not support tensors of 4D or higher rank yet.");const i=this.interpretAxes(e,n);if(e[i[0]]!==n[i[1]])throw new x(`Dimension incompatibility: ${e[i[0]]} !== ${n[i[1]]}`)}mergeFunction(t){if(t.length!==2)throw new x(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${t.length} input(s).`);let e=t[0],n=t[1],i;return Array.isArray(this.axes)?i=this.axes.map((a,o)=>en(a,t[o].shape.length)):i=[en(this.axes,e.shape.length),en(this.axes,n.shape.length)],this.normalize&&(e=Zn(e,i[0]),n=Zn(n,i[1])),EI(e,n,i)}interpretAxes(t,e){let n;return Array.isArray(this.axes)?n=this.axes:n=[en(this.axes,t.length),en(this.axes,e.length)],n}computeOutputShape(t){K(Array.isArray(t)&&t.length===2&&Array.isArray(t[0])&&Array.isArray(t[1]),()=>"A `Dot` layer should be called on a list of exactly 2 inputs.");const e=t[0].slice(),n=t[1].slice();if(e.length>3||n.length>3)throw new it("Dot layer does not support tensors of 4D or higher rank yet.");const i=this.interpretAxes(e,n);e.splice(i[0],1),n.splice(i[1],1),n.splice(0,1);const a=e.concat(n);return a.length===1&&a.push(1),a}computeMask(t,e){return null}getConfig(){const t={axes:this.axes,normalize:this.normalize},e=super.getConfig();return Object.assign(t,e),t}}mr.className="Dot";O(mr);class gr extends rt{constructor(t){super(t),this.supportsMasking=!0,this.stddev=t.stddev}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={stddev:this.stddev};return Object.assign(e,t),e}call(t,e){return T(()=>{this.invokeCallHook(t,e);const n=nt(t);return Cn(()=>X(yi(n.shape,0,this.stddev),n),()=>n,e.training||!1)})}}gr.className="GaussianNoise";O(gr);class br extends rt{constructor(t){super(t),this.supportsMasking=!0,this.rate=t.rate}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={rate:this.rate};return Object.assign(e,t),e}call(t,e){return T(()=>{this.invokeCallHook(t,e);const n=nt(t);return this.rate>0&&this.rate<1?Cn(()=>{const a=Math.sqrt(this.rate/(1-this.rate));return A(n,yi(n.shape,1,a))},()=>n,e.training||!1):n})}}br.className="GaussianDropout";O(br);class yr extends rt{constructor(t){super(t),this.supportsMasking=!0,this.rate=t.rate,this.noiseShape=t.noiseShape}_getNoiseShape(t){return this.noiseShape||nt(t).shape}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={rate:this.rate};return Object.assign(e,t),e}call(t,e){return T(()=>{if(this.rate<1&&this.rate>0){const n=this._getNoiseShape(t);return Cn(()=>{const a=nt(t),r=-1.6732632423543772*1.0507009873554805;let l=Hs(mi(n),this.rate);l=Te(l,"float32");const c=((1-this.rate)*(1+this.rate*r**2))**-.5,u=-c*r*this.rate,d=X(A(a,l),A(X(l,-1),r));return X(A(d,c),u)},()=>nt(t),e.training||!1)}return t})}}yr.className="AlphaDropout";O(yr);function bn(s,t,e,n,i,a=.001){let o;if(s.rank===2)o=zm(s,t,e,n,i,a);else if(s.rank===3)o=Fm(s,t,e,n,i,a);else if(s.rank===4)o=$m(s,t,e,n,i,a);else throw new it(`batchNormalization is not implemented for array of rank ${s.rank} yet`);return o}function LI(s,t,e,n,i=.001){return T(()=>{const a=oo(s,n),o=a.mean,r=a.variance;return[bn(s,o,r,e,t,i),o,r]})}function OI(s,t,e,n,i=.001){return T(()=>{const a=oo(s,n),o=a.mean,r=a.variance,l=[];for(const m of be(0,s.rank))n.indexOf(m)!==-1?l.push(1):l.push(s.shape[m]);const c=B(o,l),u=B(r,l),d=t==null?null:B(t,l),h=e==null?null:B(e,l);return[bn(s,c,u,h,d,i),o,r]})}function _I(s,t,e,n,i=.001){return Jt(n.slice().sort(),be(0,s.rank-1))?LI(s,t,e,n,i):OI(s,t,e,n,i)}class wr extends rt{constructor(t){t==null&&(t={}),super(t),this.supportsMasking=!0,this.axis=t.axis==null?-1:t.axis,this.momentum=t.momentum==null?.99:t.momentum,this.epsilon=t.epsilon==null?.001:t.epsilon,this.center=t.center==null?!0:t.center,this.scale=t.scale==null?!0:t.scale,this.betaInitializer=vt(t.betaInitializer||"zeros"),this.gammaInitializer=vt(t.gammaInitializer||"ones"),this.movingMeanInitializer=vt(t.movingMeanInitializer||"zeros"),this.movingVarianceInitializer=vt(t.movingVarianceInitializer||"ones"),this.betaConstraint=Et(t.betaConstraint),this.gammaConstraint=Et(t.gammaConstraint),this.betaRegularizer=Nt(t.betaRegularizer),this.gammaRegularizer=Nt(t.gammaRegularizer)}build(t){t=dt(t);const e=this.axis>=0?this.axis:this.axis+t.length,n=t[e];if(n==null)throw new x(`Axis ${e} of input tensor should have a defined dimension but the layer received an input with shape ${JSON.stringify(t)}.`);this.inputSpec=[new Mt({ndim:t.length,axes:{[e]:n}})];const i=[n];this.scale&&(this.gamma=this.addWeight("gamma",i,null,this.gammaInitializer,this.gammaRegularizer,!0,this.gammaConstraint)),this.center&&(this.beta=this.addWeight("beta",i,null,this.betaInitializer,this.betaRegularizer,!0,this.betaConstraint)),this.movingMean=this.addWeight("moving_mean",i,null,this.movingMeanInitializer,null,!1),this.movingVariance=this.addWeight("moving_variance",i,null,this.movingVarianceInitializer,null,!1),this.built=!0}call(t,e){return T(()=>{const n=e.training==null?!1:e.training,i=nt(t),a=i.shape,o=a.length,r=be(0,o),l=this.axis>=0?this.axis:this.axis+o;r.splice(l,1);const c=ms(1,o);c[l]=a[l];const u=r.slice();u.sort();const d=!Jt(u,be(0,o).slice(0,o-1)),h=()=>{if(d){const b=B(this.movingMean.read(),c),k=B(this.movingVariance.read(),c),y=this.center?B(this.beta.read(),c):null,I=this.scale?B(this.gamma.read(),c):null;return bn(i,b,k,y,I,this.epsilon)}else return bn(i,this.movingMean.read(),this.movingVariance.read(),this.beta==null?null:this.beta.read(),this.gamma==null?null:this.gamma.read(),this.epsilon)};if(!n)return h();const[p,m,f]=_I(i,this.gamma.read(),this.beta.read(),r,this.epsilon),g=(b,k,y)=>{T(()=>{const I=1-y,S=b.read(),v=A(pt(S,k),I);b.write(pt(S,v))})};return g(this.movingMean,m,this.momentum),g(this.movingVariance,f,this.momentum),p})}getConfig(){const t={axis:this.axis,momentum:this.momentum,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:Tt(this.betaInitializer),gammaInitializer:Tt(this.gammaInitializer),movingMeanInitializer:Tt(this.movingMeanInitializer),movingVarianceInitializer:Tt(this.movingVarianceInitializer),betaRegularizer:yt(this.betaRegularizer),gammaRegularizer:yt(this.gammaRegularizer),betaConstraint:Rt(this.betaConstraint),gammaConstraint:Rt(this.gammaConstraint)},e=super.getConfig();return Object.assign(t,e),t}}wr.className="BatchNormalization";O(wr);class kr extends rt{constructor(t){if(t==null&&(t={}),super(t),this.axis=t.axis==null?-1:t.axis,typeof this.axis=="number"){if(!Number.isInteger(this.axis))throw new Error(`Expected axis to be an integer, but received ${this.axis}`)}else if(Array.isArray(this.axis)){for(const e of this.axis)if(!Number.isInteger(e))throw new Error(`Expected axis to be an array of integers, but received ${JSON.stringify(this.axis)}`)}else throw new Error(`Expected axis to be an integer or an array of integers, but received ${JSON.stringify(this.axis)}`);this.epsilon=t.epsilon==null?.001:t.epsilon,this.center=t.center==null?!0:t.center,this.scale=t.scale==null?!0:t.scale,this.betaInitializer=vt(t.betaInitializer||"zeros"),this.gammaInitializer=vt(t.gammaInitializer||"ones"),this.betaRegularizer=Nt(t.betaRegularizer),this.gammaRegularizer=Nt(t.gammaRegularizer),this.supportsMasking=!0}build(t){t=dt(t);const e=t.length;typeof this.axis=="number"&&(this.axis=[this.axis]);for(let a=0;a<this.axis.length;++a)this.axis[a]<0&&(this.axis[a]+=e);for(const a of this.axis)if(a<0||a>=e)throw new Error(`Invalid axis: ${a}`);if(this.axis.length!==Xe(this.axis).length)throw new Error(`Found duplicate axes in: ${this.axis}`);const n=this.axis.map(a=>t[a]),i=!0;this.scale?this.gamma=this.addWeight("gamma",n,"float32",this.gammaInitializer,this.gammaRegularizer,i):this.gamma=null,this.center?this.beta=this.addWeight("beta",n,"float32",this.betaInitializer,this.betaRegularizer,i):this.beta=null,this.built=!0}call(t,e){const n=nt(t),i=n.shape,a=i.length;return T(()=>{let{mean:r,variance:l}=oo(n,this.axis,!0);const c=ms(1,a);for(const f of this.axis)c[f]=i[f];const u=f=>f!=null&&f.shape.length!==a?B(f,c):f;let d=this.scale?u(this.gamma.read()):null,h=this.center?u(this.beta.read()):null;const p=[],m=[];for(let f=0;f<a;++f)this.axis.indexOf(f)!==-1?(p.push(i[f]),m.push(1)):(p.push(1),m.push(i[f]));return r=hs(r,p),l=hs(l,p),d!=null&&(d=hs(d,m)),h!=null&&(h=hs(h,m)),bn(n,r,l,h,d,this.epsilon)})}getConfig(){const t={axis:this.axis,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:Tt(this.betaInitializer),gammaInitializer:Tt(this.gammaInitializer),betaRegularizer:yt(this.betaRegularizer),gammaRegularizer:yt(this.gammaRegularizer)},e=super.getConfig();return Object.assign(t,e),t}}kr.className="LayerNormalization";O(kr);function WI(s,t,e){return T(()=>{if(s.rank!==4)throw new x(`temporalPadding expects input tensor to be 4-D, but received a ${s.rank}-D tensor.`);if(t==null&&(t=[[1,1],[1,1]]),t.length!==2||t[0].length!==2||t[1].length!==2)throw new x("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");if(e==null&&(e=ye()),e!=="channelsLast"&&e!=="channelsFirst")throw new x(`Unknown data format: ${e}. Supported data formats are 'channelsLast' and 'channelsFirst.`);let n;return e==="channelsFirst"?n=[[0,0],[0,0],t[0],t[1]]:n=[[0,0],t[0],t[1],[0,0]],to(s,n)})}class Ir extends rt{constructor(t){if(t==null&&(t={}),super(t),this.dataFormat=t.dataFormat==null?ye():t.dataFormat,t.padding==null)this.padding=[[1,1],[1,1]];else if(typeof t.padding=="number")this.padding=[[t.padding,t.padding],[t.padding,t.padding]];else{if(t.padding=t.padding,t.padding.length!==2)throw new x(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${t.padding.length} array.`);let e,n;if(typeof t.padding[0]=="number")e=[t.padding[0],t.padding[0]],n=[t.padding[1],t.padding[1]];else{if(t.padding=t.padding,t.padding[0].length!==2)throw new x(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${t.padding[0].length} array.`);if(e=t.padding[0],t.padding[1].length!==2)throw new x(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${t.padding[1].length} array.`);n=t.padding[1]}this.padding=[e,n]}this.inputSpec=[new Mt({ndim:4})]}computeOutputShape(t){t=dt(t);let e,n;return this.dataFormat==="channelsFirst"?(t[2]!=null&&t[2]>=0?e=t[2]+this.padding[0][0]+this.padding[0][1]:e=null,t[3]!=null&&t[3]>=0?n=t[3]+this.padding[1][0]+this.padding[1][1]:n=null,[t[0],t[1],e,n]):(t[1]!=null&&t[1]>=0?e=t[1]+this.padding[0][0]+this.padding[0][1]:e=null,t[2]!=null&&t[2]>=0?n=t[2]+this.padding[1][0]+this.padding[1][1]:n=null,[t[0],e,n,t[3]])}call(t,e){return T(()=>WI(nt(t),this.padding,this.dataFormat))}getConfig(){const t={padding:this.padding,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}Ir.className="ZeroPadding2D";O(Ir);function Ei(s,t,e,n,i,a){return T(()=>{Ft(i),Bu(a),se(n),e==null&&(e=[1,1]),n==null&&(n="valid"),i==null&&(i=ye()),a==null&&(a="max"),s=Go(s,i);let o;const r=n==="same"?"same":"valid";return a==="max"?o=yu(s,t,e,r):o=uu(s,t,e,r),i==="channelsFirst"&&(o=ht(o,[0,3,1,2])),o})}function zh(s,t,e,n,i,a){return T(()=>{Ft(i),Bu(a),se(n),e==null&&(e=[1,1,1]),n==null&&(n="valid"),i==null&&(i=ye()),a==null&&(a="max"),s=Nh(s,i);let o;const r=n==="same"?"same":"valid";return a==="max"?o=Mm(s,t,e,r):o=Rm(s,t,e,r),i==="channelsFirst"&&(o=ht(o,[0,4,1,2,3])),o})}class Fh extends rt{constructor(t){if(t.poolSize==null&&(t.poolSize=2),super(t),typeof t.poolSize=="number")this.poolSize=[t.poolSize];else if(Array.isArray(t.poolSize)&&t.poolSize.length===1&&typeof t.poolSize[0]=="number")this.poolSize=t.poolSize;else throw new x(`poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(t.poolSize)}`);if(_t(this.poolSize,"poolSize"),t.strides==null)this.strides=this.poolSize;else if(typeof t.strides=="number")this.strides=[t.strides];else if(Array.isArray(t.strides)&&t.strides.length===1&&typeof t.strides[0]=="number")this.strides=t.strides;else throw new x(`strides for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(t.strides)}`);_t(this.strides,"strides"),this.padding=t.padding==null?"valid":t.padding,se(this.padding),this.inputSpec=[new Mt({ndim:3})]}computeOutputShape(t){t=dt(t);const e=me(t[1],this.poolSize[0],this.padding,this.strides[0]);return[t[0],e,t[2]]}call(t,e){return T(()=>{this.invokeCallHook(t,e),t=vn(nt(t),2);const n=this.poolingFunction(nt(t),[this.poolSize[0],1],[this.strides[0],1],this.padding,"channelsLast");return pi(n,[2])})}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides},e=super.getConfig();return Object.assign(t,e),t}}class xr extends Fh{constructor(t){super(t)}poolingFunction(t,e,n,i,a){return Ft(a),se(i),Ei(t,e,n,i,a,"max")}}xr.className="MaxPooling1D";O(xr);class Sr extends Fh{constructor(t){super(t)}poolingFunction(t,e,n,i,a){return Ft(a),se(i),Ei(t,e,n,i,a,"avg")}}Sr.className="AveragePooling1D";O(Sr);class $h extends rt{constructor(t){if(t.poolSize==null&&(t.poolSize=[2,2]),super(t),this.poolSize=Array.isArray(t.poolSize)?t.poolSize:[t.poolSize,t.poolSize],t.strides==null)this.strides=this.poolSize;else if(Array.isArray(t.strides)){if(t.strides.length!==2)throw new x(`If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ${t.strides.length}.`);this.strides=t.strides}else this.strides=[t.strides,t.strides];_t(this.poolSize,"poolSize"),_t(this.strides,"strides"),this.padding=t.padding==null?"valid":t.padding,this.dataFormat=t.dataFormat==null?"channelsLast":t.dataFormat,Ft(this.dataFormat),se(this.padding),this.inputSpec=[new Mt({ndim:4})]}computeOutputShape(t){t=dt(t);let e=this.dataFormat==="channelsFirst"?t[2]:t[1],n=this.dataFormat==="channelsFirst"?t[3]:t[2];return e=me(e,this.poolSize[0],this.padding,this.strides[0]),n=me(n,this.poolSize[1],this.padding,this.strides[1]),this.dataFormat==="channelsFirst"?[t[0],t[1],e,n]:[t[0],e,n,t[3]]}call(t,e){return T(()=>(this.invokeCallHook(t,e),this.poolingFunction(nt(t),this.poolSize,this.strides,this.padding,this.dataFormat)))}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}class vr extends $h{constructor(t){super(t)}poolingFunction(t,e,n,i,a){return Ft(a),se(i),Ei(t,e,n,i,a,"max")}}vr.className="MaxPooling2D";O(vr);class Nr extends $h{constructor(t){super(t)}poolingFunction(t,e,n,i,a){return Ft(a),se(i),Ei(t,e,n,i,a,"avg")}}Nr.className="AveragePooling2D";O(Nr);class Mh extends rt{constructor(t){if(t.poolSize==null&&(t.poolSize=[2,2,2]),super(t),this.poolSize=Array.isArray(t.poolSize)?t.poolSize:[t.poolSize,t.poolSize,t.poolSize],t.strides==null)this.strides=this.poolSize;else if(Array.isArray(t.strides)){if(t.strides.length!==3)throw new x(`If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ${t.strides.length}.`);this.strides=t.strides}else this.strides=[t.strides,t.strides,t.strides];_t(this.poolSize,"poolSize"),_t(this.strides,"strides"),this.padding=t.padding==null?"valid":t.padding,this.dataFormat=t.dataFormat==null?"channelsLast":t.dataFormat,Ft(this.dataFormat),se(this.padding),this.inputSpec=[new Mt({ndim:5})]}computeOutputShape(t){t=dt(t);let e=this.dataFormat==="channelsFirst"?t[2]:t[1],n=this.dataFormat==="channelsFirst"?t[3]:t[2],i=this.dataFormat==="channelsFirst"?t[4]:t[3];return e=me(e,this.poolSize[0],this.padding,this.strides[0]),n=me(n,this.poolSize[1],this.padding,this.strides[1]),i=me(i,this.poolSize[2],this.padding,this.strides[2]),this.dataFormat==="channelsFirst"?[t[0],t[1],e,n,i]:[t[0],e,n,i,t[4]]}call(t,e){return T(()=>(this.invokeCallHook(t,e),this.poolingFunction(nt(t),this.poolSize,this.strides,this.padding,this.dataFormat)))}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}class Cr extends Mh{constructor(t){super(t)}poolingFunction(t,e,n,i,a){return Ft(a),se(i),zh(t,e,n,i,a,"max")}}Cr.className="MaxPooling3D";O(Cr);class Tr extends Mh{constructor(t){super(t)}poolingFunction(t,e,n,i,a){return Ft(a),se(i),zh(t,e,n,i,a,"avg")}}Tr.className="AveragePooling3D";O(Tr);class Rh extends rt{constructor(t){super(t),this.inputSpec=[new Mt({ndim:3})]}computeOutputShape(t){return[t[0],t[2]]}call(t,e){throw new it}}class Ar extends Rh{constructor(t){super(t||{})}call(t,e){return T(()=>{const n=nt(t);return Ot(n,1)})}}Ar.className="GlobalAveragePooling1D";O(Ar);class Dr extends Rh{constructor(t){super(t||{})}call(t,e){return T(()=>{const n=nt(t);return Rs(n,1)})}}Dr.className="GlobalMaxPooling1D";O(Dr);class Eh extends rt{constructor(t){super(t),this.dataFormat=t.dataFormat==null?"channelsLast":t.dataFormat,Ft(this.dataFormat),this.inputSpec=[new Mt({ndim:4})]}computeOutputShape(t){return t=t,this.dataFormat==="channelsLast"?[t[0],t[3]]:[t[0],t[1]]}call(t,e){throw new it}getConfig(){const t={dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}class zr extends Eh{call(t,e){return T(()=>{const n=nt(t);return this.dataFormat==="channelsLast"?Ot(n,[1,2]):Ot(n,[2,3])})}}zr.className="GlobalAveragePooling2D";O(zr);class Fr extends Eh{call(t,e){return T(()=>{const n=nt(t);return this.dataFormat==="channelsLast"?Rs(n,[1,2]):Rs(n,[2,3])})}}Fr.className="GlobalMaxPooling2D";O(Fr);class Lh extends rt{constructor(t){super(t),this.layer=t.layer}build(t){this.built=!0}get trainable(){return this.layer!=null?this.layer.trainable:!1}set trainable(t){this.layer!=null&&(this.layer.trainable=t)}get trainableWeights(){return this.layer.trainableWeights}get nonTrainableWeights(){return this.layer.nonTrainableWeights}get updates(){return this.layer._updates}get losses(){return this.layer.losses}getWeights(){return this.layer.getWeights()}setWeights(t){this.layer.setWeights(t)}getConfig(){const t={layer:{className:this.layer.getClassName(),config:this.layer.getConfig()}},e=super.getConfig();return Object.assign(t,e),t}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),this.layer!=null&&this.layer.setFastWeightInitDuringBuild(t)}static fromConfig(t,e,n={}){const i=e.layer,a=fe(i,n);delete e.layer;const o={layer:a};return Object.assign(o,e),new t(o)}}class $r extends Lh{constructor(t){super(t),this.supportsMasking=!0}build(t){if(t=dt(t),t.length<3)throw new x(`TimeDistributed layer expects an input shape >= 3D, but received input shape ${JSON.stringify(t)}`);this.inputSpec=[{shape:t}];const e=[t[0]].concat(t.slice(2));this.layer.built||(this.layer.build(e),this.layer.built=!0),super.build(t)}computeOutputShape(t){t=dt(t);const e=[t[0]].concat(t.slice(2)),n=this.layer.computeOutputShape(e),i=t[1];return[n[0],i].concat(n.slice(1))}call(t,e){return T(()=>(t=nt(t),Ah((o,r)=>[nt(this.layer.call(o,e)),[]],t,[],!1,null,null,!1,!0)[1]))}}$r.className="TimeDistributed";O($r);function VI(s){vs(Ww,"BidirectionalMergeMode",s)}const BI="concat";class Mr extends Lh{constructor(t){super(t);const e=t.layer.getConfig(),n={};n.className=t.layer.getClassName(),n.config=e,this.forwardLayer=fe(n),e.goBackwards=e.goBackwards!==!0;const i={};if(i.className=t.layer.getClassName(),i.config=e,this.backwardLayer=fe(i),this.forwardLayer.name="forward_"+this.forwardLayer.name,this.backwardLayer.name="backward_"+this.backwardLayer.name,this.mergeMode=t.mergeMode===void 0?BI:t.mergeMode,VI(this.mergeMode),t.weights)throw new it("weights support is not implemented for Bidirectional layer yet.");this._stateful=t.layer.stateful,this.returnSequences=t.layer.returnSequences,this.returnState=t.layer.returnState,this.supportsMasking=!0,this._trainable=!0,this.inputSpec=t.layer.inputSpec,this.numConstants=null}get trainable(){return this._trainable}set trainable(t){this._trainable=t,this.forwardLayer!=null&&(this.forwardLayer.trainable=t),this.backwardLayer!=null&&(this.backwardLayer.trainable=t)}getWeights(){return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights())}setWeights(t){const e=t.length,n=Math.floor(e/2);this.forwardLayer.setWeights(t.slice(0,n)),this.backwardLayer.setWeights(t.slice(n))}computeOutputShape(t){let e=this.forwardLayer.computeOutputShape(t);Array.isArray(e)&&Array.isArray(e[0])||(e=[e]),e=e;let n,i,a;return this.returnState&&(a=e.slice(1)),n=e[0],n=n,this.mergeMode==="concat"?(n[n.length-1]*=2,i=[n]):this.mergeMode==null?i=[n,n.slice()]:i=[n],this.returnState?this.mergeMode==null?i.concat(a).concat(a.slice()):[n].concat(a).concat(a.slice()):jt(i)}apply(t,e){let n=e==null?null:e.initialState,i=e==null?null:e.constants;e==null&&(e={});const a=Th(t,n,i,this.numConstants);if(t=a.inputs,n=a.initialState,i=a.constants,Array.isArray(t)&&(n=t.slice(1),t=t[0]),(n==null||n.length===0)&&i==null)return super.apply(t,e);const o=[],r=[];if(n!=null){const c=n.length;if(c%2>0)throw new x("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");e.initialState=n,o.push(...n);const u=n.map(d=>new Mt({shape:d.shape}));this.forwardLayer.stateSpec=u.slice(0,c/2),this.backwardLayer.stateSpec=u.slice(c/2),r.push(...u)}if(i!=null)throw new it("Support for constants in Bidirectional layers is not implemented yet.");const l=o[0]instanceof ze;for(const c of o)if(c instanceof ze!==l)throw new x("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");if(l){const c=[t].concat(o),u=this.inputSpec.concat(r),d=this.inputSpec;this.inputSpec=u;const h=super.apply(c,e);return this.inputSpec=d,h}else return super.apply(t,e)}call(t,e){return T(()=>{const n=e.initialState;let i,a;if(n==null)i=this.forwardLayer.call(t,e),a=this.backwardLayer.call(t,e);else{const l=n.slice(0,n.length/2),c=n.slice(n.length/2);i=this.forwardLayer.call(t,Object.assign(e,{initialState:l})),a=this.backwardLayer.call(t,Object.assign(e,{initialState:c}))}let o;this.returnState&&(Array.isArray(i)&&(o=i.slice(1).concat(a.slice(1))),i=i[0],a=a[0]),this.returnSequences&&(a=un(a,1));let r;return this.mergeMode==="concat"?r=go([i,a]):this.mergeMode==="sum"?r=X(i,a):this.mergeMode==="ave"?r=A(.5,X(i,a)):this.mergeMode==="mul"?r=A(i,a):this.mergeMode==null&&(r=[i,a]),this.returnState?this.mergeMode==null?r.concat(o):[r].concat(o):r})}resetStates(t){this.forwardLayer.resetStates(),this.backwardLayer.resetStates()}build(t){ds(this.forwardLayer.name,()=>{this.forwardLayer.build(t)}),ds(this.backwardLayer.name,()=>{this.backwardLayer.build(t)}),this.built=!0}computeMask(t,e){Array.isArray(e)&&(e=e[0]);let n;if(this.returnSequences?this.mergeMode==null?n=[e,e]:n=e:this.mergeMode==null?n=[null,null]:n=null,this.returnState){const a=this.forwardLayer.states.map(o=>null);return Array.isArray(n)?n.concat(a).concat(a):[n].concat(a).concat(a)}else return n}get trainableWeights(){return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights)}get nonTrainableWeights(){return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights)}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),this.forwardLayer!=null&&this.forwardLayer.setFastWeightInitDuringBuild(t),this.backwardLayer!=null&&this.backwardLayer.setFastWeightInitDuringBuild(t)}getConfig(){const t={mergeMode:this.mergeMode},e=super.getConfig();return Object.assign(t,e),t}static fromConfig(t,e){const n=fe(e.layer);if(delete e.layer,e.numConstants!=null)throw new it("Deserialization of a Bidirectional layer with numConstants present is not supported yet.");const i=e;return i.layer=n,new t(i)}}Mr.className="Bidirectional";O(Mr);class Rr extends rt{constructor(t){super(t),this.scale=t.scale,t.offset?this.offset=t.offset:this.offset=0}getConfig(){const t={scale:this.scale,offset:this.offset},e=super.getConfig();return Object.assign(t,e),t}call(t,e){return T(()=>(t=nt(t),t.dtype!=="float32"&&(t=Te(t,"float32")),X(A(t,this.scale),this.offset)))}}Rr.className="Rescaling";O(Rr);const{resizeBilinear:PI,cropAndResize:GI}=Ce;class Er extends rt{constructor(t){super(t),this.height=t.height,this.width=t.width}centerCrop(t,e,n,i,a,o,r,l){return T(()=>{let c,u=!1;const d=e/o,h=n/r,p=(i+e)/o,m=(a+n)/r,f=[d,h,p,m],g=[];t.rank===3?(u=!0,c=Us([t])):c=t;for(let I=0;I<c.shape[0];I++)g.push(f);const w=Ga(g,[g.length,4]),b=Em(0,g.length,1,"int32"),y=GI(c,w,b,[i,a],"nearest");return Te(u?nt(cn(y)):y,l)})}upsize(t,e,n,i){return T(()=>{const a=PI(t,[e,n]);return Te(a,i)})}call(t,e){return T(()=>{const n=nt(t),i=n.dtype,a=n.shape,o=a[a.length-3],r=a[a.length-2];let l=0;o!==this.height&&(l=Math.floor((o-this.height)/2));let c=0;return r!==this.width&&(c=Math.floor((r-this.width)/2),c===0&&(c=1)),l>=0&&c>=0?this.centerCrop(n,l,c,this.height,this.width,o,r,i):this.upsize(t,this.height,this.width,i)})}getConfig(){const t={height:this.height,width:this.width},e=super.getConfig();return Object.assign(t,e),t}computeOutputShape(t){t=dt(t);const e=t.length-3,n=t.length-2;return t[e]=this.height,t[n]=this.width,t}}Er.className="CenterCrop";O(Er);function HI(s,t,e,n){let i=nt(s);if(i.dtype!=="int32"&&(i=Te(i,"int32")),t==="int")return i;const a=i.shape;if(i.rank===0&&(i=Ve(i,-1)),t==="oneHot"&&i.shape[i.shape.length-1]!==1&&(i=Ve(i,-1)),i.rank>2)throw new x(`When outputMode is not int, maximum output rank is 2 Received outputMode ${t} and input shape ${a} which would result in output rank ${i.rank}.`);const o=["multiHot","oneHot"].includes(t),r=i;let l;if(typeof n<"u"&&t==="count"?l=sl(r,n,e,o):l=sl(r,[],e,o),t!=="tfIdf")return l;if(n)return A(l,n);throw new x("When outputMode is 'tfIdf', weights must be provided.")}class Lr extends rt{constructor(t){super(t),this.numTokens=t.numTokens,t.outputMode?this.outputMode=t.outputMode:this.outputMode="multiHot"}getConfig(){const t={numTokens:this.numTokens,outputMode:this.outputMode},e=super.getConfig();return Object.assign(t,e),t}computeOutputShape(t){return t=dt(t),t==null?[this.numTokens]:this.outputMode==="oneHot"&&t[t.length-1]!==1?(t.push(this.numTokens),t):(t[t.length-1]=this.numTokens,t)}call(t,e){return T(()=>{t=nt(t),t.dtype!=="int32"&&(t=Te(t,"int32"));let n;if(typeof e.countWeights<"u"){if(this.outputMode!=="count")throw new x(`countWeights is not used when outputMode !== count.
              Received countWeights=${e.countWeights}`);n=nt(e.countWeights)}const i=Rs(t),a=wu(t),o=ke(this.numTokens,i).bufferSync().get(0),r=Hs(a,0).bufferSync().get(0);if(!(o&&r))throw new x(`Input values must be between 0 < values <= numTokens with numTokens=${this.numTokens}`);return HI(t,this.outputMode,this.numTokens,n)})}}Lr.className="CategoryEncoding";O(Lr);const UI=["bilinear","nearest"],zl=new Set(UI);class Or extends rt{constructor(t){if(super(t),this.height=t.height,this.width=t.width,t.interpolation)if(zl.has(t.interpolation))this.interpolation=t.interpolation;else throw new x(`Invalid interpolation parameter: ${t.interpolation} is not implemented`);else this.interpolation="bilinear";this.cropToAspectRatio=!!t.cropToAspectRatio}computeOutputShape(t){t=dt(t);const e=t[2];return[this.height,this.width,e]}getConfig(){const t={height:this.height,width:this.width,interpolation:this.interpolation,cropToAspectRatio:this.cropToAspectRatio},e=super.getConfig();return Object.assign(t,e),t}call(t,e){return T(()=>{const n=[this.height,this.width];if(this.interpolation==="bilinear")return Ce.resizeBilinear(t,n,!this.cropToAspectRatio);if(this.interpolation==="nearest")return Ce.resizeNearestNeighbor(t,n,!this.cropToAspectRatio);throw new Error(`Interpolation is ${this.interpolation} but only ${[...zl]} are supported`)})}}Or.className="Resizing";O(Or);class Oh{constructor(t){this.seed=t}next(){if(this.seed!==void 0)return this.seed++}}Oh.className="RandomSeed";class _h extends rt{constructor(t){super(t),this.randomGenerator=new Oh(t.seed)}getConfig(){const t={seed:this.randomGenerator.seed},e=super.getConfig();return Object.assign(t,e),t}}_h.className="BaseRandomLayer";const jI=["bilinear","nearest"],Fl=new Set(jI);class _r extends _h{constructor(t){super(t);const{factor:e,interpolation:n="bilinear"}=t;if(this.factor=e,Array.isArray(this.factor)&&this.factor.length===2)this.widthLower=this.factor[0],this.widthUpper=this.factor[1];else if(!Array.isArray(this.factor)&&this.factor>0)this.widthLower=-this.factor,this.widthUpper=this.factor;else throw new x(`Invalid factor: ${this.factor}. Must be positive number or tuple of 2 numbers`);if(this.widthLower<-1||this.widthUpper<-1)throw new x(`factor must have values larger than -1. Got: ${this.factor}`);if(this.widthUpper<this.widthLower)throw new x(`factor cannot have upper bound less than lower bound.
        Got upper bound: ${this.widthUpper}.
        Got lower bound: ${this.widthLower}
      `);if(n)if(Fl.has(n))this.interpolation=n;else throw new x(`Invalid interpolation parameter: ${n} is not implemented`)}getConfig(){const t={factor:this.factor,interpolation:this.interpolation},e=super.getConfig();return Object.assign(t,e),t}computeOutputShape(t){t=dt(t);const e=t[2];return[this.imgHeight,-1,e]}call(t,e){return T(()=>{const n=nt(t);this.imgHeight=n.shape[n.shape.length-3];const i=n.shape[n.shape.length-2];this.widthFactor=mi([1],1+this.widthLower,1+this.widthUpper,"float32",this.randomGenerator.next());let a=this.widthFactor.dataSync()[0]*i;a=Math.round(a);const o=[this.imgHeight,a];switch(this.interpolation){case"bilinear":return Ce.resizeBilinear(t,o);case"nearest":return Ce.resizeNearestNeighbor(t,o);default:throw new Error(`Interpolation is ${this.interpolation}
          but only ${[...Fl]} are supported`)}})}}_r.className="RandomWidth";O(_r);function qI(s){return new qs(s)}function KI(s){return new Vo(s)}function ZI(s){return new Oo(s)}function JI(s){return new _o(s)}function XI(s){return new Wo(s)}function YI(s){return new Po(s)}function QI(s){return new Bo(s)}function tx(s){return new Dn(s)}function ex(s){return new Js(s)}function sx(s){return new Ho(s)}function nx(s){return new Xs(s)}function ix(s){return new Uo(s)}function ax(s){return new jo(s)}function ox(s){return new qo(s)}function rx(s){return new Ko(s)}function lx(s){return new Zo(s)}function cx(s){return new nr(s)}function ux(s){return new er(s)}function hx(s){return new Ri(s)}function dx(s){return new tr(s)}function px(s){return new sr(s)}function fx(s){return new ir(s)}function mx(s){return new ar(s)}function gx(s){return new or(s)}function bx(s){return new lr(s)}function yx(s){return new cr(s)}function wx(s){return new hr(s)}function kx(s){return new fr(s)}function Ix(s){return new dr(s)}function xx(s){return new pr(s)}function Sx(s){return new ur(s)}function vx(s){return new mr(s)}function Nx(s){return new wr(s)}function Cx(s){return new kr(s)}function Tx(s){return new Ir(s)}function Wr(s){return new Sr(s)}function Ax(s){return Wr(s)}function Dx(s){return Wr(s)}function Vr(s){return new Nr(s)}function zx(s){return Vr(s)}function Fx(s){return Vr(s)}function Br(s){return new Tr(s)}function $x(s){return Br(s)}function Mx(s){return Br(s)}function Rx(s){return new Ar(s)}function Ex(s){return new zr(s)}function Wh(s){return new Dr(s)}function Vh(s){return new Fr(s)}function Bh(s){return new xr(s)}function Ph(s){return new vr(s)}function Lx(s){return new Cr(s)}function Ox(s){return new Xo(s)}function _x(s){return new Fi(s)}function Wx(s){return new Yo(s)}function Vx(s){return new Fn(s)}function Bx(s){return new Jo(s)}function Px(s){return new zi(s)}function Gx(s){return new Qo(s)}function Hx(s){return new Mi(s)}function Ux(s){return new $e(s)}function jx(s){return new $i(s)}function qx(s){return new Mr(s)}function Kx(s){return new $r(s)}const Zx=Wh,Jx=Vh,Xx=Bh,Yx=Ph;function Qx(s){return new gr(s)}function t0(s){return new br(s)}function e0(s){return new yr(s)}function s0(s){return new rr(s)}function n0(s){return new Rr(s)}function i0(s){return new Er(s)}function a0(s){return new Or(s)}function o0(s){return new Lr(s)}function r0(s){return new _r(s)}const XT=Object.freeze(Object.defineProperty({__proto__:null,Layer:rt,RNN:$e,RNNCell:zn,activation:cx,add:yx,alphaDropout:e0,average:wx,averagePooling1d:Wr,averagePooling2d:Vr,averagePooling3d:Br,avgPool1d:Ax,avgPool2d:zx,avgPool3d:$x,avgPooling1d:Dx,avgPooling2d:Fx,avgPooling3d:Mx,batchNormalization:Nx,bidirectional:qx,categoryEncoding:o0,centerCrop:i0,concatenate:kx,conv1d:tx,conv2d:ex,conv2dTranspose:sx,conv3d:nx,conv3dTranspose:ix,convLstm2d:Gx,convLstm2dCell:Hx,cropping2D:ox,dense:ux,depthwiseConv2d:lx,dot:vx,dropout:hx,elu:KI,embedding:bx,flatten:px,gaussianDropout:t0,gaussianNoise:Qx,globalAveragePooling1d:Rx,globalAveragePooling2d:Ex,globalMaxPool1d:Zx,globalMaxPool2d:Jx,globalMaxPooling1d:Wh,globalMaxPooling2d:Vh,gru:Ox,gruCell:_x,input:AI,inputLayer:qI,layerNormalization:Cx,leakyReLU:JI,lstm:Wx,lstmCell:Vx,masking:s0,maxPool1d:Xx,maxPool2d:Yx,maxPooling1d:Bh,maxPooling2d:Ph,maxPooling3d:Lx,maximum:Ix,minimum:xx,multiply:Sx,permute:gx,prelu:XI,randomWidth:r0,reLU:ZI,repeatVector:fx,rescaling:n0,reshape:mx,resizing:a0,rnn:Ux,separableConv2d:ax,simpleRNN:Bx,simpleRNNCell:Px,softmax:YI,spatialDropout1d:dx,stackedRNNCells:jx,thresholdedReLU:QI,timeDistributed:Kx,upSampling2d:rx,zeroPadding2d:Tx},Symbol.toStringTag,{value:"Module"}));function l0(s,t){return Fo(s,t)}function c0(s,t){return th(s,t)}function u0(s,t){return eh(s,t)}function h0(s,t){return $o(s,t)}function d0(s,t){return Mo(s,t)}function p0(s,t){return Qu(s,t)}function f0(s,t){return Zk(s,t)}function m0(s,t){return zo(s,t)}function g0(s,t){return Ti(s,t)}function b0(s,t){return Ks(s,t)}function y0(s,t){return Ks(s,t)}function w0(s,t){return Ks(s,t)}function k0(s,t){return Ns(s,t)}function I0(s,t){return Ns(s,t)}function x0(s,t){return Ns(s,t)}function S0(s,t){return Jk(s,t)}const YT=Object.freeze(Object.defineProperty({__proto__:null,MAPE:y0,MSE:I0,binaryAccuracy:l0,binaryCrossentropy:c0,categoricalAccuracy:h0,categoricalCrossentropy:d0,cosineProximity:m0,mape:w0,meanAbsoluteError:g0,meanAbsolutePercentageError:b0,meanSquaredError:k0,mse:x0,precision:p0,r2Score:S0,recall:f0,sparseCategoricalAccuracy:u0},Symbol.toStringTag,{value:"Module"}));const QT=Object.freeze(Object.defineProperty({__proto__:null,modelFromJSON:NI},Symbol.toStringTag,{value:"Module"}));function v0(s){return new An(s)}function N0(s){return DI(s)}function C0(s){return zI(s)}const tA=Object.freeze(Object.defineProperty({__proto__:null,l1:N0,l1l2:v0,l2:C0},Symbol.toStringTag,{value:"Module"}));class T0 extends Os{constructor(){super(...arguments),this.model=null}setModel(t){if(!(t instanceof Qe))throw new Error("model must be a LayersModel, not some other Container");this.model=t}}function _n(s,t){return s<t}function $l(s,t){return s>t}class A0 extends T0{constructor(t){if(super(),t==null&&(t={}),t.restoreBestWeights)throw new it("restoreBestWeights = True is not implemented in EarlyStopping yet.");this.monitor=t.monitor||"val_loss",this.minDelta=Math.abs(t.minDelta||0),this.patience=t.patience||0,this.verbose=t.verbose||0,this.mode=t.mode||"auto",this.baseline=t.baseline,["auto","min","max"].indexOf(this.mode)===-1&&(console.warn(`EarlyStopping mode '${this.mode}' is invalid. Falling back to mode 'auto'.`),this.mode="auto"),this.mode==="min"?this.monitorFunc=_n:this.mode==="max"?this.monitorFunc=$l:this.monitor.indexOf("acc")!==-1?this.monitorFunc=$l:this.monitorFunc=_n,this.monitorFunc===_n&&(this.minDelta*=-1)}async onTrainBegin(t){this.wait=0,this.stoppedEpoch=0,this.baseline!=null?this.best=this.baseline:this.best=this.monitorFunc===_n?1/0:-1/0}async onEpochEnd(t,e){await Ke(e);const n=this.getMonitorValue(e);n!=null&&(this.monitorFunc(n-this.minDelta,this.best)?(this.best=n,this.wait=0):(this.wait++,this.wait>=this.patience&&(this.stoppedEpoch=t,this.model.stopTraining=!0)))}async onTrainEnd(t){this.stoppedEpoch>0&&this.verbose&&console.log(`Epoch ${this.stoppedEpoch}: early stopping.`)}getMonitorValue(t){t==null&&(t={});const e=t[this.monitor];return e==null&&console.warn(`Metric for EarlyStopping ${this.monitor} is not available. Available metrics are: ${Object.keys(t)}`),e}}function D0(s){return new A0(s)}const eA={earlyStopping:D0};const z0="4.22.0";function F0(s,t){return ti(s,t)}function ti(s,t,e=new Map,n=new Set){if(s==null)return null;if(typeof Blob=="function"&&s instanceof Blob)return s.slice();if(n.has(s))throw new Error("Circular references are not supported.");if(e.has(s))return e.get(s);const i=t(s);if(i.recurse&&i.value!==null)throw new Error("A deep map function may not return both a value and recurse=true.");if(i.recurse)if(Ws(s)){const a=Array.isArray(s)?[]:{};n.add(s);for(const o in s){const r=s[o],l=ti(r,t,e,n);a[o]=l}return n.delete(s),s.__proto__&&(a.__proto__=s.__proto__),a}else throw new Error(`Can't recurse into non-iterable type: ${s}`);else return e.set(s,i.value),i.value}function $0(s,t=Hh){return Gh(s,t)}function Gh(s,t,e=new Set){const n=s[0];if(e.has(n))throw new Error("Circular references are not supported.");const i=t(s);if(i.recurse&&i.value!==null)throw new Error("A deep zip function may not return both a value and recurse=true.");if(i.recurse)if(Ws(n)){const a=Array.isArray(n)?[]:{};e.add(n);for(const o in n){const r=s.map(c=>c[o]),l=Gh(r,t,e);a[o]=l}return e.delete(n),a}else throw new Error(`Can't recurse into non-iterable type: ${n}`);else return i.value}function Hh(s){return s===null?null:Ws(s[0])?{value:null,recurse:!0}:{value:s,recurse:!1}}async function Uh(s,t){const e=new Map;ti(s,t,e);for(const i of Array.from(e.keys())){const a=e.get(i);if(mp(a)){const o=await a;e.set(i,o)}}return ti(s,t,e)}function Ws(s){let t=!1;if(We().get("IS_BROWSER"))t=s instanceof TextDecoder;else{const{StringDecoder:e}=require("string_decoder");t=s instanceof e}return s!=null&&!ArrayBuffer.isView(s)&&(Array.isArray(s)||typeof s=="object"&&!(s instanceof re)&&!(s instanceof Promise)&&!t)}function M0(s){return s==null||R0(s)||Array.isArray(s)||typeof s=="object"&&s instanceof re||cs(s)}function R0(s){return s===null||typeof s!="object"&&typeof s!="function"}function E0(s){return F0(s,L0)}function L0(s){return s instanceof re?{value:s.clone(),recurse:!1}:Ws(s)?{value:null,recurse:!0}:{value:s,recurse:!1}}class jh{constructor(t){if(this.capacity=t,this.begin=0,this.end=0,t==null)throw new RangeError("Can't create a ring buffer of unknown capacity.");if(t<1)throw new RangeError("Can't create ring buffer of capacity < 1.");this.data=new Array(t),this.doubledCapacity=2*t}wrap(t){for(;t<0;)t+=this.doubledCapacity;return t%this.doubledCapacity}get(t){if(t<0)throw new RangeError("Can't get item at a negative index.");return this.data[t%this.capacity]}set(t,e){if(t<0)throw new RangeError("Can't set item at a negative index.");this.data[t%this.capacity]=e}length(){let t=this.end-this.begin;return t<0&&(t=this.doubledCapacity+t),t}isFull(){return this.length()===this.capacity}isEmpty(){return this.length()===0}push(t){if(this.isFull())throw new RangeError("Ring buffer is full.");this.set(this.end,t),this.end=this.wrap(this.end+1)}pushAll(t){for(const e of t)this.push(e)}pop(){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");this.end=this.wrap(this.end-1);const t=this.get(this.end);return this.set(this.end,void 0),t}unshift(t){if(this.isFull())throw new RangeError("Ring buffer is full.");this.begin=this.wrap(this.begin-1),this.set(this.begin,t)}shift(){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");const t=this.get(this.begin);return this.set(this.begin,void 0),this.begin=this.wrap(this.begin+1),t}shuffleExcise(t){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");const e=this.wrap(this.begin+t),n=this.get(e);return this.set(e,this.pop()),n}}class Li extends jh{constructor(){super(Li.INITIAL_CAPACITY)}isFull(){return!1}push(t){super.isFull()&&this.expand(),super.push(t)}unshift(t){super.isFull()&&this.expand(),super.unshift(t)}expand(){const t=this.capacity*2,e=new Array(t),n=this.length();for(let i=0;i<n;i++)e[i]=this.get(this.wrap(this.begin+i));this.data=e,this.capacity=t,this.doubledCapacity=2*this.capacity,this.begin=0,this.end=n}}Li.INITIAL_CAPACITY=32;function qh(s){return new W0(s)}function Pr(s){return new V0(s)}function O0(s,t){return new Kh(s,t)}function _0(s,t=Je.FAIL){return new Z0(s,t)}class Wt{async toArray(){const t=[];let e=await this.next();for(;!e.done;)t.push(e.value),e=await this.next();return t}async toArrayForTest(){const t=this.prefetch(100),e=[];let n=await t.next();for(;!n.done;)e.push(n.value),n=await t.next();return e}async resolveFully(){let t=await this.next();for(;!t.done;)t=await this.next()}async resolveWhile(t){let e=await this.next(),n=t(e.value);for(;!e.done&&n;)e=await this.next(),n=t(e.value)}handleErrors(t){return new q0(this,t)}filter(t){return new U0(this,t)}map(t){return new j0(this,t)}mapAsync(t){return new Ml(this,t)}serialMapAsync(t){return new Ml(this,t).serial()}flatmap(t){return new K0(this,t)}async forEachAsync(t){return this.map(t).resolveFully()}async serialForEach(t){return this.serialMapAsync(t).resolveWhile(e=>e===!0)}rowMajorBatch(t,e=!0){return new H0(this,t,e)}columnMajorBatch(t,e=!0,n=Hh){return this.rowMajorBatch(t,e).map(a=>$0(a,n))}concatenate(t,e){return new Kh(qh([this,t]),e)}take(t){return t<0||t==null?this:new G0(this,t)}skip(t){return t<0||t==null?this:new P0(this,t)}prefetch(t){return new Zh(this,t)}shuffle(t,e){return new J0(this,t,e)}serial(){return new B0(this)}}class W0 extends Wt{constructor(t){super(),this.items=t,this.trav=0}summary(){return`Array of ${this.items.length} items`}async next(){if(this.trav>=this.items.length)return{value:null,done:!0};const t=this.items[this.trav];return this.trav++,{value:E0(t),done:!1}}}class V0 extends Wt{constructor(t){super(),this.nextFn=t}summary(){return"Function call"}async next(){try{return this.nextFn()}catch(t){throw t.message=`Error thrown while iterating through a dataset: ${t.message}`,t}}}class B0 extends Wt{constructor(t){super(),this.upstream=t,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> Serial`}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){return this.upstream.next()}}class P0 extends Wt{constructor(t,e){super(),this.upstream=t,this.maxCount=e,this.count=0,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> Skip`}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){for(;this.count++<this.maxCount;){const t=await this.upstream.next();if(t.done)return t;gt(t.value)}return this.upstream.next()}}class G0 extends Wt{constructor(t,e){super(),this.upstream=t,this.maxCount=e,this.count=0}summary(){return`${this.upstream.summary()} -> Take`}async next(){return this.count++>=this.maxCount?{value:null,done:!0}:this.upstream.next()}}class H0 extends Wt{constructor(t,e,n=!0){super(),this.upstream=t,this.batchSize=e,this.enableSmallLastBatch=n,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> RowMajorBatch`}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){const t=[];for(;t.length<this.batchSize;){const e=await this.upstream.next();if(e.done)return this.enableSmallLastBatch&&t.length>0?{value:t,done:!1}:{value:null,done:!0};t.push(e.value)}return{value:t,done:!1}}}class U0 extends Wt{constructor(t,e){super(),this.upstream=t,this.predicate=e,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> Filter`}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){for(;;){const t=await this.upstream.next();if(t.done||this.predicate(t.value))return t;gt(t.value)}}}class j0 extends Wt{constructor(t,e){super(),this.upstream=t,this.transform=e}summary(){return`${this.upstream.summary()} -> Map`}async next(){const t=await this.upstream.next();if(t.done)return{value:null,done:!0};const e=Ms(t.value),n=this.transform(t.value),i=Ms(n);for(const a of e)Ha(a,i)||a.dispose();return{value:n,done:!1}}}class q0 extends Wt{constructor(t,e){super(),this.upstream=t,this.handler=e,this.count=0,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> handleErrors`}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){for(;;)try{return await this.upstream.next()}catch(t){if(!this.handler(t))return{value:null,done:!0}}}}class Ml extends Wt{constructor(t,e){super(),this.upstream=t,this.transform=e}summary(){return`${this.upstream.summary()} -> AsyncMap`}async next(){const t=await this.upstream.next();if(t.done)return{value:null,done:!0};const e=Ms(t.value),n=await this.transform(t.value),i=Ms(n);for(const a of e)Ha(a,i)||a.dispose();return{value:n,done:!1}}}class Gr extends Wt{constructor(){super(),this.outputQueue=new Li,this.lastRead=Promise.resolve({value:null,done:!1})}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){for(;this.outputQueue.length()===0;)if(!await this.pump())return{value:null,done:!0};return{value:this.outputQueue.shift(),done:!1}}}class K0 extends Gr{constructor(t,e){super(),this.upstream=t,this.transform=e}summary(){return`${this.upstream.summary()} -> Flatmap`}async pump(){const t=await this.upstream.next();if(t.done)return!1;const e=Ms(t.value),n=this.transform(t.value),i=Ms(n);this.outputQueue.pushAll(n);for(const a of e)Ha(a,i)||a.dispose();return!0}}class Kh extends Wt{constructor(t,e){super(),this.baseErrorHandler=e,this.lastRead=null,this.iterator=null,this.moreIterators=t}summary(){return"TODO: fill in upstream of chained summaries -> Chained"}async next(){return this.lastRead=this.readFromChain(this.lastRead),this.lastRead}async readFromChain(t){if(await t,this.iterator==null){const n=await this.moreIterators.next();if(n.done)return{value:null,done:!0};this.iterator=n.value,this.baseErrorHandler!=null&&(this.iterator=this.iterator.handleErrors(this.baseErrorHandler))}const e=await this.iterator.next();return e.done?(this.iterator=null,this.readFromChain(t)):e}}var Je;(function(s){s[s.FAIL=0]="FAIL",s[s.SHORTEST=1]="SHORTEST",s[s.LONGEST=2]="LONGEST"})(Je||(Je={}));class Z0 extends Wt{constructor(t,e=Je.FAIL){super(),this.iterators=t,this.mismatchMode=e,this.count=0,this.currentPromise=null}summary(){return"{TODO: fill in upstream of zip summaries} -> Zip"}async nextState(t){await t;let e=0,n=0;function i(o){return o instanceof Wt?{value:o.next().then(l=>(e++,l.done&&n++,l.value)),recurse:!1}:{value:null,recurse:!0}}const a=await Uh(this.iterators,i);if(e===n)return{value:null,done:!0};if(n>0)switch(this.mismatchMode){case Je.FAIL:throw new Error(`Zipped streams should have the same length. Mismatched at element ${this.count}.`);case Je.SHORTEST:return{value:null,done:!0};case Je.LONGEST:}return this.count++,{value:a,done:!1}}async next(){return this.currentPromise=this.nextState(this.currentPromise),this.currentPromise}}class Zh extends Wt{constructor(t,e){super(),this.upstream=t,this.bufferSize=e,this.buffer=new jh(e)}summary(){return`${this.upstream.summary()} -> Prefetch`}refill(){for(;!this.buffer.isFull();){const t=this.upstream.next();this.buffer.push(t)}}next(){return this.refill(),this.buffer.shift()}}class J0 extends Zh{constructor(t,e,n){super(t,e),this.upstream=t,this.windowSize=e,this.upstreamExhausted=!1,this.random=co.alea(n||$s().toString()),this.lastRead=Promise.resolve({value:null,done:!1})}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}randomInt(t){return Math.floor(this.random()*t)}chooseIndex(){return this.randomInt(this.buffer.length())}async serialNext(){for(this.upstreamExhausted||this.refill();!this.buffer.isEmpty();){const t=this.chooseIndex(),e=await this.buffer.shuffleExcise(t);if(e.done)this.upstreamExhausted=!0;else return this.refill(),e}return{value:null,done:!0}}}class Ys{constructor(){this.size=null}batch(t,e=!0){const n=this;K(t>0,()=>`batchSize needs to be positive, but it is
      ${t}`);let i;return this.size===1/0||this.size==null?i=this.size:e?i=Math.ceil(this.size/t):i=Math.floor(this.size/t),Kt(async()=>(await n.iterator()).columnMajorBatch(t,e,Q0),i)}concatenate(t){const e=this;let n;return this.size===1/0||t.size===1/0?n=1/0:this.size!=null&&t.size!=null?n=this.size+t.size:n=null,Kt(async()=>(await e.iterator()).concatenate(await t.iterator()),n)}filter(t){const e=this;let n;return this.size===1/0?n=1/0:n=null,Kt(async()=>(await e.iterator()).filter(i=>T(()=>t(i))),n)}async forEachAsync(t){return(await this.iterator()).forEachAsync(t)}map(t){const e=this;return Kt(async()=>(await e.iterator()).map(n=>T(()=>t(n))),this.size)}mapAsync(t){const e=this;return Kt(async()=>(await e.iterator()).mapAsync(t),this.size)}prefetch(t){if(t==null)throw new RangeError("`Dataset.prefetch()` requires bufferSize to be specified.");const e=this;return Kt(async()=>(await e.iterator()).prefetch(t),this.size)}repeat(t){const e=this;let n;return this.size!=null&&t>0?n=this.size*t:t===0?n=0:this.size!=null&&(t===void 0||t<0)?n=1/0:n=null,Kt(async()=>{const i=Pr(async()=>({value:await e.iterator(),done:!1}));return O0(i.take(t))},n)}skip(t){const e=this;let n;return this.size!=null&&t>=0&&this.size>=t?n=this.size-t:this.size!=null&&(this.size<t||t===void 0||t<0)?n=0:n=null,Kt(async()=>(await e.iterator()).skip(t),n)}shuffle(t,e,n=!0){if(t==null||t<0)throw this.size==null?new RangeError("`Dataset.shuffle()` requires bufferSize to be specified."):new RangeError(`\`Dataset.shuffle()\` requires bufferSize to be specified.  If your data fits in main memory (for regular JS objects), and/or GPU memory (for \`tf.Tensor\`s), consider setting bufferSize to the dataset size (${this.size} elements)`);const i=this,a=co.alea(e||$s().toString());return Kt(async()=>{let o=a.int32();return n&&(o+=a.int32()),(await i.iterator()).shuffle(t,o.toString())},this.size)}take(t){const e=this;let n;return this.size!=null&&this.size>t?n=t:this.size!=null&&this.size<=t?n=this.size:n=null,Kt(async()=>(await e.iterator()).take(t),n)}async toArray(){if(this.size===1/0)throw new Error("Can not convert infinite data stream to array.");return(await this.iterator()).toArray()}async toArrayForTest(){if(this.size===1/0)throw new Error("Can not convert infinite data stream to array.");return(await this.iterator()).toArrayForTest()}}Ys.MAX_BUFFER_SIZE=1e4;function Kt(s,t=null){return new class extends Ys{constructor(){super(...arguments),this.size=t}async iterator(){return s()}}}function X0(s){return Kt(async()=>qh(s),s.length)}function Y0(s){if(!Ws(s))throw new Error("The argument to zip() must be an object or array.");let t;if(Array.isArray(s))for(let e=0;e<s.length;e++)t=t==null?s[e].size:Math.min(t,s[e].size);else if(s instanceof Object)for(const e in s)t=t==null?s[e].size:Math.min(t,s[e].size);return Kt(async()=>{const e=await Uh(s,n=>{if(n instanceof Ys)return{value:n.iterator(),recurse:!1};if(Ws(n))return{value:null,recurse:!0};throw new Error("Leaves of the structure passed to zip() must be Datasets, not primitives.")});return _0(e,Je.SHORTEST)},t)}function Q0(s){if(s===null)return null;const t=s[0];return M0(t)?{value:tS(s),recurse:!1}:{value:null,recurse:!0}}function tS(s){if(s.length===0)throw new Error("Can't make a batch of zero elements.");return s[0]instanceof re?Us(s):Ga(s)}class Jh extends Ys{constructor(t){super(),this.input=t}async iterator(){return(await this.input.iterator()).decodeUTF8().split(`
`).map(i=>(i.endsWith("\r")&&(i=i.slice(0,-1)),i))}}const Wn='"',sn=Symbol("out"),Rl=Symbol("field"),Vn=Symbol("quote"),qi=Symbol("quoteafterquote"),El=Symbol("quoteinquote");class Xh extends Ys{async columnNames(){return this.columnNamesValidated||await this.setColumnNames(),this.configuredColumnsOnly?Object.keys(this.columnConfigs):this.fullColumnNames}async setColumnNames(){const t=await this.maybeReadHeaderLine();if(!this.fullColumnNames&&!t)throw new Error("Column names must be provided if there is no header line.");this.fullColumnNames&&t&&K(t.length===this.fullColumnNames.length,()=>"The length of provided columnNames ("+this.fullColumnNames.length.toString()+") does not match the length of the header line read from file ("+t.length.toString()+")."),this.fullColumnNames||(this.fullColumnNames=t);const e=this.fullColumnNames.reduce((i,a)=>(i[a]=i[a]+1||1,i),{}),n=Object.keys(e).filter(i=>e[i]>1);if(K(n.length===0,()=>"Duplicate column names found: "+n.toString()),this.columnConfigs){for(const i of Object.keys(this.columnConfigs))if(this.fullColumnNames.indexOf(i)===-1)throw new Error('The key "'+i+'" provided in columnConfigs does not match any of the column names ('+this.fullColumnNames.toString()+").")}this.columnNamesValidated=!0}async maybeReadHeaderLine(){if(this.hasHeader){const e=await(await this.base.iterator()).next();if(e.done)throw new Error("No data was found for CSV parsing.");const n=e.value;return this.parseRow(n,!1)}else return null}constructor(t,e){super(),this.input=t,this.hasHeader=!0,this.fullColumnNames=null,this.columnNamesValidated=!1,this.columnConfigs=null,this.configuredColumnsOnly=!1,this.delimiter=",",this.delimWhitespace=!1,this.base=new Jh(t),e||(e={}),this.hasHeader=e.hasHeader!==!1,this.fullColumnNames=e.columnNames,this.columnConfigs=e.columnConfigs,this.configuredColumnsOnly=e.configuredColumnsOnly,e.delimWhitespace?(K(e.delimiter==null,()=>"Delimiter should not be provided when delimWhitespace is true."),this.delimWhitespace=!0,this.delimiter=" "):this.delimiter=e.delimiter?e.delimiter:","}async iterator(){this.columnNamesValidated||await this.setColumnNames();let t=await this.base.iterator();return this.hasHeader&&(t=t.skip(1)),t.map(e=>this.makeDataElement(e))}makeDataElement(t){const e=this.parseRow(t),n={},i={};for(let a=0;a<this.fullColumnNames.length;a++){const o=this.fullColumnNames[a],r=this.columnConfigs?this.columnConfigs[o]:null;if(!(this.configuredColumnsOnly&&!r)){const l=e[a];let c=null;if(l==="")if(r&&r.default!==void 0)c=r.default;else{if(r&&(r.required||r.isLabel))throw new Error(`Required column ${o} is empty in this line: ${t}`);c=void 0}else{const u=Number(l);if(isNaN(u))r&&r.dtype==="bool"?c=this.getBoolean(l):c=l;else if(!r||!r.dtype)c=u;else switch(r.dtype){case"float32":c=u;break;case"int32":c=Math.floor(u);break;case"bool":c=this.getBoolean(l);break;default:c=u}}r&&r.isLabel?i[o]=c:n[o]=c}}return Object.keys(i).length===0?n:{xs:n,ys:i}}getBoolean(t){return t==="1"||t.toLowerCase()==="true"?1:0}parseRow(t,e=!0){const n=[];let i=0;const a=t.length;let o=sn;for(let r=0;r<a;r++)switch(o){case sn:switch(t.charAt(r)){case Wn:i=r+1,o=Vn;break;case this.delimiter:if(i=r+1,this.delimiter===" "&&this.delimWhitespace)break;n.push(""),o=sn;break;default:o=Rl,i=r;break}break;case Rl:t.charAt(r)===this.delimiter&&(n.push(t.substring(i,r)),o=sn,i=r+1);break;case Vn:t.charAt(r)===Wn&&(o=qi);break;case qi:switch(t.charAt(r)){case this.delimiter:n.push(t.substring(i,r-1)),o=sn,i=r+1;break;case Wn:o=Vn;break;default:o=El;break}break;case El:t.charAt(r)===Wn&&(o=Vn);break}if(o===qi?n.push(t.substring(i,a-1)):n.push(t.substring(i)),e&&n.length!==this.fullColumnNames.length)throw new Error(`Invalid row in csv file. Should have ${this.fullColumnNames.length} elements in a row, but got ${n}`);return n}}class Hr extends Wt{constructor(t){super(),this.microphoneConfig=t,this.isClosed=!1,this.fftSize=t.fftSize||1024;const e=Math.log2(this.fftSize);if(this.fftSize<0||e<4||e>14||!Number.isInteger(e))throw new Error(`Invalid fftSize: it must be a power of 2 between 2 to 4 and 2 to 14, but got ${this.fftSize}`);if(this.numFrames=t.numFramesPerSpectrogram||43,this.sampleRateHz=t.sampleRateHz,this.columnTruncateLength=t.columnTruncateLength||this.fftSize,this.audioTrackConstraints=t.audioTrackConstraints,this.smoothingTimeConstant=t.smoothingTimeConstant||0,this.includeSpectrogram=t.includeSpectrogram!==!1,this.includeWaveform=t.includeWaveform===!0,!this.includeSpectrogram&&!this.includeWaveform)throw new Error("Both includeSpectrogram and includeWaveform are false. At least one type of data should be returned.")}summary(){return"microphone"}static async create(t={}){if(!We().get("IS_BROWSER"))throw new Error("microphone API is only supported in browser environment.");const e=new Hr(t);return await e.start(),e}async start(){try{this.stream=await navigator.mediaDevices.getUserMedia({audio:this.audioTrackConstraints==null?!0:this.audioTrackConstraints,video:!1})}catch(n){throw new Error(`Error thrown while initializing video stream: ${n.message}`)}if(!this.stream)throw new Error("Could not obtain audio from microphone.");const t=window.AudioContext||window.webkitAudioContext;if(this.audioContext=new t,!this.sampleRateHz)this.sampleRateHz=this.audioContext.sampleRate;else if(this.audioContext.sampleRate!==this.sampleRateHz)throw new Error(`Mismatch in sampling rate: Expected: ${this.sampleRateHz}; Actual: ${this.audioContext.sampleRate}`);const e=this.audioContext.createMediaStreamSource(this.stream);this.analyser=this.audioContext.createAnalyser(),this.analyser.fftSize=this.fftSize*2,this.analyser.smoothingTimeConstant=this.smoothingTimeConstant,e.connect(this.analyser),this.freqData=new Float32Array(this.fftSize),this.timeData=new Float32Array(this.fftSize)}async next(){if(this.isClosed)return{value:null,done:!0};let t,e;const n=await this.getAudioData();if(this.includeSpectrogram){const i=this.flattenQueue(n.freqDataQueue);t=this.getTensorFromAudioDataArray(i,[this.numFrames,this.columnTruncateLength,1])}if(this.includeWaveform){const i=this.flattenQueue(n.timeDataQueue);e=this.getTensorFromAudioDataArray(i,[this.numFrames*this.fftSize,1])}return{value:{spectrogram:t,waveform:e},done:!1}}async capture(){return(await this.next()).value}async getAudioData(){const t=[],e=[];let n=0;return new Promise(i=>{const a=setInterval(()=>{this.includeSpectrogram&&(this.analyser.getFloatFrequencyData(this.freqData),this.freqData[0]===-1/0&&i({freqDataQueue:t,timeDataQueue:e}),t.push(this.freqData.slice(0,this.columnTruncateLength))),this.includeWaveform&&(this.analyser.getFloatTimeDomainData(this.timeData),e.push(this.timeData.slice())),++n===this.numFrames&&(clearInterval(a),i({freqDataQueue:t,timeDataQueue:e}))},this.fftSize/this.sampleRateHz*1e3)})}stop(){this.isClosed||(this.isClosed=!0,this.analyser.disconnect(),this.audioContext.close(),this.stream!=null&&this.stream.getTracks().length>0&&this.stream.getTracks()[0].stop())}toArray(){throw new Error("Can not convert infinite audio stream to array.")}getSampleRate(){return this.sampleRateHz}flattenQueue(t){const e=t[0].length,n=new Float32Array(t.length*e);return t.forEach((i,a)=>n.set(i,a*e)),n}getTensorFromAudioDataArray(t,e){const n=new Float32Array(st(e));return n.set(t,n.length-t.length),Ga(n,e)}}class Ur extends Wt{constructor(t,e){if(super(),this.webcamVideoElement=t,this.webcamConfig=e,this.isClosed=!0,this.resize=!1,this.needToResize())if(this.resize=!0,this.cropSize=[this.webcamConfig.resizeHeight,this.webcamConfig.resizeWidth],this.cropBoxInd=dn([0],"int32"),this.webcamConfig.centerCrop){const n=this.webcamConfig.resizeWidth*1/this.webcamVideoElement.width,i=this.webcamConfig.resizeHeight*1/this.webcamVideoElement.height,a=(1-n)/2,o=(1-i)/2,r=a+n,l=i+o;this.cropBox=nl([o,a,l,r],[1,4])}else this.cropBox=nl([0,0,1,1],[1,4])}summary(){return"webcam"}static async create(t,e={}){if(!We().get("IS_BROWSER"))throw new Error("tf.data.webcam is only supported in browser environment.");if(!t){if(t=document.createElement("video"),!e.resizeWidth||!e.resizeHeight)throw new Error("Please provide webcam video element, or resizeWidth and resizeHeight to create a hidden video element.");t.width=e.resizeWidth,t.height=e.resizeHeight}const n=new Ur(t,e);return await n.start(),n}async start(){this.webcamConfig.facingMode&&K(this.webcamConfig.facingMode==="user"||this.webcamConfig.facingMode==="environment",()=>`Invalid webcam facing mode: ${this.webcamConfig.facingMode}. Please provide 'user' or 'environment'`);try{this.stream=await navigator.mediaDevices.getUserMedia({video:{deviceId:this.webcamConfig.deviceId,facingMode:this.webcamConfig.facingMode?this.webcamConfig.facingMode:"user",width:this.webcamVideoElement.width,height:this.webcamVideoElement.height}})}catch(t){throw t.message=`Error thrown while initializing video stream: ${t.message}`,t}if(!this.stream)throw new Error("Could not obtain video from webcam.");try{this.webcamVideoElement.srcObject=this.stream}catch(t){console.log(t),this.webcamVideoElement.src=window.URL.createObjectURL(this.stream)}return this.webcamVideoElement.play(),this.isClosed=!1,new Promise(t=>{this.webcamVideoElement.onloadedmetadata=()=>{t()}})}async next(){if(this.isClosed)return{value:null,done:!0};let t;try{t=Lm(this.webcamVideoElement)}catch(e){throw new Error(`Error thrown converting video to pixels: ${JSON.stringify(e)}`)}if(this.resize)try{return{value:this.cropAndResizeFrame(t),done:!1}}catch(e){throw new Error(`Error thrown cropping the video: ${e.message}`)}finally{t.dispose()}else return{value:t,done:!1}}needToResize(){return!!(this.webcamConfig.resizeWidth&&this.webcamConfig.resizeHeight&&(this.webcamVideoElement.width!==this.webcamConfig.resizeWidth||this.webcamVideoElement.height!==this.webcamConfig.resizeHeight))}cropAndResizeFrame(t){return T(()=>{const e=Ve(J(t,"float32"),0);let n;n=Ce.cropAndResize(e,this.cropBox,this.cropBoxInd,this.cropSize,"bilinear");const i=n.shape;return B(n,i.slice(1))})}async capture(){return(await this.next()).value}stop(){this.stream.getTracks().forEach(e=>e.stop());try{this.webcamVideoElement.srcObject=null}catch(e){console.log(e),this.webcamVideoElement.src=null}this.isClosed=!0}toArray(){throw new Error("Can not convert infinite video stream to array.")}}class Yh{}class Qh extends Wt{split(t){return new eS(this,t)}}class eS extends Qh{constructor(t,e){super(),this.upstream=t,this.impl=new sS(t,e)}summary(){return this.impl.summary()}async next(){return this.impl.next()}}class sS extends Gr{constructor(t,e){super(),this.upstream=t,this.separator=e,this.carryover=""}summary(){return`${this.upstream.summary()} -> Split('${this.separator}')`}async pump(){const t=await this.upstream.next();if(t.done)return this.carryover===""?!1:(this.outputQueue.push(this.carryover),this.carryover="",!0);const e=t.value.split(this.separator);e[0]=this.carryover+e[0];for(const n of e.slice(0,-1))this.outputQueue.push(n);return this.carryover=e[e.length-1],!0}}class nS extends Wt{decodeUTF8(){return new iS(this)}}class iS extends Qh{constructor(t){super(),this.upstream=t,this.impl=new aS(t)}summary(){return this.impl.summary()}async next(){return this.impl.next()}}class aS extends Gr{constructor(t){if(super(),this.upstream=t,We().get("IS_BROWSER"))this.decoder=new TextDecoder("utf-8");else{const{StringDecoder:e}=require("string_decoder");this.decoder=new e("utf8")}}summary(){return`${this.upstream.summary()} -> Utf8`}async pump(){const t=await this.upstream.next();let e;if(t.done)return!1;e=t.value;let n;return We().get("IS_BROWSER")?n=this.decoder.decode(e,{stream:!0}):n=this.decoder.write(Buffer.from(e.buffer)),this.outputQueue.push(n),!0}}class td extends nS{constructor(t,e={}){super(),this.file=t,this.options=e,K(t instanceof Uint8Array||(We().get("IS_BROWSER")?t instanceof File||t instanceof Blob:!1),()=>"FileChunkIterator only supports File, Blob and Uint8Array right now."),this.offset=e.offset||0,this.chunkSize=e.chunkSize||1024*1024}summary(){return`FileChunks ${this.file}`}async next(){return this.offset>=(this.file instanceof Uint8Array?this.file.byteLength:this.file.size)?{value:null,done:!0}:{value:await new Promise((e,n)=>{const i=this.offset+this.chunkSize;if(this.file instanceof Uint8Array)e(new Uint8Array(this.file.slice(this.offset,i)));else{const a=new FileReader;a.onload=r=>{let l=a.result;if(l instanceof ArrayBuffer&&(l=new Uint8Array(l)),!(l instanceof Uint8Array))return n(new TypeError("FileReader returned unknown type."));e(l)},a.onabort=r=>n(new Error("Aborted")),a.onerror=r=>n(new Error(r.type));const o=this.file.slice(this.offset,i);a.readAsArrayBuffer(o)}this.offset=i}),done:!1}}}async function oS(s,t={},e){let n,i;typeof s=="string"?n=s:(n=s.url,i=rS(s));const a=await gp(n,i);if(a.ok){const o=new Uint8Array(await a.arrayBuffer());return new td(o,t)}else throw new Error(a.statusText)}const rS=s=>({method:s.method,headers:s.headers,body:s.body,mode:s.mode,credentials:s.credentials,cache:s.cache,redirect:s.redirect,referrer:s.referrer,integrity:s.integrity});function ed(s){return typeof s=="string"&&s.slice(0,7)==="file://"}class sd extends Yh{constructor(t,e={}){super(),this.input=t,this.options=e}async iterator(){if(ed(this.input)&&We().get("IS_NODE")){const t=require("fs");this.input=t.readFileSync(this.input.slice(7))}return new td(this.input,this.options)}}class nd extends Yh{constructor(t,e={}){super(),this.url=t,this.fileOptions=e}async iterator(){return ed(this.url)?new sd(this.url,this.fileOptions).iterator():oS(this.url,this.fileOptions)}}function lS(s,t={}){return new Xh(new nd(s),t)}function cS(s){const t=Pr(s);return Kt(async()=>t)}function uS(s){return Kt(async()=>{const t=await s();return Pr(()=>t.next())})}async function hS(s,t){return Ur.create(s,t)}async function dS(s){return Hr.create(s)}const id="4.22.0";const sA=Object.freeze(Object.defineProperty({__proto__:null,CSVDataset:Xh,Dataset:Ys,FileDataSource:sd,TextLineDataset:Jh,URLDataSource:nd,array:X0,csv:lS,func:cS,generator:uS,microphone:dS,version_data:id,webcam:hS,zip:Y0},Symbol.toStringTag,{value:"Module"}));const pS=Pl;class Oi extends bp{nextDataId(){return Oi.nextDataId++}constructor(){super(),this.blockSize=48,this.firstUse=!0,this.data=new yp(this,tl())}write(t,e,n){this.firstUse&&(this.firstUse=!1,We().get("IS_NODE")&&wp(`
============================
Hi, looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, visit https://github.com/tensorflow/tfjs-node for more details. 
============================`));const i={id:this.nextDataId()};return this.data.set(i,{values:t,dtype:n,refCount:1}),i}makeTensorInfo(t,e,n){let i;if(e==="string"&&n!=null&&n.length>0&&nn(n[0])){const a=n.map(o=>_l(o));i=this.write(a,t,e)}else i=this.write(n,t,e);return{dataId:i,shape:t,dtype:e}}refCount(t){return this.data.has(t)?this.data.get(t).refCount:0}incRef(t){const e=this.data.get(t);e.refCount++}decRef(t){if(this.data.has(t)){const e=this.data.get(t);e.refCount--}}move(t,e,n,i,a){this.data.set(t,{values:e,dtype:i,refCount:a})}numDataIds(){return this.data.numDataIds()}async read(t){return this.readSync(t)}readSync(t){const{dtype:e,complexTensorInfos:n}=this.data.get(t);if(e==="complex64"){const i=this.readSync(n.real.dataId),a=this.readSync(n.imag.dataId);return gi(i,a)}return kp(this.data.get(t).values,e)}bufferSync(t){const e=this.readSync(t.dataId);if(t.dtype==="string")try{const n=e.map(i=>Uc(i));return Bt(t.shape,t.dtype,n)}catch{throw new Error("Failed to decode encoded string bytes into utf-8")}return Bt(t.shape,t.dtype,e)}makeOutput(t,e,n){return tl().makeTensorFromTensorInfo(this.makeTensorInfo(e,n,t),this)}disposeData(t,e=!1){if(this.data.has(t)){if(this.data.get(t).refCount--,!e&&this.data.get(t).refCount>0)return!1;const{complexTensorInfos:n}=this.data.get(t);n!=null&&(this.disposeData(n.real.dataId,!0),this.disposeData(n.imag.dataId,!0)),this.data.delete(t)}return!0}disposeIntermediateTensorInfo(t){this.disposeData(t.dataId)}async time(t){const e=$s();return t(),{kernelMs:$s()-e}}memory(){return{unreliable:!0,reasons:["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]}}where(t){Q([t],"where");const e=this.readSync(t.dataId);return pS(t.shape,e)}dispose(){}floatPrecision(){return 32}epsilon(){return super.epsilon()}}Oi.nextDataId=0;const fS="4.22.0";Ip("cpu",()=>new Oi,1);const ad=wt(Ia,s=>s>=0?s:Math.exp(s)-1),mS={kernelName:Ia,backendName:"cpu",kernelFunc:ad};function od(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{alpha:a}=n;Q([i],"leakyRelu");const o=st(i.shape),r=e.data.get(i.dataId).values,l=es("float32",o);for(let c=0;c<r.length;c++)l[c]=r[c]<0?a*r[c]:r[c];return e.makeTensorInfo(i.shape,"float32",l)}const gS={kernelName:hc,backendName:"cpu",kernelFunc:od};const bS=xs((s,t)=>s<0?t*s:s);function rd(s){const{inputs:t,backend:e}=s,{x:n,alpha:i}=t;Q([n,i],"prelu");const a=e.data.get(n.dataId).values,o=e.data.get(i.dataId).values,[r,l]=bS(n.shape,i.shape,a,o,"float32");return e.makeTensorInfo(l,"float32",r)}const yS={kernelName:Cc,backendName:"cpu",kernelFunc:rd};const ld=wt($a,s=>Math.max(0,s)),wS={kernelName:$a,backendName:"cpu",kernelFunc:ld};const cd=wt(Fa,s=>Math.min(Math.max(0,s),6)),kS={kernelName:Fa,backendName:"cpu",kernelFunc:cd};function ei(s,t,e,n,i){if(e==="linear")return Ss({inputs:{x:t},backend:s});if(e==="relu")return ld({inputs:{x:t},backend:s});if(e==="elu")return ad({inputs:{x:t},backend:s});if(e==="relu6")return cd({inputs:{x:t},backend:s});if(e==="prelu")return rd({inputs:{x:t,alpha:n},backend:s});if(e==="leakyrelu")return od({inputs:{x:t},backend:s,attrs:{alpha:i}});if(e==="sigmoid")return Wm({inputs:{x:t},backend:s});throw new Error(`Activation ${e} has not been implemented for the CPU backend.`)}function xt(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{shape:a}=n,o=st(i.shape),r=xp(a,o),l=st(r);K(o===l,()=>`The new shape (${r}) has ${l} elements and the old shape (${i.shape}) has ${o} elements. The new shape and old shape must have the same number of elements.`),e.incRef(i.dataId);const c=e.data.get(i.dataId);if(c.complexTensorInfos!=null){const u=c.complexTensorInfos.real,d=c.complexTensorInfos.imag;u.shape=r,d.shape=r}return{dataId:i.dataId,shape:r,dtype:i.dtype}}const IS={kernelName:Tc,backendName:"cpu",kernelFunc:xt};function ud(s){const{inputs:t,backend:e,attrs:n}=s,{a:i,b:a}=t,{transposeA:o,transposeB:r}=n;Q([i,a],"matMul");const l=i.shape.length,c=a.shape.length,u=o?i.shape[l-2]:i.shape[l-1],d=r?a.shape[c-1]:a.shape[c-2],h=o?i.shape[l-1]:i.shape[l-2],p=r?a.shape[c-2]:a.shape[c-1],m=i.shape.slice(0,-2),f=a.shape.slice(0,-2),g=st(m),w=st(f),k=Fe(i.shape.slice(0,-2),a.shape.slice(0,-2)).concat([h,p]);K(u===d,()=>`Error in matMul: inner shapes (${u}) and (${d}) of Tensors with shapes ${i.shape} and ${a.shape} and transposeA=${o} and transposeB=${r} must match.`);const y=o?[g,u,h]:[g,h,u],I=r?[w,p,d]:[w,d,p],S=xt({inputs:{x:i},backend:e,attrs:{shape:y}}),v=xt({inputs:{x:a},backend:e,attrs:{shape:I}}),N=o?S.shape[1]:S.shape[2],C=o?S.shape[2]:S.shape[1],D=r?v.shape[1]:v.shape[2],E=Math.max(g,w),V=e.data.get(S.dataId).values,M=e.data.get(v.dataId).values,L=ct(S.shape),F=ct(v.shape),[$,W,R]=o?[L[0],1,L[1]]:[L[0],L[1],1],[_,G,P]=r?[1,F[1],F[0]]:[F[1],1,F[0]],U=C*D,H=Bt([E,C,D],S.dtype),q=H.values,j=e.blockSize;for(let Z=0;Z<E;Z++){const Y=Z%g,et=Z%w;for(let tt=0;tt<C;tt+=j){const at=Math.min(tt+j,C);for(let ot=0;ot<D;ot+=j){const ft=Math.min(ot+j,D);for(let kt=0;kt<N;kt+=j){const At=Math.min(kt+j,N);for(let It=tt;It<at;It++)for(let bt=ot;bt<ft;bt++){let Ct=0;for(let St=kt;St<At;St++){const Me=V[Y*$+It*W+St*R],Vt=M[St*_+bt*G+et*P];Ct+=Me*Vt}q[Z*U+(It*D+bt)]+=Ct}}}}}return e.disposeIntermediateTensorInfo(S),e.disposeIntermediateTensorInfo(v),e.makeTensorInfo(k,H.dtype,H.values)}const xS={kernelName:Jl,backendName:"cpu",kernelFunc:ud};function SS(s){const{inputs:t,backend:e,attrs:n}=s,{a:i,b:a,bias:o,preluActivationWeights:r}=t,{transposeA:l,transposeB:c,activation:u,leakyreluAlpha:d}=n;let h,p,m;const f=[];h=ud({inputs:{a:i,b:a},attrs:{transposeA:l,transposeB:c},backend:e}),o&&(p=pn({inputs:{a:h,b:o},backend:e}),f.push(h),h=p),u&&(m=ei(e,h,u,r,d),f.push(h),h=m);for(const w of f)e.disposeIntermediateTensorInfo(w);return h}const vS={kernelName:Sp,backendName:"cpu",kernelFunc:SS};const NS=wt(ua,s=>Math.acos(s)),CS={kernelName:ua,backendName:"cpu",kernelFunc:NS};const TS=wt(ha,s=>Math.acosh(s)),AS={kernelName:ha,backendName:"cpu",kernelFunc:TS};function DS(s){const{inputs:t,backend:e}=s,n=t;Q(t,"addN");const i=n.map(r=>e.data.get(r.dataId).values),a=Bt(n[0].shape,n[0].dtype),o=a.values;for(let r=0;r<n.length;r++){const l=i[r];for(let c=0;c<o.length;c++)o[c]+=l[c]}return e.makeTensorInfo(a.shape,a.dtype,a.values)}const zS={kernelName:Gl,backendName:"cpu",kernelFunc:DS};function FS(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{axis:a,keepDims:o}=n;Q(i,"all");const r=Lt(a,i.shape);let l=r;const c=we(l,i.shape.length);let u=i;c!=null&&(u=ee({inputs:{x:i},backend:e,attrs:{perm:c}}),l=Ge(l.length,i.shape.length)),ys("all",l,u.shape.length);const[d,h]=Pe(u.shape,l),p=st(h),m=rs(st(d),u.dtype),f=e.data.get(u.dataId).values;for(let w=0;w<m.length;++w){const b=w*p;let k=f[b];for(let y=0;y<p;++y){const I=f[b+y];k=k&&I}m[w]=k}c!=null&&e.disposeIntermediateTensorInfo(u);const g=e.makeTensorInfo(d,u.dtype,m);if(o){const w=ts(d,r),b=xt({inputs:{x:g},backend:e,attrs:{shape:w}});return e.disposeIntermediateTensorInfo(g),b}return g}const $S={kernelName:vp,backendName:"cpu",kernelFunc:FS};function MS(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{axis:a,keepDims:o}=n;Q(i,"any");const r=Lt(a,i.shape);let l=r;const c=we(l,i.shape.length);let u=i;c!=null&&(u=ee({inputs:{x:i},backend:e,attrs:{perm:c}}),l=Ge(l.length,i.shape.length)),ys("any",l,u.shape.length);const[d,h]=Pe(u.shape,l),p=st(h),m=rs(st(d),u.dtype),f=e.data.get(u.dataId).values;for(let w=0;w<m.length;++w){const b=w*p;let k=f[b];for(let y=0;y<p;++y){const I=f[b+y];k=k||I}m[w]=k}c!=null&&e.disposeIntermediateTensorInfo(u);const g=e.makeTensorInfo(d,u.dtype,m);if(o){const w=ts(d,r),b=xt({inputs:{x:g},backend:e,attrs:{shape:w}});return e.disposeIntermediateTensorInfo(g),b}return g}const RS={kernelName:Np,backendName:"cpu",kernelFunc:MS};function ES(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{axis:a}=n;Q(i,"argMax");let o=Lt(a,i.shape);const r=we(o,i.shape.length);let l=i;const c=[];r!=null&&(l=ee({inputs:{x:i},backend:e,attrs:{perm:r}}),c.push(l),o=Ge(o.length,l.shape.length)),o=[o[0]],ys("argMax",o,l.shape.length);const[u,d]=Pe(l.shape,o),h=st(u),p=rs(h,"int32"),m=st(d),f=e.data.get(l.dataId).values;for(let g=0;g<p.length;++g){const w=g*m;let b=f[w],k=0;for(let y=0;y<m;++y){const I=f[w+y];I>b&&(b=I,k=y)}p[g]=k}return c.forEach(g=>e.disposeIntermediateTensorInfo(g)),e.makeTensorInfo(u,"int32",p)}const LS={kernelName:Hl,backendName:"cpu",kernelFunc:ES};function OS(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{axis:a}=n;Q(i,"argMin");let o=Lt(a,i.shape);const r=we(o,i.shape.length);let l=i;const c=[];r!=null&&(l=ee({inputs:{x:i},backend:e,attrs:{perm:r}}),c.push(l),o=Ge(o.length,l.shape.length)),o=[o[0]],ys("argMin",o,l.shape.length);const[u,d]=Pe(l.shape,o),h=st(u),p=rs(h,"int32"),m=st(d),f=e.data.get(l.dataId).values;for(let g=0;g<p.length;++g){const w=g*m;let b=f[w],k=0;for(let y=0;y<m;++y){const I=f[w+y];I<b&&(b=I,k=y)}p[g]=k}return c.forEach(g=>e.disposeIntermediateTensorInfo(g)),e.makeTensorInfo(u,"int32",p)}const _S={kernelName:Ul,backendName:"cpu",kernelFunc:OS};const WS=wt(da,s=>Math.asin(s)),VS={kernelName:da,backendName:"cpu",kernelFunc:WS};const BS=wt(pa,s=>Math.asinh(s)),PS={kernelName:pa,backendName:"cpu",kernelFunc:BS};const GS=wt(ma,s=>Math.atan(s)),HS={kernelName:ma,backendName:"cpu",kernelFunc:GS};const US=xs((s,t)=>Math.atan2(s,t)),jS=js(fa,US),qS={kernelName:fa,backendName:"cpu",kernelFunc:jS};const KS=wt(ga,s=>Math.atanh(s)),ZS={kernelName:ga,backendName:"cpu",kernelFunc:KS};function jr(s,t,e,n,i,a){const o=i.strideHeight,r=i.strideWidth,l=i.dilationHeight,c=i.dilationWidth,u=i.effectiveFilterHeight,d=i.effectiveFilterWidth,h=i.padInfo.top,p=i.padInfo.left,m=a==="max"?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,f=Bt(i.outShape,e),g=f.values,w=i.outShape[1]*i.outShape[2]*i.outShape[3],b=i.outShape[2]*i.outShape[3],k=i.outShape[3];for(let y=0;y<i.batchSize;++y){const I=y*w,S=y*n[0];for(let v=0;v<i.inChannels;++v)for(let N=0;N<i.outHeight;++N){const C=N*o-h,D=Math.max(0,C),E=Math.min(i.inHeight,u+C),V=I+N*b;for(let M=0;M<i.outWidth;++M){const L=M*r-p,F=Math.max(0,L),$=Math.min(i.inWidth,d+L);let W=m,R=0,_=0;for(let P=D;P<E;P+=l){const U=S+P*n[1];for(let H=F;H<$;H+=c){const q=U+H*n[2],j=s[q+v];a==="max"&&j>W?W=j:a==="avg"&&(R+=j,_++)}if(isNaN(W))break}const G=V+M*k+v;g[G]=a==="avg"?R/_:W}}}return f}function hd(s,t,e,n,i=!1,a=!1){const o=Bt(n.outShape,"int32"),r=n.strideHeight,l=n.strideWidth,c=n.dilationHeight,u=n.dilationWidth,d=n.effectiveFilterHeight,h=n.effectiveFilterWidth,p=n.padInfo.top,m=n.padInfo.left,f=Bt(t,e,s);for(let g=0;g<n.batchSize;++g)for(let w=0;w<n.inChannels;++w)for(let b=0;b<n.outHeight;++b){const k=b*r-p;let y=k;for(;y<0;)y+=c;const I=Math.min(n.inHeight,d+k);for(let S=0;S<n.outWidth;++S){const v=S*l-m;let N=v;for(;N<0;)N+=u;const C=Math.min(n.inWidth,h+v);let D=Number.NEGATIVE_INFINITY,E=-1;for(let V=y;V<I;V+=c){const M=V-k;for(let L=N;L<C;L+=u){const F=L-v,$=f.get(g,V,L,w);$>D&&(D=$,i?E=a?((g*n.inHeight+V)*n.inWidth+L)*n.inChannels+w:(V*n.inWidth+L)*n.inChannels+w:E=M*h+F)}}o.set(E,g,b,S,w)}}return o}function dd(s,t,e,n,i,a){const o=i.strideDepth,r=i.strideHeight,l=i.strideWidth,c=i.dilationDepth,u=i.dilationHeight,d=i.dilationWidth,h=i.effectiveFilterDepth,p=i.effectiveFilterHeight,m=i.effectiveFilterWidth,f=i.padInfo.front,g=i.padInfo.top,w=i.padInfo.left,b=a==="max"?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,k=Bt(i.outShape,e),y=k.values,I=i.outShape[1]*i.outShape[2]*i.outShape[3]*i.outShape[4],S=i.outShape[2]*i.outShape[3]*i.outShape[4],v=i.outShape[3]*i.outShape[4],N=i.outShape[4];for(let C=0;C<i.batchSize;++C){const D=C*I,E=C*n[0];for(let V=0;V<i.inChannels;++V)for(let M=0;M<i.outDepth;++M){const L=M*o-f;let F=L;for(;F<0;)F+=c;const $=Math.min(i.inDepth,h+L),W=D+M*S;for(let R=0;R<i.outHeight;++R){const _=R*r-g;let G=_;for(;G<0;)G+=u;const P=Math.min(i.inHeight,p+_),U=W+R*v;for(let H=0;H<i.outWidth;++H){const q=H*l-w;let j=q;for(;j<0;)j+=d;const Z=Math.min(i.inWidth,m+q),Y=U+H*N;let et=b,tt=0,at=0;for(let ft=F;ft<$;ft+=c){const kt=E+ft*n[1];for(let At=G;At<P;At+=u){const It=kt+At*n[2];for(let bt=j;bt<Z;bt+=d){const Ct=It+bt*n[3],St=s[Ct+V];if(a==="max"&&St>et?et=St:a==="avg"&&(tt+=St,at++),isNaN(et))break}if(isNaN(et))break}if(isNaN(et))break}const ot=Y+V;y[ot]=a==="avg"?tt/Math.max(at,1):et}}}}return k}function JS(s,t){const e=Bt(t.outShape,"int32"),n=t.strideDepth,i=t.strideHeight,a=t.strideWidth,o=t.dilationDepth,r=t.dilationHeight,l=t.dilationWidth,c=t.effectiveFilterDepth,u=t.effectiveFilterHeight,d=t.effectiveFilterWidth,h=t.padInfo.front,p=t.padInfo.top,m=t.padInfo.left;for(let f=0;f<t.batchSize;++f)for(let g=0;g<t.inChannels;++g)for(let w=0;w<t.outDepth;++w){const b=w*n-h;let k=b;for(;k<0;)k+=o;const y=Math.min(t.inDepth,c+b);for(let I=0;I<t.outHeight;++I){const S=I*i-p;let v=S;for(;v<0;)v+=r;const N=Math.min(t.inHeight,u+S);for(let C=0;C<t.outWidth;++C){const D=C*a-m;let E=D;for(;E<0;)E+=l;const V=Math.min(t.inWidth,d+D);let M=Number.NEGATIVE_INFINITY,L=-1;for(let F=k;F<y;F+=o){const $=F-b;for(let W=v;W<N;W+=r){const R=W-S;for(let _=E;_<V;_+=l){const G=_-D,P=s.get(f,F,W,_,g);P>=M&&(M=P,L=$*u*d+R*u+G)}}}e.set(L,f,w,I,C,g)}}}return e}function XS(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t;Q(i,"avgPool");const{filterSize:a,strides:o,pad:r,dimRoundingMode:l}=n,c=1;K(oi(o,c),()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${o} and dilations '${c}'`);const u=In(i.shape,a,o,c,r,l);let d;if(u.filterWidth===1&&u.filterHeight===1&&Jt(u.inShape,u.outShape))d=Ss({inputs:{x:i},backend:e});else{const h=e.data.get(i.dataId).values,p=ct(i.shape),m=jr(h,i.shape,i.dtype,p,u,"avg");d=e.makeTensorInfo(u.outShape,i.dtype,m.values)}return d}const YS={kernelName:Zl,backendName:"cpu",kernelFunc:XS};function QS(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{filterSize:a,strides:o,pad:r,dimRoundingMode:l,dataFormat:c}=n;Q(i,"avgPool3d");const u=ci(i.shape,a,o,1,r,l,c),d=e.data.get(i.dataId).values,h=dd(d,i.shape,i.dtype,ct(i.shape),u,"avg");return e.makeTensorInfo(h.shape,"float32",h.values)}const t1={kernelName:ql,backendName:"cpu",kernelFunc:QS};function e1(s){const{inputs:t,backend:e,attrs:n}=s,{dy:i,input:a}=t,{filterSize:o,strides:r,pad:l,dimRoundingMode:c}=n;Q([i,a],"avgPool3DGrad");const u=ci(a.shape,o,r,1,l,c),d=u.strideDepth,h=u.strideHeight,p=u.strideWidth,m=u.filterDepth,f=u.filterHeight,g=u.filterWidth,w=u.dilationDepth,b=u.dilationHeight,k=u.dilationWidth,y=u.effectiveFilterDepth,I=u.effectiveFilterHeight,S=u.effectiveFilterWidth,v=y-1-u.padInfo.front,N=S-1-u.padInfo.left,C=I-1-u.padInfo.top,D=Bt(a.shape,"float32"),E=1/(m*f*g),V=e.bufferSync(i);for(let M=0;M<u.batchSize;++M)for(let L=0;L<u.inChannels;++L)for(let F=0;F<u.inDepth;++F)for(let $=0;$<u.inHeight;++$)for(let W=0;W<u.inWidth;++W){const R=F-v,_=$-C,G=W-N;let P=0;for(let U=0;U<y;U+=w){const H=(R+U)/d;if(!(H<0||H>=u.outDepth||Math.floor(H)!==H))for(let q=0;q<I;q+=b){const j=(_+q)/h;if(!(j<0||j>=u.outHeight||Math.floor(j)!==j))for(let Z=0;Z<S;Z+=k){const Y=(G+Z)/p;if(Y<0||Y>=u.outWidth||Math.floor(Y)!==Y)continue;const et=V.get(M,H,j,Y,L);P+=et}}}D.set(P*E,M,F,$,W,L)}return e.makeTensorInfo(D.shape,D.dtype,D.values)}const s1={kernelName:jl,backendName:"cpu",kernelFunc:e1};function n1(s){const{inputs:t,backend:e,attrs:n}=s,{dy:i,input:a}=t,o=a;Q([i,a],"avgPoolGrad");const{filterSize:r,strides:l,pad:c}=n,u=In(o.shape,r,l,1,c),d=u.strideHeight,h=u.strideWidth,p=u.filterHeight,m=u.filterWidth,f=u.dilationHeight,g=u.dilationWidth,w=u.effectiveFilterHeight,b=u.effectiveFilterWidth,k=b-1-u.padInfo.left,y=w-1-u.padInfo.top,I=Bt(o.shape,"float32"),S=1/(p*m),v=e.data.get(i.dataId).values,N=Bt(i.shape,"float32",v);for(let C=0;C<u.batchSize;++C)for(let D=0;D<u.inChannels;++D)for(let E=0;E<u.inHeight;++E)for(let V=0;V<u.inWidth;++V){const M=E-y,L=V-k;let F=0;for(let $=0;$<w;$+=f){const W=(M+$)/d;if(!(W<0||W>=u.outHeight||Math.floor(W)!==W))for(let R=0;R<b;R+=g){const _=(L+R)/h;if(_<0||_>=u.outWidth||Math.floor(_)!==_)continue;const G=N.get(C,W,_,D);F+=G}}I.set(F*S,C,E,V,D)}return e.makeTensorInfo(I.shape,I.dtype,I.values)}const i1={kernelName:Kl,backendName:"cpu",kernelFunc:n1};function a1(s){const{inputs:t,backend:e,attrs:n}=s,{x:i,scale:a,offset:o,mean:r,variance:l}=t;K(r.shape.length===l.shape.length,()=>"Batch normalization gradient requires mean and variance to have equal ranks."),K(o==null||r.shape.length===o.shape.length,()=>"Batch normalization gradient requires mean and offset to have equal ranks."),K(a==null||r.shape.length===a.shape.length,()=>"Batch normalization gradient requires mean and scale to have equal ranks."),Q([i,r,l,a,o],"batchNorm");let{varianceEpsilon:c}=n;c==null&&(c=.001);const u=e.data.get(i.dataId).values,d=e.data.get(r.dataId).values,h=e.data.get(l.dataId).values,p=a?e.data.get(a.dataId).values:new Float32Array([1]),m=o?e.data.get(o.dataId).values:new Float32Array([0]),f=new Float32Array(u.length),g=m.length,w=p.length,b=h.length,k=d.length;let y=0,I=0,S=0,v=0;for(let N=0;N<u.length;++N)f[N]=m[y++]+(u[N]-d[I++])*p[S++]/Math.sqrt(h[v++]+c),y>=g&&(y=0),I>=k&&(I=0),S>=w&&(S=0),v>=b&&(v=0);return e.makeTensorInfo(i.shape,i.dtype,f)}const o1={kernelName:cc,backendName:"cpu",kernelFunc:a1};function r1(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{blockShape:a,crops:o}=n;Q([i],"batchToSpaceND");const r=a.reduce((w,b)=>w*b),l=Cu(i.shape,a,r),c=Tu(l.length,a.length),u=Au(i.shape,a,r),d=Vm(o,a.length),h=Bm(u,o,a.length),p=xt({inputs:{x:i},backend:e,attrs:{shape:l}}),m=ee({inputs:{x:p},backend:e,attrs:{perm:c}}),f=xt({inputs:{x:m},backend:e,attrs:{shape:u}}),g=Es({inputs:{x:f},backend:e,attrs:{begin:d,size:h}});return e.disposeIntermediateTensorInfo(p),e.disposeIntermediateTensorInfo(m),e.disposeIntermediateTensorInfo(f),g}const l1={kernelName:Xl,backendName:"cpu",kernelFunc:r1};function c1(s){const{inputs:t,backend:e,attrs:n}=s,{x:i,weights:a}=t,{size:o}=n,r=e.data.get(i.dataId).values,l=e.data.get(a.dataId).values,c=Du(r,l,a.dtype,a.shape,o);return e.makeTensorInfo([o],a.dtype,c)}const u1={kernelName:Cp,backendName:"cpu",kernelFunc:c1};function h1(s){const{inputs:t,backend:e}=s,{s0:n,s1:i}=t,a=e.data.get(n.dataId).values,o=e.data.get(i.dataId).values,r=Fe(Array.from(a),Array.from(o));return e.makeTensorInfo([r.length],"int32",Int32Array.from(r))}const d1={kernelName:Tp,backendName:"cpu",kernelFunc:h1};const p1=wt(ba,(s,t)=>{const e=t;return s>e.clipValueMax?e.clipValueMax:s<e.clipValueMin?e.clipValueMin:s}),f1={kernelName:ba,backendName:"cpu",kernelFunc:p1};const m1=s=>{const{x:t}=s.inputs,e=s.backend,n=new Float32Array(st(t.shape)),i=e.data.get(t.dataId),a=i.complexTensorInfos.real,o=i.complexTensorInfos.imag,r=e.data.get(a.dataId).values,l=e.data.get(o.dataId).values;for(let c=0;c<r.length;c++){const u=r[c],d=l[c];n[c]=Math.hypot(u,d)}return e.makeOutput(n,t.shape,"float32")},g1={kernelName:Yl,backendName:"cpu",kernelFunc:m1};function Vs(s){const{inputs:t,backend:e}=s,{input:n}=t,i=e.data.get(n.dataId).complexTensorInfos.imag,a=e.data.get(i.dataId).values;return e.makeTensorInfo(i.shape,i.dtype,a)}const b1={kernelName:Ap,backendName:"cpu",kernelFunc:Vs};function Bs(s){const{inputs:t,backend:e,attrs:n}=s,{axis:i}=n,a=Lt(i,t[0].shape)[0],o=t.map(f=>f.shape);Pm(o,a);let r=Vi(t.map(f=>f.shape),a);if(st(r)===0)return e.makeTensorInfo(r,t[0].dtype,[]);const l=t.filter(f=>st(f.shape)>0);if(l.length===1)return Ss({inputs:{x:l[0]},backend:e});if(l[0].dtype==="complex64"){const f=l.map(y=>fn({inputs:{input:y},backend:e})),g=l.map(y=>Vs({inputs:{input:y},backend:e})),w=Bs({inputs:f,backend:e,attrs:{axis:a}}),b=Bs({inputs:g,backend:e,attrs:{axis:a}}),k=Ne({inputs:{real:w,imag:b},backend:e});return f.forEach(y=>e.disposeIntermediateTensorInfo(y)),g.forEach(y=>e.disposeIntermediateTensorInfo(y)),e.disposeIntermediateTensorInfo(w),e.disposeIntermediateTensorInfo(b),k}const c=l.map(f=>{const w=[-1,st(f.shape.slice(a))];return xt({inputs:{x:f},backend:e,attrs:{shape:w}})}),u=c.map(f=>({vals:e.data.get(f.dataId).values,shape:f.shape}));r=Vi(c.map(f=>f.shape),1);const d=c[0].shape[0]===1,h=Gm(u,r,t[0].dtype,d),p=Vi(l.map(f=>f.shape),a),m=e.makeTensorInfo(p,t[0].dtype,h);return c.forEach(f=>e.disposeIntermediateTensorInfo(f)),m}const y1={kernelName:Ql,backendName:"cpu",kernelFunc:Bs};function pd(s){const{inputs:t,backend:e,attrs:n}=s,{x:i,filter:a}=t,{strides:o,pad:r,dataFormat:l,dilations:c,dimRoundingMode:u}=n;Q([i,a],"conv2d");const d=Ua(l),h=Gs(i.shape,a.shape,o,c,r,u,!1,d),p=h.filterHeight,m=h.filterWidth,f=h.dilationHeight,g=h.dilationWidth,w=h.padInfo.left,b=h.padInfo.top,k=h.dataFormat==="channelsLast",y=new Zt(h.outShape,i.dtype),I=ct(i.shape),S=ct(a.shape),v=I[0],N=k?I[1]:I[2],C=k?I[2]:1,D=k?1:I[1],E=y.strides[0],V=k?y.strides[1]:y.strides[2],M=k?y.strides[2]:1,L=k?1:y.strides[1],F=e.data.get(i.dataId).values,$=e.data.get(a.dataId).values,W=y.values;for(let R=0;R<h.batchSize;++R){const _=R*v,G=R*E;for(let P=0;P<h.outHeight;++P){const U=G+P*V,H=P*h.strideHeight-b;for(let q=0;q<p;++q){const j=H+q*f;if(j<0||j>=h.inHeight)continue;const Z=q*S[0],Y=_+j*N;for(let et=0;et<h.outWidth;++et){const tt=U+et*M,at=et*h.strideWidth-w;for(let ot=0;ot<m;++ot){const ft=at+ot*g;if(ft<0||ft>=h.inWidth)continue;const kt=Z+ot*S[1],At=Y+ft*C;let It=kt;for(let bt=0;bt<h.inChannels;++bt){const Ct=F[At+bt*D];for(let St=0;St<h.outChannels;++St)W[tt+St*L]+=Ct*$[It+St];It+=h.outChannels}}}}}}return e.makeTensorInfo(y.shape,y.dtype,W)}const w1={kernelName:tc,backendName:"cpu",kernelFunc:pd};function k1(s){const{inputs:t,backend:e,attrs:n}=s,{x:i,dy:a}=t,{strides:o,pad:r,dataFormat:l,dimRoundingMode:c,filterShape:u}=n;Q([i,a],"conv2dBackpropFilter");const d=Ua(l),h=Gs(i.shape,u,o,1,r,c,!1,d),{strideHeight:p,strideWidth:m,filterHeight:f,filterWidth:g}=h,w=h.dataFormat==="channelsLast",b=new Zt(h.filterShape,"float32"),k=h.padInfo.left,y=h.padInfo.top,I=e.data.get(i.dataId).values,S=e.data.get(a.dataId).values,v=new Zt(i.shape,i.dtype,I),N=new Zt(a.shape,a.dtype,S);for(let C=0;C<f;++C){const D=Math.max(0,Math.ceil((y-C)/p)),E=Math.min(h.outHeight,(h.inHeight+y-C)/p);for(let V=0;V<g;++V){const M=Math.max(0,Math.ceil((k-V)/m)),L=Math.min(h.outWidth,(h.inWidth+k-V)/m);for(let F=0;F<h.inChannels;++F)for(let $=0;$<h.outChannels;++$){let W=0;for(let R=0;R<h.batchSize;++R)for(let _=D;_<E;++_){const G=C+_*p-y;for(let P=M;P<L;++P){const U=V+P*m-k;w?W+=v.get(R,G,U,F)*N.get(R,_,P,$):W+=v.get(R,F,G,U)*N.get(R,$,_,P)}}b.set(W,C,V,F,$)}}}return e.makeTensorInfo(b.shape,b.dtype,b.values)}const I1={kernelName:Dp,backendName:"cpu",kernelFunc:k1};function x1(s){const{inputs:t,backend:e,attrs:n}=s,{dy:i,filter:a}=t,{inputShape:o,strides:r,pad:l,dataFormat:c,dimRoundingMode:u}=n;Q([i,a],"conv2dBackpropInput");const d=ct(a.shape),h=ct(i.shape);let p=Ua(c);const m=Gs(o,a.shape,r,1,l,u,!1,p),f=new Zt(m.inShape,"float32"),g=f.values,w=e.data.get(i.dataId).values,b=e.data.get(a.dataId).values,[k,y,I]=d,{batchSize:S,filterHeight:v,filterWidth:N,inChannels:C,inHeight:D,inWidth:E,outChannels:V,outHeight:M,outWidth:L,strideHeight:F,strideWidth:$}=m;p=m.dataFormat;const W=v-1-m.padInfo.top,R=N-1-m.padInfo.left,_=p==="channelsLast",G=f.strides[0],P=_?f.strides[1]:f.strides[2],U=_?f.strides[2]:1,H=_?1:f.strides[1],q=h[0],j=_?h[1]:h[2],Z=_?h[2]:1,Y=_?1:h[1];for(let et=0;et<S;++et)for(let tt=0;tt<C;++tt)for(let at=0;at<D;++at){const ot=at-W,ft=Math.max(0,Math.ceil(ot/F)),kt=Math.min(M,(v+ot)/F);for(let At=0;At<E;++At){const It=At-R,bt=Math.max(0,Math.ceil(It/$)),Ct=Math.min(L,(N+It)/$);let St=0;for(let Vt=ft;Vt<kt;++Vt){const He=Vt*F-ot;for(let Xt=bt;Xt<Ct;++Xt){const ls=Xt*$-It,ue=q*et+j*Vt+Z*Xt,Re=k*(v-1-He)+y*(N-1-ls)+I*tt;for(let Ue=0;Ue<V;++Ue){const je=w[ue+Y*Ue],qe=b[Re+Ue];St+=je*qe}}}const Me=G*et+P*at+U*At+H*tt;g[Me]=St}}return e.makeTensorInfo(f.shape,f.dtype,f.values)}const S1={kernelName:ec,backendName:"cpu",kernelFunc:x1};function v1(s){const{inputs:t,backend:e,attrs:n}=s,{x:i,filter:a}=t,{strides:o,pad:r,dilations:l}=n;Q([i,a],"conv3d");const c=ja(i.shape,a.shape,o,l,r),{filterDepth:u,filterHeight:d,filterWidth:h,dilationDepth:p,dilationHeight:m,dilationWidth:f,padInfo:g}=c,w=g.front,b=g.left,k=g.top,y=new Zt(c.outShape,i.dtype),I=e.data.get(i.dataId).values,S=e.data.get(a.dataId).values,v=y.values,N=ct(i.shape),C=ct(a.shape);for(let D=0;D<c.batchSize;++D){const E=D*N[0],V=D*y.strides[0];for(let M=0;M<c.outDepth;++M){const L=V+M*y.strides[1],F=M*c.strideDepth-w;for(let $=0;$<u;++$){const W=F+$*p;if(W<0||W>=c.inDepth)continue;const R=$*C[0],_=E+W*N[1];for(let G=0;G<c.outHeight;++G){const P=L+G*y.strides[2],U=G*c.strideHeight-k;for(let H=0;H<d;++H){const q=U+H*m;if(q<0||q>=c.inHeight)continue;const j=R+H*C[1],Z=_+q*N[2];for(let Y=0;Y<c.outWidth;++Y){const et=P+Y*c.outChannels,tt=Y*c.strideWidth-b;for(let at=0;at<h;++at){const ot=tt+at*f;if(ot<0||ot>=c.inWidth)continue;const ft=j+at*C[2],kt=Z+ot*c.inChannels;let At=ft;for(let It=0;It<c.inChannels;++It){const bt=I[kt+It];for(let Ct=0;Ct<c.outChannels;++Ct)v[et+Ct]+=bt*S[At+Ct];At+=c.outChannels}}}}}}}}return e.makeTensorInfo(y.shape,y.dtype,y.values)}const N1={kernelName:nc,backendName:"cpu",kernelFunc:v1};function C1(s){const{inputs:t,backend:e,attrs:n}=s,{x:i,dy:a}=t,{strides:o,pad:r,filterShape:l}=n;Q([i,a],"conv3dBackpropFilterV2");const c=ct(i.shape),u=ct(a.shape),d=ja(i.shape,l,o,1,r),h=d.strideDepth,p=d.strideHeight,m=d.strideWidth,f=d.filterDepth,g=d.filterHeight,w=d.filterWidth,b=new Zt(d.filterShape,"float32"),k=b.values,[y,I,S,v]=b.strides,N=e.data.get(a.dataId).values,[C,D,E,V]=u,M=e.data.get(i.dataId).values,[L,F,$,W]=c,R=d.padInfo.front,_=d.padInfo.left,G=d.padInfo.top;for(let P=0;P<f;++P){const U=Math.max(0,Math.ceil((R-P)/h)),H=Math.min(d.outDepth,(d.inDepth+R-P)/h),q=P*y;for(let j=0;j<g;++j){const Z=Math.max(0,Math.ceil((G-j)/p)),Y=Math.min(d.outHeight,(d.inHeight+G-j)/p),et=j*I+q;for(let tt=0;tt<w;++tt){const at=Math.max(0,Math.ceil((_-tt)/m)),ot=Math.min(d.outWidth,(d.inWidth+_-tt)/m),ft=tt*S+et;for(let kt=0;kt<d.inChannels;++kt){const At=kt*v+ft;for(let It=0;It<d.outChannels;++It){let bt=0;for(let Ct=0;Ct<d.batchSize;++Ct){const St=Ct*L,Me=Ct*C;for(let Vt=U;Vt<H;++Vt){const Xt=(P+Vt*h-R)*F+St,ls=Vt*D+Me;for(let ue=Z;ue<Y;++ue){const Ue=(j+ue*p-G)*$+Xt,je=ue*E+ls;for(let qe=at;qe<ot;++qe){const _i=(tt+qe*m-_)*W+Ue,Wi=qe*V+je;bt+=M[_i+kt]*N[Wi+It]}}}}k[At+It]=bt}}}}}return e.makeTensorInfo(b.shape,b.dtype,b.values)}const T1={kernelName:sc,backendName:"cpu",kernelFunc:C1};function A1(s){const{inputs:t,backend:e,attrs:n}=s,{dy:i,filter:a}=t,{pad:o,strides:r,inputShape:l}=n;Q([i],"conv3dBackpropInputV2");const c=ct(i.shape),u=ct(a.shape),d=ja(l,a.shape,r,1,o),h=new Zt(d.inShape,"float32"),p=h.values,[m,f,g,w]=h.strides,b=e.data.get(i.dataId).values,[k,y,I,S]=c,v=e.data.get(a.dataId).values,[N,C,D,E]=u,{batchSize:V,filterDepth:M,filterHeight:L,filterWidth:F,inChannels:$,inDepth:W,inHeight:R,inWidth:_,outChannels:G,outDepth:P,outHeight:U,outWidth:H,strideDepth:q,strideHeight:j,strideWidth:Z}=d,Y=M-1-d.padInfo.front,et=L-1-d.padInfo.top,tt=F-1-d.padInfo.left;for(let at=0;at<V;++at)for(let ot=0;ot<$;++ot)for(let ft=0;ft<W;++ft){const kt=ft-Y,At=Math.max(0,Math.ceil(kt/q)),It=Math.min(P,(M+kt)/q);for(let bt=0;bt<R;++bt){const Ct=bt-et,St=Math.max(0,Math.ceil(Ct/j)),Me=Math.min(U,(L+Ct)/j);for(let Vt=0;Vt<_;++Vt){const He=Vt-tt,Xt=Math.max(0,Math.ceil(He/Z)),ls=Math.min(H,(F+He)/Z);let ue=0;for(let Re=At;Re<It;++Re){const Ue=Re*q-kt;for(let je=St;je<Me;++je){const qe=je*j-Ct;for(let Qs=Xt;Qs<ls;++Qs){const _i=Qs*Z-He,Wi=k*at+y*Re+I*je+S*Qs,Id=N*(M-1-Ue)+C*(L-1-qe)+D*(F-1-_i)+E*ot;for(let Mn=0;Mn<G;++Mn){const xd=b[Wi+Mn],Sd=v[Id+Mn];ue+=xd*Sd}}}}p[m*at+f*ft+g*bt+w*Vt+ot]=ue}}}return e.makeTensorInfo(h.shape,h.dtype,h.values)}const D1={kernelName:zp,backendName:"cpu",kernelFunc:A1};const z1=wt(wa,s=>Math.cos(s)),F1={kernelName:wa,backendName:"cpu",kernelFunc:z1};const $1=wt(ka,s=>Math.cosh(s)),M1={kernelName:ka,backendName:"cpu",kernelFunc:$1};function R1(s){const{inputs:t,backend:e,attrs:n}=s,{image:i,boxes:a,boxInd:o}=t,{cropSize:r,method:l,extrapolationValue:c}=n,[u,d,h,p]=i.shape,m=a.shape[0],[f,g]=r,w=Bt([m,f,g,p],"float32"),b=e.data.get(a.dataId).values,k=e.data.get(o.dataId).values,y=e.data.get(i.dataId).values,I=ct(i.shape),S=ct(w.shape);for(let v=0;v<m;v++){const N=v*4,C=b[N],D=b[N+1],E=b[N+2],V=b[N+3],M=k[v];if(M>=u)continue;const L=f>1?(E-C)*(d-1)/(f-1):0,F=g>1?(V-D)*(h-1)/(g-1):0;for(let $=0;$<f;$++){const W=f>1?C*(d-1)+$*L:.5*(C+E)*(d-1);if(W<0||W>d-1){for(let R=0;R<g;R++)for(let _=0;_<p;_++){const G=_+R*S[2]+$*S[1]+v*S[0];w.values[G]=c}continue}if(l==="bilinear"){const R=Math.floor(W),_=Math.ceil(W),G=W-R;for(let P=0;P<g;P++){const U=g>1?D*(h-1)+P*F:.5*(D+V)*(h-1);if(U<0||U>h-1){for(let Z=0;Z<p;Z++){const Y=Z+P*S[2]+$*S[1]+v*S[0];w.values[Y]=c}continue}const H=Math.floor(U),q=Math.ceil(U),j=U-H;for(let Z=0;Z<p;Z++){let Y=Z+H*I[2]+R*I[1]+M*I[0];const et=y[Y];Y=Z+q*I[2]+R*I[1]+M*I[0];const tt=y[Y];Y=Z+H*I[2]+_*I[1]+M*I[0];const at=y[Y];Y=Z+q*I[2]+_*I[1]+M*I[0];const ot=y[Y],ft=et+(tt-et)*j,kt=at+(ot-at)*j;Y=Z+P*S[2]+$*S[1]+v*S[0],w.values[Y]=ft+(kt-ft)*G}}}else for(let R=0;R<g;++R){const _=g>1?D*(h-1)+R*F:.5*(D+V)*(h-1);if(_<0||_>h-1){for(let U=0;U<p;U++){const H=U+R*S[2]+$*S[1]+v*S[0];w.values[H]=c}continue}const G=Math.round(_),P=Math.round(W);for(let U=0;U<p;U++){const H=U+G*I[2]+P*I[1]+M*I[0],q=U+R*S[2]+$*S[1]+v*S[0];w.values[q]=y[H]}}}}return e.makeTensorInfo(w.shape,w.dtype,w.values)}const E1={kernelName:Fp,backendName:"cpu",kernelFunc:R1};function L1(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{axis:a,exclusive:o,reverse:r}=n;Q(i,"cumprod");const l=we([a],i.shape.length);let c=i;l!=null&&(c=ee({inputs:{x:i},backend:e,attrs:{perm:l}}));const u=Ge(1,i.shape.length)[0];if(u!==c.shape.length-1)throw new Error(`backend.cumprod in CPU expects an inner-most axis=${c.shape.length-1} but got axis=${u}`);const d=ui(c.dtype,"int32"),h=Mp(st(c.shape),d),p=e.data.get(c.dataId).values,m=c.shape[c.shape.length-1],f=r?(w,b)=>w+m-b-1:(w,b)=>w+b;for(let w=0;w<p.length;w+=m)for(let b=0;b<m;b++){const k=f(w,b);if(b===0)h[k]=o?1:p[k];else{const y=f(w,b-1);h[k]=o?p[y]*h[y]:p[k]*h[y]}}const g=e.makeTensorInfo(c.shape,d,h);if(l!=null){const w=yn(l),b=ee({inputs:{x:g},backend:e,attrs:{perm:w}});return e.disposeIntermediateTensorInfo(g),e.disposeIntermediateTensorInfo(c),b}return g}const O1={kernelName:$p,backendName:"cpu",kernelFunc:L1};function _1(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{axis:a,exclusive:o,reverse:r}=n;Q(i,"cumsum");const l=we([a],i.shape.length);let c=i;l!=null&&(c=ee({inputs:{x:i},backend:e,attrs:{perm:l}}));const u=Ge(1,i.shape.length)[0];if(u!==c.shape.length-1)throw new Error(`backend.cumsum in CPU expects an inner-most axis=${c.shape.length-1} but got axis=${u}`);const d=ui(c.dtype,"int32"),h=rs(st(c.shape),d),p=e.data.get(c.dataId).values,m=c.shape[c.shape.length-1],f=r?(w,b)=>w+m-b-1:(w,b)=>w+b;for(let w=0;w<p.length;w+=m)for(let b=0;b<m;b++){const k=f(w,b);if(b===0)h[k]=o?0:p[k];else{const y=f(w,b-1);h[k]=o?p[y]+h[y]:p[k]+h[y]}}const g=e.makeTensorInfo(c.shape,d,h);if(l!=null){const w=yn(l),b=ee({inputs:{x:g},backend:e,attrs:{perm:w}});return e.disposeIntermediateTensorInfo(g),e.disposeIntermediateTensorInfo(c),b}return g}const W1={kernelName:ic,backendName:"cpu",kernelFunc:_1};function V1(s){const{inputs:t,backend:e,attrs:n}=s,{x:i,weights:a}=t,{size:o,binaryOutput:r}=n;if(i.shape.length===1){const l=e.data.get(i.dataId).values,c=e.data.get(a.dataId).values,u=Du(l,c,a.dtype,a.shape,o);return e.makeTensorInfo([o],a.dtype,u)}else if(i.shape.length===2){const l=e.bufferSync(i),c=e.bufferSync(a),u=Hm(l,c,o,r);return e.makeTensorInfo(u.shape,a.dtype,u.values)}throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${i.shape.length}.`)}const B1={kernelName:Rp,backendName:"cpu",kernelFunc:V1};function P1(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{blockSize:a,dataFormat:o}=n;K(o==="NHWC",()=>`Only NHWC dataFormat supported on CPU for depthToSpace. Got ${o}`);const r=i.shape[0],l=i.shape[1],c=i.shape[2],u=i.shape[3],d=l*a,h=c*a,p=u/(a*a),m=e.data.get(i.dataId).values,f=new Float32Array(r*d*h*p);let g=0;for(let w=0;w<r;++w)for(let b=0;b<d;++b){const k=Math.floor(b/a),y=b%a;for(let I=0;I<h;++I){const S=Math.floor(I/a),v=I%a,N=(y*a+v)*p;for(let C=0;C<p;++C){const E=C+N+u*(S+c*(k+l*w));f[g++]=m[E]}}}return e.makeTensorInfo([r,d,h,p],i.dtype,f)}const G1={kernelName:Ep,backendName:"cpu",kernelFunc:P1};function fd(s){const{inputs:t,backend:e,attrs:n}=s,{x:i,filter:a}=t,{strides:o,pad:r,dilations:l,dimRoundingMode:c}=n;Q([i,a],"depthwiseConv2DNative");const u=ct(i.shape),d=ct(a.shape);let h=l;h==null&&(h=[1,1]),K(oi(o,h),()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${o} and dilations '${h}'`);const p=Gs(i.shape,a.shape,o,h,r,c,!0),{filterHeight:m,filterWidth:f,dilationHeight:g,dilationWidth:w,padInfo:b}=p,k=b.left,y=b.top,I=p.outChannels/p.inChannels,S=new Zt(p.outShape,i.dtype),v=e.data.get(i.dataId).values,N=e.data.get(a.dataId).values,C=S.values;for(let D=0;D<p.batchSize;++D){const E=D*u[0],V=D*S.strides[0];for(let M=0;M<p.outHeight;++M){const L=V+M*S.strides[1],F=M*p.strideHeight-y;for(let $=0;$<m;++$){const W=F+$*g;if(W<0||W>=p.inHeight)continue;const R=$*d[0],_=E+W*u[1];for(let G=0;G<p.outWidth;++G){const P=L+G*S.strides[2],U=G*p.strideWidth-k;for(let H=0;H<f;++H){const q=U+H*w;if(q<0||q>=p.inWidth)continue;const j=R+H*d[1],Z=_+q*p.inChannels;let Y=P,et=j;for(let tt=0;tt<p.inChannels;++tt){const at=v[Z+tt];for(let ot=0;ot<I;++ot)C[Y+ot]+=at*N[et+ot];Y+=I,et+=I}}}}}}return e.makeTensorInfo(S.shape,S.dtype,S.values)}const H1={kernelName:ac,backendName:"cpu",kernelFunc:fd};function U1(s){const{inputs:t,backend:e,attrs:n}=s,{x:i,dy:a}=t,{strides:o,dilations:r,pad:l,dimRoundingMode:c,filterShape:u}=n;Q([i,a],"depthwiseConv2dNativeBackpropFilter");const d=Gs(i.shape,u,o,r,l,c,!0),{strideHeight:h,strideWidth:p,filterHeight:m,filterWidth:f}=d,g=new Zt(d.filterShape,"float32"),w=d.padInfo.left,b=d.padInfo.top,k=d.outChannels/d.inChannels,y=e.data.get(i.dataId).values,I=new Zt(i.shape,i.dtype,y),S=e.data.get(a.dataId).values,v=new Zt(a.shape,a.dtype,S);for(let N=0;N<m;++N){const C=Math.max(0,Math.ceil((b-N)/h)),D=Math.min(d.outHeight,(d.inHeight+b-N)/h);for(let E=0;E<f;++E){const V=Math.max(0,Math.ceil((w-E)/p)),M=Math.min(d.outWidth,(d.inWidth+w-E)/p);for(let L=0;L<d.outChannels;++L){const F=Math.trunc(L/k),$=L%k;let W=0;for(let R=0;R<d.batchSize;++R)for(let _=C;_<D;++_){const G=N+_*h-b;for(let P=V;P<M;++P){const U=E+P*p-w;W+=I.get(R,G,U,F)*v.get(R,_,P,L)}}g.set(W,N,E,F,$)}}}return e.makeTensorInfo(g.shape,g.dtype,g.values)}const j1={kernelName:Lp,backendName:"cpu",kernelFunc:U1};function q1(s){const{inputs:t,backend:e,attrs:n}=s,{dy:i,filter:a}=t,{strides:o,dilations:r,pad:l,dimRoundingMode:c,inputShape:u}=n;Q([i,a],"depthwiseConv2DNativeBackpropInput");const d=ct(i.shape),h=ct(a.shape),p=Gs(u,a.shape,o,r,l,c,!0),m=new Zt(p.inShape,"float32"),f=m.values,[g,w,b]=m.strides,k=e.data.get(i.dataId).values,[y,I,S]=d,v=e.data.get(a.dataId).values,[N,C,D]=h,{batchSize:E,filterHeight:V,filterWidth:M,inChannels:L,inHeight:F,inWidth:$,outChannels:W,outHeight:R,outWidth:_,strideHeight:G,strideWidth:P}=p,U=V-1-p.padInfo.top,H=M-1-p.padInfo.left,q=W/L;for(let j=0;j<E;++j)for(let Z=0;Z<L;++Z)for(let Y=0;Y<F;++Y){const et=Y-U,tt=Math.max(0,Math.ceil(et/G)),at=Math.min(R,(V+et)/G);for(let ot=0;ot<$;++ot){const ft=ot-H,kt=Math.max(0,Math.ceil(ft/P)),At=Math.min(_,(M+ft)/P);let It=0;for(let bt=tt;bt<at;++bt){const Ct=bt*G-et;for(let St=kt;St<At;++St){const Me=St*P-ft,Vt=y*j+I*bt+S*St,He=N*(V-1-Ct)+C*(M-1-Me)+D*Z;for(let Xt=0;Xt<q;++Xt){const ls=Z*q+Xt,ue=k[Vt+ls],Re=v[He+Xt];It+=ue*Re}}}f[g*j+w*Y+b*ot+Z]=It}}return e.makeTensorInfo(m.shape,m.dtype,m.values)}const K1={kernelName:Op,backendName:"cpu",kernelFunc:q1};function Z1(s){const{inputs:t,backend:e}=s,{x:n}=t,i=st(n.shape),a=e.data.get(n.dataId).values,o=Bt([i,i],n.dtype),r=o.values;for(let c=0;c<a.length;c++)r[c*i+c]=a[c];const l=[...n.shape,...n.shape];return e.makeTensorInfo(l,o.dtype,o.values)}const J1={kernelName:_p,backendName:"cpu",kernelFunc:Z1};const X1={kernelName:oc,backendName:"cpu",kernelFunc:({inputs:s,backend:t,attrs:e})=>{const{x:n,filter:i}=s,{strides:a,pad:o,dilations:r}=e,l=t,c=l.data.get(n.dataId).values,u=n.shape.length,d=l.data.get(i.dataId).values,h=i.shape.length,{batchSize:p,inHeight:m,inWidth:f,inChannels:g,outHeight:w,outWidth:b,padInfo:k,strideHeight:y,strideWidth:I,filterHeight:S,filterWidth:v,dilationHeight:N,dilationWidth:C,outShape:D}=qa(n.shape,i.shape,a,o,"NHWC",r),E=st(D),V=D.length,M=Ka(n.dtype,E);for(let F=0;F<p;++F)for(let $=0;$<w;++$){const W=$*y-k.top;for(let R=0;R<b;++R){const _=R*I-k.left;for(let G=0;G<g;++G){let P=Number.MIN_SAFE_INTEGER;for(let H=0;H<S;++H){const q=W+H*N;if(q>=0&&q<m)for(let j=0;j<v;++j){const Z=_+j*C;if(Z>=0&&Z<f){const Y=rn([F,q,Z,G],u,ct(n.shape)),et=rn([H,j,G],h,ct(i.shape)),tt=c[Y]+d[et];tt>P&&(P=tt)}}}const U=rn([F,$,R,G],V,ct(D));M[U]=P}}}return{dataId:l.write(Za(M,n.dtype),D,n.dtype),shape:D,dtype:n.dtype}}};const Y1={kernelName:Ki,backendName:"cpu",kernelFunc:({inputs:s,backend:t,attrs:e})=>{const{x:n,filter:i,dy:a}=s,{strides:o,pad:r,dilations:l}=e,c=t,u=zs(n.shape,c.data.get(n.dataId).values),d=zs(i.shape,c.data.get(i.dataId).values),{batchSize:h,inHeight:p,inWidth:m,inChannels:f,outHeight:g,outWidth:w,padInfo:b,strideHeight:k,strideWidth:y,filterHeight:I,filterWidth:S,dilationHeight:v,dilationWidth:N,outShape:C}=qa(n.shape,i.shape,o,r,"NHWC",l);K(a.rank===C.length,()=>`Error in ${Ki}, dy must have the same rank as output ${C.length}, but got ${a.rank}`);const D=zs(C,c.data.get(a.dataId).values),E=jc(i.shape,i.dtype);for(let M=0;M<h;++M)for(let L=0;L<g;++L){const F=L*k-b.top;for(let $=0;$<w;++$){const W=$*y-b.left;for(let R=0;R<f;++R){let _=Number.MIN_SAFE_INTEGER,G=0,P=0;for(let U=0;U<I;++U){const H=F+U*v;if(H>=0&&H<p)for(let q=0;q<S;++q){const j=W+q*N;if(j>=0&&j<m){const Z=u[M][H][j][R]+d[U][q][R];Z>_&&(_=Z,G=U,P=q)}}}E[G][P][R]+=D[M][L][$][R]}}}return{dataId:c.write(Za(E,n.dtype),i.shape,i.dtype),shape:i.shape,dtype:i.dtype}}};const Q1={kernelName:Zi,backendName:"cpu",kernelFunc:({inputs:s,backend:t,attrs:e})=>{const{x:n,filter:i,dy:a}=s,{strides:o,pad:r,dilations:l}=e,c=t,u=zs(n.shape,c.data.get(n.dataId).values),d=zs(i.shape,c.data.get(i.dataId).values),{batchSize:h,inHeight:p,inWidth:m,inChannels:f,outHeight:g,outWidth:w,padInfo:b,strideHeight:k,strideWidth:y,filterHeight:I,filterWidth:S,dilationHeight:v,dilationWidth:N,outShape:C}=qa(n.shape,i.shape,o,r,"NHWC",l);K(a.rank===C.length,()=>`Error in ${Zi}, dy must have the same rank as output ${C.length}, but got ${a.rank}`);const D=zs(C,c.data.get(a.dataId).values),E=jc(n.shape,n.dtype);for(let M=0;M<h;++M)for(let L=0;L<g;++L){const F=L*k-b.top;for(let $=0;$<w;++$){const W=$*y-b.left;for(let R=0;R<f;++R){let _=Number.MIN_SAFE_INTEGER,G=F<0?0:F,P=W<0?0:W;for(let U=0;U<I;++U){const H=F+U*v;if(H>=0&&H<p)for(let q=0;q<S;++q){const j=W+q*N;if(j>=0&&j<m){const Z=u[M][H][j][R]+d[U][q][R];Z>_&&(_=Z,G=H,P=j)}}}E[M][G][P][R]+=D[M][L][$][R]}}}return{dataId:c.write(Za(E,n.dtype),n.shape,n.dtype),shape:n.shape,dtype:n.dtype}}};function tv(s){const{inputs:t,backend:e,attrs:n}=s,{image:i}=t,{canvas:a,options:o}=n,{contextOptions:r,imageOptions:l}=o||{},c=l?.alpha||1,u=r?.contextType||"2d";if(u!=="2d")throw new Error(`Context type ${r.contextType} is not supported by the CPU backend.`);const d=a.getContext(u,r?.contextAttributes||{});if(d==null)throw new Error(`Could not get the context with ${u} type.`);const[h,p]=i.shape.slice(0,2),m=i.shape.length===2?1:i.shape[2],f=e.data.get(i.dataId).values,g=i.dtype==="float32"?255:1,w=new Uint8ClampedArray(p*h*4);for(let k=0;k<h*p;++k){const y=[0,0,0,255*c];for(let S=0;S<m;S++){const v=f[k*m+S];if(i.dtype==="float32"){if(v<0||v>1)throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${v}.`)}else if(i.dtype==="int32"&&(v<0||v>255))throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${v}.`);m===1?(y[0]=v*g,y[1]=v*g,y[2]=v*g):y[S]=v*g}const I=k*4;w[I+0]=Math.round(y[0]),w[I+1]=Math.round(y[1]),w[I+2]=Math.round(y[2]),w[I+3]=Math.round(y[3])}a.width=p,a.height=h;const b=new ImageData(w,p,h);return d.putImageData(b,0,0),i}const ev={kernelName:Wp,backendName:"cpu",kernelFunc:tv};function $n(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{axis:a,keepDims:o}=n;Q(i,"sum");let r;i.dtype==="bool"?r=ro({inputs:{x:i},backend:e,attrs:{dtype:"int32"}}):r=Ss({inputs:{x:i},backend:e});const l=r.shape.length,c=Lt(a,r.shape),u=we(c,l);let d=c,h=r;u!=null&&(h=ee({inputs:{x:r},backend:e,attrs:{perm:u}}),d=Ge(d.length,l)),ys("sum",d,h.shape.length);const[p,m]=Pe(h.shape,d),f=ui(h.dtype,"int32");let g=Um(e,p,f);const w=st(m),b=e.data.get(g.dataId).values,k=e.data.get(h.dataId).values;for(let y=0;y<b.length;++y){const I=y*w;let S=0;for(let v=0;v<w;++v)S+=k[I+v];b[y]=S}if(o){const y=ts(g.shape,c),I=g;g=xt({inputs:{x:g},backend:e,attrs:{shape:y}}),e.disposeIntermediateTensorInfo(I)}return e.disposeIntermediateTensorInfo(r),u!=null&&e.disposeIntermediateTensorInfo(h),g}const sv={kernelName:_c,backendName:"cpu",kernelFunc:$n};function nv(s){const{inputs:t,backend:e,attrs:n}=s,{equation:i}=n,a=t,{allDims:o,summedDims:r,idDims:l}=jm(i,a.length);qm(o.length,l,a);const{path:c,steps:u}=Km(r,l),d=u.length;let h=null,p=o.length;const m=[];for(let f=0;f<d;++f){for(const g of u[f]){const{permutationIndices:w,expandDims:b}=Zm(p,l[g]);let k;Jm(w)?k=a[g]:(k=ee({inputs:{x:a[g]},backend:e,attrs:{perm:w}}),m.push(k));const y=k.shape.slice();for(let I=0;I<b.length;++I)y.splice(b[I],0,1);Jt(k.shape,y)||(k=xt({inputs:{x:k},backend:e,attrs:{shape:y}}),m.push(k)),h===null?h=k:(h=lo({inputs:{a:k,b:h},backend:e}),m.push(h))}f<d-1&&(c[f]>=0&&(h=$n({inputs:{x:h},backend:e,attrs:{axis:c[f]-(o.length-p),keepDims:!1}}),m.push(h)),p--)}for(const f of m)f!==h&&e.disposeIntermediateTensorInfo(f);return h}const iv={kernelName:Vp,backendName:"cpu",kernelFunc:nv};function av(s){const{inputs:t,backend:e}=s,{dy:n,y:i}=t;Q([n,i],"eluGrad");const a=new Float32Array(st(i.shape)),o=e.data.get(i.dataId).values,r=e.data.get(n.dataId).values;for(let l=0;l<o.length;++l){const c=o[l];c>=0?a[l]=r[l]:a[l]=r[l]*(c+1)}return e.makeTensorInfo(i.shape,"float32",a)}const ov={kernelName:rc,backendName:"cpu",kernelFunc:av};const rv=sg,lv=eg,cv=tg,uv=Qm,hv=Ym,dv=Xm,pv=wt(xa,s=>{const t=Math.sign(s),e=Math.abs(s),n=1/(1+rv*e);return t*(1-((((dv*n+hv)*n+uv)*n+cv)*n+lv)*n*Math.exp(-e*e))}),fv={kernelName:xa,backendName:"cpu",kernelFunc:pv};function si(s){const{inputs:t,backend:e,attrs:n}=s,{input:i}=t,{dim:a}=n,o=i.shape.length,r=i.shape.slice();let l=a;return a<0&&(K(-(o+1)<=a,()=>`Axis must be in the interval [${-(o+1)}, ${o}]`),l=o+a+1),r.splice(l,0,1),xt({inputs:{x:i},backend:e,attrs:{shape:r}})}const mv={kernelName:lc,backendName:"cpu",kernelFunc:si};const gv=xs((s,t)=>s/t),qr=js(Da,gv),la={kernelName:Da,backendName:"cpu",kernelFunc:qr};function md(s,t,e){const n=s.shape,i=n[0],a=n[1],o=e.data.get(s.dataId),r=o.complexTensorInfos.real,l=o.complexTensorInfos.imag,c=[i,a],u=st(c),d=es("float32",u),h=es("float32",u);for(let g=0;g<i;g++){const w=Es({inputs:{x:r},backend:e,attrs:{begin:[g,0],size:[1,a]}}),b=Es({inputs:{x:l},backend:e,attrs:{begin:[g,0],size:[1,a]}}),k=Ne({inputs:{real:w,imag:b},backend:e}),{real:y,imag:I}=bv(k,t,e),S=gi(y,I);for(let v=0;v<a;v++){const N=zu(S,v);d[g*a+v]=N.real,h[g*a+v]=N.imag}e.disposeIntermediateTensorInfo(w),e.disposeIntermediateTensorInfo(b),e.disposeIntermediateTensorInfo(k)}const p=e.makeTensorInfo(c,"float32",d),m=e.makeTensorInfo(c,"float32",h),f=Ne({inputs:{real:p,imag:m},backend:e});return e.disposeIntermediateTensorInfo(p),e.disposeIntermediateTensorInfo(m),f}function bv(s,t,e){const n=st(s.shape),i=e.data.get(s.dataId),a=e.data.get(i.complexTensorInfos.real.dataId).values,o=e.data.get(i.complexTensorInfos.imag.dataId).values;if(yv(n)){const r=ca(a,o,n,t,e),l=[s.shape[0],s.shape[1]];if(t){const c=e.makeTensorInfo(l,"float32",r.real),u=e.makeTensorInfo(l,"float32",r.imag),d=e.makeTensorInfo([],"float32",qc(n,"float32")),h=Ss({inputs:{x:d},backend:e}),p=la.kernelFunc({inputs:{a:c,b:d},backend:e}),m=la.kernelFunc({inputs:{a:u,b:h},backend:e}),f=e.data.get(p.dataId).values,g=e.data.get(m.dataId).values;return e.disposeIntermediateTensorInfo(c),e.disposeIntermediateTensorInfo(u),e.disposeIntermediateTensorInfo(d),e.disposeIntermediateTensorInfo(h),e.disposeIntermediateTensorInfo(p),e.disposeIntermediateTensorInfo(m),{real:f,imag:g}}return r}else{const r=gi(a,o),l=wv(r,n,t);return ng(l)}}function yv(s){return(s&s-1)===0}function ca(s,t,e,n,i){if(e===1)return{real:s,imag:t};const a=gi(s,t),o=e/2,r=ig(a),l=r.real,c=r.imag,u=[l.length],d=i.makeTensorInfo(u,"float32",l),h=i.makeTensorInfo(u,"float32",c),p=Ne({inputs:{real:d,imag:h},backend:i}),m=ag(a),f=m.real,g=m.imag,w=[f.length],b=i.makeTensorInfo(w,"float32",f),k=i.makeTensorInfo(w,"float32",g),y=Ne({inputs:{real:b,imag:k},backend:i}),I=ca(l,c,o,n,i),S=I.real,v=I.imag,N=[S.length],C=i.makeTensorInfo(N,"float32",S),D=i.makeTensorInfo(N,"float32",v),E=Ne({inputs:{real:C,imag:D},backend:i}),V=ca(f,g,o,n,i),M=V.real,L=V.imag,F=[M.length],$=i.makeTensorInfo(F,"float32",M),W=i.makeTensorInfo(F,"float32",L),R=Ne({inputs:{real:$,imag:W},backend:i}),_=og(e,n),G=[_.real.length],P=i.makeTensorInfo(G,"float32",_.real),U=i.makeTensorInfo(G,"float32",_.imag),H=Ne({inputs:{real:P,imag:U},backend:i}),q=lo({inputs:{a:H,b:R},backend:i}),j=pn({inputs:{a:E,b:q},backend:i}),Z=Fu({inputs:{a:E,b:q},backend:i}),Y=fn({inputs:{input:j},backend:i}),et=fn({inputs:{input:Z},backend:i}),tt=Vs({inputs:{input:j},backend:i}),at=Vs({inputs:{input:Z},backend:i}),ot=Bs({inputs:[Y,et],backend:i,attrs:{axis:0}}),ft=Bs({inputs:[tt,at],backend:i,attrs:{axis:0}}),kt=i.data.get(ot.dataId).values,At=i.data.get(ft.dataId).values;return i.disposeIntermediateTensorInfo(d),i.disposeIntermediateTensorInfo(h),i.disposeIntermediateTensorInfo(p),i.disposeIntermediateTensorInfo(b),i.disposeIntermediateTensorInfo(k),i.disposeIntermediateTensorInfo(y),i.disposeIntermediateTensorInfo(C),i.disposeIntermediateTensorInfo(D),i.disposeIntermediateTensorInfo(E),i.disposeIntermediateTensorInfo($),i.disposeIntermediateTensorInfo(W),i.disposeIntermediateTensorInfo(R),i.disposeIntermediateTensorInfo(P),i.disposeIntermediateTensorInfo(U),i.disposeIntermediateTensorInfo(H),i.disposeIntermediateTensorInfo(q),i.disposeIntermediateTensorInfo(j),i.disposeIntermediateTensorInfo(Z),i.disposeIntermediateTensorInfo(Y),i.disposeIntermediateTensorInfo(tt),i.disposeIntermediateTensorInfo(et),i.disposeIntermediateTensorInfo(at),i.disposeIntermediateTensorInfo(ot),i.disposeIntermediateTensorInfo(ft),{real:kt,imag:At}}function wv(s,t,e){const n=new Float32Array(t*2);for(let i=0;i<t;i++){let a=0,o=0;for(let r=0;r<t;r++){const l=rg(i*r,t,e),c=zu(s,r);a+=c.real*l.real-c.imag*l.imag,o+=c.real*l.imag+c.imag*l.real}e&&(a/=t,o/=t),lg(n,a,o,i)}return n}function kv(s){const{inputs:t,backend:e}=s,{input:n}=t,i=st(n.shape),a=n.shape[n.shape.length-1],o=i/a,r=xt({inputs:{x:n},backend:e,attrs:{shape:[o,a]}}),l=md(r,!1,e),c=xt({inputs:{x:l},backend:e,attrs:{shape:n.shape}});return e.disposeIntermediateTensorInfo(r),e.disposeIntermediateTensorInfo(l),c}const Iv={kernelName:Bp,backendName:"cpu",kernelFunc:kv};function Kr(s){const{backend:t,attrs:e}=s,{shape:n,value:i,dtype:a}=e,o=a||Gp(i),r=Ka(o,st(n));return Sv(r,i,o),t.makeTensorInfo(n,o,r)}const xv={kernelName:Pp,backendName:"cpu",kernelFunc:Kr};function Sv(s,t,e){s.fill(t)}const vv={kernelName:Hp,backendName:"cpu",kernelFunc:({inputs:s,attrs:t,backend:e})=>{const{image:n}=s,i=e,a=es(n.dtype,st(n.shape)),[o,r,l,c]=n.shape,u=i.data.get(n.dataId).values;for(let h=0;h<o;h++){const p=h*l*r*c;for(let m=0;m<r;m++){const f=m*(l*c);for(let g=0;g<l;g++){const w=g*c;for(let b=0;b<c;b++){const k=Math.round(l-g-1),y=p+f+w+b;let I=u[y];if(k>=0&&k<l){const S=k*c,v=p+f+S+b;I=u[v]}a[y]=I}}}}return{dataId:i.write(a,n.shape,n.dtype),shape:n.shape,dtype:n.dtype}}};function Nv(s){const{inputs:t,backend:e,attrs:n}=s,{x:i,filter:a,bias:o,preluActivationWeights:r}=t,{strides:l,pad:c,dataFormat:u,dilations:d,dimRoundingMode:h,activation:p,leakyreluAlpha:m}=n;let f=pd({inputs:{x:i,filter:a},backend:e,attrs:{strides:l,pad:c,dataFormat:u,dilations:d,dimRoundingMode:h}});if(o){const g=f;if(u==="NCHW"&&o.shape.length===1&&o.shape[0]!==1){const w=xt({inputs:{x:o},backend:e,attrs:{shape:[o.shape[0],1,1]}});f=pn({inputs:{a:f,b:w},backend:e}),e.disposeIntermediateTensorInfo(w)}else f=pn({inputs:{a:f,b:o},backend:e});e.disposeIntermediateTensorInfo(g)}if(p){const g=f;if(u==="NCHW"&&p==="prelu"&&r.shape.length===1&&r.shape[0]!==1){const w=xt({inputs:{x:r},backend:e,attrs:{shape:[r.shape[0],1,1]}});f=ei(e,f,p,w,m),e.disposeIntermediateTensorInfo(w)}else f=ei(e,f,p,r,m);e.disposeIntermediateTensorInfo(g)}return f}const Cv={kernelName:Up,backendName:"cpu",kernelFunc:Nv};function Tv(s){const{inputs:t,backend:e,attrs:n}=s,{x:i,filter:a,bias:o,preluActivationWeights:r}=t,{strides:l,pad:c,dataFormat:u,dilations:d,dimRoundingMode:h,activation:p,leakyreluAlpha:m}=n;let f=fd({inputs:{x:i,filter:a},backend:e,attrs:{strides:l,pad:c,dataFormat:u,dilations:d,dimRoundingMode:h}});if(o){const g=f;f=pn({inputs:{a:f,b:o},backend:e}),e.disposeIntermediateTensorInfo(g)}if(p){const g=f;f=ei(e,f,p,r,m),e.disposeIntermediateTensorInfo(g)}return f}const Av={kernelName:jp,backendName:"cpu",kernelFunc:Tv};function Dv(s){const{inputs:t,backend:e}=s,{params:n,indices:i}=t,a=st(n.shape),o=i.shape,r=o[o.length-1],[l,c,u,d]=cg(n,i);if(c===0)return e.makeTensorInfo(l,n.dtype,[]);const h=e.data.get(i.dataId).values,p=e.bufferSync(n),m=ug(h,p,n.dtype,c,r,u,d,n.shape,a);return e.makeTensorInfo(l,n.dtype,m.values)}const zv={kernelName:qp,backendName:"cpu",kernelFunc:Dv};function Fv(s){const{inputs:t,backend:e,attrs:n}=s,{x:i,indices:a}=t,{axis:o,batchDims:r}=n;Q([i,a],"gatherV2");const l=Lt(o,i.shape)[0],c=e.data.get(a.dataId).values,u=i.shape[l];for(let y=0;y<c.length;++y){const I=c[y];K(I<=u-1&&I>=0,()=>`GatherV2: the index value ${I} is not in [0, ${u-1}]`)}let d=r;r==null&&(d=0);const h=st(a.shape),p=hg(i,a,l,d),m=xt({inputs:{x:i},backend:e,attrs:{shape:[p.batchSize,p.outerSize,p.dimSize,p.sliceSize]}}),f=xt({inputs:{x:a},backend:e,attrs:{shape:[p.batchSize,h/p.batchSize]}}),g=[p.batchSize,p.outerSize,h/p.batchSize,p.sliceSize],w=e.bufferSync(f),b=e.bufferSync(m),k=dg(b,w,g);return e.disposeIntermediateTensorInfo(m),e.disposeIntermediateTensorInfo(f),e.makeTensorInfo(p.outputShape,k.dtype,k.values)}const $v={kernelName:uc,backendName:"cpu",kernelFunc:Fv};function Mv(s){const{inputs:t,backend:e}=s,{input:n}=t,i=st(n.shape),a=n.shape[n.shape.length-1],o=i/a,r=xt({inputs:{x:n},backend:e,attrs:{shape:[o,a]}}),l=md(r,!0,e),c=xt({inputs:{x:l},backend:e,attrs:{shape:n.shape}});return e.disposeIntermediateTensorInfo(r),e.disposeIntermediateTensorInfo(l),c}const Rv={kernelName:Kp,backendName:"cpu",kernelFunc:Mv};const Ev=wt(Sa,s=>Number.isFinite(s)?1:0,"bool"),Lv={kernelName:Sa,backendName:"cpu",kernelFunc:Ev};const Ov=wt(va,s=>Math.abs(s)===1/0?1:0,"bool"),_v={kernelName:va,backendName:"cpu",kernelFunc:Ov};const Wv=wt(Na,s=>Number.isNaN(s)?1:0,"bool"),Vv={kernelName:Na,backendName:"cpu",kernelFunc:Wv};function Bv(s){const{backend:t,attrs:e}=s,{start:n,stop:i,num:a}=e,o=pg(n,i,a);return t.makeTensorInfo([o.length],"float32",o)}const Pv={kernelName:Zp,backendName:"cpu",kernelFunc:Bv};const Gv=wt(Ca,s=>Math.log1p(s)),Hv={kernelName:Ca,backendName:"cpu",kernelFunc:Gv};const Uv=xs((s,t)=>s&&t),jv=js(Kc,Uv,null,"bool"),qv={kernelName:Kc,backendName:"cpu",kernelFunc:jv};const Kv=wt(Zc,s=>s?0:1,"bool"),Zv={kernelName:Zc,backendName:"cpu",kernelFunc:Kv};const Jv=xs((s,t)=>s||t),Xv=js(Jc,Jv,null,"bool"),Yv={kernelName:Jc,backendName:"cpu",kernelFunc:Xv};function Qv(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{depthRadius:a,bias:o,alpha:r,beta:l}=n;Q(i,"LRN");const c=i.shape[3],u=c-1,d=e.data.get(i.dataId).values,h=st(i.shape),p=new Float32Array(h);function m(f){const g=f%c;let w=f-g+Math.max(0,g-a);const b=f-g+Math.min(g+a,u);let k=0;for(;w<=b;w++){const y=d[w];k+=y*y}return k}for(let f=0;f<h;f++){const g=m(f),w=d[f]*Math.pow(o+r*g,-l);p[f]=w}return e.makeTensorInfo(i.shape,i.dtype,p)}const tN={kernelName:pc,backendName:"cpu",kernelFunc:Qv};function eN(s){const{inputs:t,backend:e,attrs:n}=s,{x:i,y:a,dy:o}=t,{depthRadius:r,bias:l,alpha:c,beta:u}=n;Q(o,"LRNGrad");const d=st(o.shape),h=o.shape[3],p=e.data.get(o.dataId).values,m=e.data.get(i.dataId).values,f=e.data.get(a.dataId).values,g=new Float32Array(d),w=d;for(let b=0;b<w;b++){const k=b%h,y=b-k+Math.max(0,k-r),I=b-k+Math.min(h,k+r+1);let S=0;for(let v=y;v<I;v++)S+=Math.pow(m[v],2);S=c*S+l;for(let v=y;v<I;v++){let N=-2*c*u*m[v]*f[b]/S;b===v&&(N+=Math.pow(S,-u)),N*=p[b],g[v]+=N}}return e.makeTensorInfo(o.shape,i.dtype,g)}const sN={kernelName:dc,backendName:"cpu",kernelFunc:eN};function gd(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{reductionIndices:a,keepDims:o}=n,r=e;let l=i.shape;const c=l.length,u=Lt(a,l);let d=u;const h=we(d,c);let p=r.data.get(i.dataId).values;if(h!=null){const y=new Array(c);for(let I=0;I<y.length;I++)y[I]=l[h[I]];p=fg(p,l,i.dtype,h,y),d=Ge(d.length,c),l=y}Q(i,"max"),ys("max",d,c);const[m,f]=Pe(l,d),g=st(f),w=mg(p,g,m,i.dtype),b=r.write(w,m,i.dtype);let k=m;return o&&(k=ts(m,u)),{dataId:b,shape:k,dtype:i.dtype}}const nN={kernelName:fc,backendName:"cpu",kernelFunc:gd};function iN(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t;Q(i,"maxPool");const{filterSize:a,strides:o,pad:r,dimRoundingMode:l}=n,c=1;K(oi(o,c),()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${o} and dilations '${c}'`);const u=In(i.shape,a,o,c,r,l);let d;if(u.filterWidth===1&&u.filterHeight===1&&Jt(u.inShape,u.outShape))d=Ss({inputs:{x:i},backend:e});else{const h=e.data.get(i.dataId).values,p=ct(i.shape),m=jr(h,i.shape,i.dtype,p,u,"max");d=e.makeTensorInfo(u.outShape,i.dtype,m.values)}return d}const aN={kernelName:yc,backendName:"cpu",kernelFunc:iN};function oN(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{filterSize:a,strides:o,pad:r,dimRoundingMode:l,dataFormat:c}=n;Q(i,"maxPool3d");const u=ci(i.shape,a,o,1,r,l,c),d=e.data.get(i.dataId).values,h=dd(d,i.shape,i.dtype,ct(i.shape),u,"max");return e.makeTensorInfo(h.shape,"float32",h.values)}const rN={kernelName:gc,backendName:"cpu",kernelFunc:oN};function lN(s){const{inputs:t,backend:e,attrs:n}=s,{dy:i,input:a}=t,{filterSize:o,strides:r,pad:l,dimRoundingMode:c}=n;Q([i,a],"maxPool3DGrad");const u=ci(a.shape,o,r,1,l,c),d=e.bufferSync(a),h=JS(d,u),p=u.strideDepth,m=u.strideHeight,f=u.strideWidth,g=u.dilationDepth,w=u.dilationHeight,b=u.dilationWidth,k=u.effectiveFilterDepth,y=u.effectiveFilterHeight,I=u.effectiveFilterWidth,S=k-1-u.padInfo.front,v=I-1-u.padInfo.left,N=y-1-u.padInfo.top,C=Bt(a.shape,"float32"),D=e.bufferSync(i);for(let E=0;E<u.batchSize;++E)for(let V=0;V<u.inChannels;++V)for(let M=0;M<u.inDepth;++M)for(let L=0;L<u.inHeight;++L)for(let F=0;F<u.inWidth;++F){const $=M-S,W=L-N,R=F-v;let _=0;for(let G=0;G<k;G+=g){const P=($+G)/p;if(!(P<0||P>=u.outDepth||Math.floor(P)!==P))for(let U=0;U<y;U+=w){const H=(W+U)/m;if(!(H<0||H>=u.outHeight||Math.floor(H)!==H))for(let q=0;q<I;q+=b){const j=(R+q)/f;if(j<0||j>=u.outWidth||Math.floor(j)!==j)continue;const Z=k*y*I-1-h.get(E,P,H,j,V),Y=G*y*I+U*I+q,et=Z===Y?1:0;if(et===0)continue;const tt=D.get(E,P,H,j,V);_+=tt*et}}}C.set(_,E,M,L,F,V)}return e.makeTensorInfo(C.shape,C.dtype,C.values)}const cN={kernelName:mc,backendName:"cpu",kernelFunc:lN};function uN(s){const{inputs:t,backend:e,attrs:n}=s,{dy:i,input:a,output:o}=t,r=a;Q([a,o],"maxPoolGrad");const{filterSize:l,strides:c,pad:u,dimRoundingMode:d}=n,h=In(r.shape,l,c,1,u,d),p=e.data.get(r.dataId).values,m=Bt(h.outShape,r.dtype,hd(p,r.shape,r.dtype,h).values),f=h.strideHeight,g=h.strideWidth,w=h.dilationHeight,b=h.dilationWidth,k=h.effectiveFilterHeight,y=h.effectiveFilterWidth,I=y-1-h.padInfo.left,S=k-1-h.padInfo.top,v=Bt(r.shape,"float32"),N=e.data.get(i.dataId).values,C=Bt(i.shape,"float32",N);for(let D=0;D<h.batchSize;++D)for(let E=0;E<h.inChannels;++E)for(let V=0;V<h.inHeight;++V)for(let M=0;M<h.inWidth;++M){const L=V-S,F=M-I;let $=0;for(let W=0;W<k;W+=w){const R=(L+W)/f;if(!(R<0||R>=h.outHeight||Math.floor(R)!==R))for(let _=0;_<y;_+=b){const G=(F+_)/g;if(G<0||G>=h.outWidth||Math.floor(G)!==G)continue;const P=k*y-1-m.get(D,R,G,E),U=W*y+_,H=P===U?1:0;if(H===0)continue;const q=C.get(D,R,G,E);$+=q*H}}v.set($,D,V,M,E)}return e.makeTensorInfo(v.shape,v.dtype,v.values)}const hN={kernelName:bc,backendName:"cpu",kernelFunc:uN};function dN(s,t,e,n,i){const a=ct(t),o=jr(s,t,e,a,i,"max"),r=hd(s,t,e,i,!0,n);return[o.values,r.values]}const pN={kernelName:Jp,backendName:"cpu",kernelFunc:({inputs:s,attrs:t,backend:e})=>{const{x:n}=s,{filterSize:i,strides:a,pad:o,includeBatchInIndex:r}=t,l=e;Q(n,"MaxPoolWithArgmax");const c=l.data.get(n.dataId).values,u=In(n.shape,i,a,[1,1],o),[d,h]=dN(c,n.shape,n.dtype,r,u),p=l.write(d,u.outShape,n.dtype),m=l.write(h,u.outShape,n.dtype);return[{dataId:p,shape:u.outShape,dtype:n.dtype},{dataId:m,shape:u.outShape,dtype:"int32"}]}};function fN(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{axis:a,keepDims:o}=n,r=Lt(a,i.shape),c=Pe(i.shape,r)[1],u=st(c),d=[],h=e.makeTensorInfo([],"float32",new Float32Array([u]));d.push(h);const p=ro({inputs:{x:i},backend:e,attrs:{dtype:"float32"}});d.push(p);const m=qr({inputs:{a:p,b:h},backend:e});d.push(m);const f=$n({inputs:{x:m},backend:e,attrs:{axis:a,keepDims:o}});return d.forEach(g=>e.disposeIntermediateTensorInfo(g)),f}const mN={kernelName:wc,backendName:"cpu",kernelFunc:fN};function gN(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{axis:a,keepDims:o}=n;Q(i,"min");const r=Lt(a,i.shape);let l=r;const c=we(l,i.shape.length);let u=i;c!=null&&(u=ee({inputs:{x:i},backend:e,attrs:{perm:c}}),l=Ge(l.length,i.shape.length)),ys("min",l,u.shape.length);const[d,h]=Pe(u.shape,l),p=st(h),m=rs(st(d),u.dtype),f=e.data.get(u.dataId).values;for(let w=0;w<m.length;++w){const b=w*p;let k=f[b];for(let y=0;y<p;++y){const I=f[b+y];(Number.isNaN(I)||I<k)&&(k=I)}m[w]=k}c!=null&&e.disposeIntermediateTensorInfo(u);const g=e.makeTensorInfo(d,u.dtype,m);if(o){const w=ts(d,r),b=xt({inputs:{x:g},backend:e,attrs:{shape:w}});return e.disposeIntermediateTensorInfo(g),b}return g}const bN={kernelName:kc,backendName:"cpu",kernelFunc:gN};function yN(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{paddings:a,mode:o}=n;Q(i,"mirrorPad");const r=a.map((k,y)=>k[0]+i.shape[y]+k[1]),l=a.map(k=>k[0]),c=a.map((k,y)=>k[0]+i.shape[y]),u=o==="reflect"?0:1,d=e.data.get(i.dataId).values,h=i.shape.length,p=ct(i.shape),m=st(r),f=r.length,g=ct(r),w=es(i.dtype,m);for(let k=0;k<m;k++){let y=Xc(k,f,g);for(let S=0;S<f;S++)y[S]<l[S]?y[S]=l[S]*2-y[S]-u:y[S]>=c[S]&&(y[S]=(c[S]-1)*2-y[S]+u);y=y.map((S,v)=>S-l[v]);const I=rn(y,h,p);w[k]=d[I]}return{dataId:e.write(w,r,i.dtype),shape:r,dtype:i.dtype}}const wN={kernelName:Ic,backendName:"cpu",kernelFunc:yN};const kN=xs(((s,t)=>{const e=s%t;return s<0&&t<0||s>=0&&t>=0?e:(e+t)%t})),IN=js(Ta,kN),xN={kernelName:Ta,backendName:"cpu",kernelFunc:IN};function bd(s){const{inputs:t,backend:e,attrs:n}=s,{logits:i}=t,{dim:a}=n,o=i.shape.length;let r=a;if(r===-1&&(r=o-1),r!==o-1)throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${o} and dim was ${r}`);const l=Lt([r],i.shape),c=gd({inputs:{x:i},backend:e,attrs:{reductionIndices:l,keepDims:!1}}),u=ts(c.shape,l),d=xt({inputs:{x:c},backend:e,attrs:{shape:u}}),h=Fu({inputs:{a:i,b:d},backend:e}),p=gg({inputs:{x:h},backend:e}),m=$n({inputs:{x:p},backend:e,attrs:{axis:l,keepDims:!1}}),f=xt({inputs:{x:m},backend:e,attrs:{shape:u}}),g=qr({inputs:{a:p,b:f},backend:e});return e.disposeIntermediateTensorInfo(c),e.disposeIntermediateTensorInfo(d),e.disposeIntermediateTensorInfo(h),e.disposeIntermediateTensorInfo(p),e.disposeIntermediateTensorInfo(m),e.disposeIntermediateTensorInfo(f),g}const SN={kernelName:Rc,backendName:"cpu",kernelFunc:bd};function vN(s){const{inputs:t,backend:e,attrs:n}=s,{logits:i}=t,{numSamples:a,seed:o,normalized:r}=n;Q(i,"multinomial");const l=r?i:bd({inputs:{logits:i},backend:e,attrs:{dim:-1}}),c=l.shape[0],u=l.shape[1],d=e.data.get(l.dataId).values,h=[c,a],p=rs(st(h),"int32");for(let m=0;m<c;++m){const f=m*u,g=new Float32Array(u-1);g[0]=d[f];for(let k=1;k<g.length;++k)g[k]=g[k-1]+d[f+k];const w=co.alea(o.toString()),b=m*a;for(let k=0;k<a;++k){const y=w();p[b+k]=g.length;for(let I=0;I<g.length;I++)if(y<g[I]){p[b+k]=I;break}}}return r||e.disposeIntermediateTensorInfo(l),e.makeTensorInfo(h,"int32",p)}const NN={kernelName:Xp,backendName:"cpu",kernelFunc:vN};const CN=Wl;function TN(s){const{inputs:t,backend:e,attrs:n}=s,{boxes:i,scores:a}=t,{maxOutputSize:o,iouThreshold:r,scoreThreshold:l}=n;Q(i,"NonMaxSuppression");const c=e.data.get(i.dataId).values,u=e.data.get(a.dataId).values,{selectedIndices:d}=CN(c,u,o,r,l);return e.makeTensorInfo([d.length],"int32",new Int32Array(d))}const AN={kernelName:Yp,backendName:"cpu",kernelFunc:TN};const DN=Vl;function zN(s){const{inputs:t,backend:e,attrs:n}=s,{boxes:i,scores:a}=t,{maxOutputSize:o,iouThreshold:r,scoreThreshold:l,padToMaxOutputSize:c}=n;Q(i,"NonMaxSuppressionPadded");const u=e.data.get(i.dataId).values,d=e.data.get(a.dataId).values,{selectedIndices:h,validOutputs:p}=DN(u,d,o,r,l,c);return[e.makeTensorInfo([h.length],"int32",new Int32Array(h)),e.makeTensorInfo([],"int32",new Int32Array([p]))]}const FN={kernelName:Qp,backendName:"cpu",kernelFunc:zN};const $N=Bl;function MN(s){const{inputs:t,backend:e,attrs:n}=s,{boxes:i,scores:a}=t,{maxOutputSize:o,iouThreshold:r,scoreThreshold:l,softNmsSigma:c}=n;Q(i,"NonMaxSuppressionWithScore");const u=e.data.get(i.dataId).values,d=e.data.get(a.dataId).values,h=o,p=r,m=l,f=c,{selectedIndices:g,selectedScores:w}=$N(u,d,h,p,m,f);return[e.makeTensorInfo([g.length],"int32",new Int32Array(g)),e.makeTensorInfo([w.length],"float32",new Float32Array(w))]}const RN={kernelName:tf,backendName:"cpu",kernelFunc:MN};function EN(s){const{inputs:t,backend:e,attrs:n}=s,{indices:i}=t,{dtype:a,depth:o,onValue:r,offValue:l}=n;Q(i,"oneHot");const c=st(i.shape),u=new Float32Array(c*o);u.fill(l);const d=e.data.get(i.dataId).values;for(let h=0;h<c;++h)d[h]>=0&&d[h]<o&&(u[h*o+d[h]]=r);return e.makeTensorInfo([...i.shape,o],a,u)}const LN={kernelName:xc,backendName:"cpu",kernelFunc:EN};function ni(s){const{inputs:t,backend:e}=s,{x:n}=t;if(n.dtype==="string")throw new Error("zerosLike is not supported for string tensors");if(n.dtype==="complex64"){const i=fn({inputs:{input:n},backend:e}),a=ni({inputs:{x:i},backend:e}),o=Vs({inputs:{input:n},backend:e}),r=ni({inputs:{x:o},backend:e}),l=Ne({inputs:{real:a,imag:r},backend:e});return e.disposeIntermediateTensorInfo(i),e.disposeIntermediateTensorInfo(a),e.disposeIntermediateTensorInfo(o),e.disposeIntermediateTensorInfo(r),l}else return Kr({backend:e,attrs:{shape:n.shape,value:0,dtype:n.dtype}})}const ON={kernelName:Pc,backendName:"cpu",kernelFunc:ni};function yd(s){const{inputs:t,backend:e}=s,{x:n}=t;if(n.dtype==="string")throw new Error("onesLike is not supported for string tensors");if(n.dtype==="complex64"){const i=fn({inputs:{input:n},backend:e}),a=yd({inputs:{x:i},backend:e}),o=Vs({inputs:{input:n},backend:e}),r=ni({inputs:{x:o},backend:e}),l=Ne({inputs:{real:a,imag:r},backend:e});return e.disposeIntermediateTensorInfo(i),e.disposeIntermediateTensorInfo(a),e.disposeIntermediateTensorInfo(o),e.disposeIntermediateTensorInfo(r),l}else return Kr({backend:e,attrs:{shape:n.shape,value:1,dtype:n.dtype}})}const _N={kernelName:Sc,backendName:"cpu",kernelFunc:yd};function wd(s){const{inputs:t,backend:e,attrs:n}=s,{axis:i}=n;if(t.length===1)return si({inputs:{input:t[0]},backend:e,attrs:{dim:i}});const a=t[0].shape,o=t[0].dtype;t.forEach(u=>{ef(a,u.shape,"All tensors passed to stack must have matching shapes"),K(o===u.dtype,()=>"All tensors passed to stack must have matching dtypes")});const r=[],l=t.map(u=>{const d=si({inputs:{input:u},backend:e,attrs:{dim:i}});return r.push(d),d}),c=Bs({inputs:l,backend:e,attrs:{axis:i}});return r.forEach(u=>e.disposeIntermediateTensorInfo(u)),c}const WN={kernelName:vc,backendName:"cpu",kernelFunc:wd};function VN(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{paddings:a,constantValue:o}=n;Q(i,"pad");const r=a.map((b,k)=>b[0]+i.shape[k]+b[1]),l=a.map(b=>b[0]),c=e.data.get(i.dataId).values,u=st(i.shape),d=i.shape.length,h=ct(i.shape),p=st(r),m=r.length,f=ct(r),g=es(i.dtype,p);o!==0&&g.fill(o);for(let b=0;b<u;b++){const y=Xc(b,d,h).map((S,v)=>S+l[v]),I=rn(y,m,f);g[I]=c[b]}return{dataId:e.write(g,r,i.dtype),shape:r,dtype:i.dtype}}const kd={kernelName:Nc,backendName:"cpu",kernelFunc:VN};const BN=xs((s,t)=>Math.pow(s,t)),PN=js(Aa,BN),GN={kernelName:Aa,backendName:"cpu",kernelFunc:PN};function HN(s){const{inputs:t,backend:e,attrs:n}=s,{paramsNestedSplits:i,paramsDenseValues:a,indices:o}=t,{outputRaggedRank:r}=n,l=i.map(w=>e.data.get(w.dataId).values),c=i.map(w=>w.shape),u=e.data.get(a.dataId).values,d=e.data.get(o.dataId).values,[h,p,m]=bg(l,c,u,a.shape,a.dtype,d,o.shape),f=h.map(w=>e.makeTensorInfo([w.length],"int32",w)),g=e.makeTensorInfo(m,a.dtype,p);return f.concat([g])}const UN={kernelName:sf,backendName:"cpu",kernelFunc:HN};function jN(s){const{inputs:t,backend:e}=s,{starts:n,limits:i,deltas:a}=t,o=e.data.get(n.dataId).values,r=e.data.get(i.dataId).values,l=e.data.get(a.dataId).values,[c,u]=yg(o,n.shape,n.dtype,r,i.shape,l,a.shape),d=e.makeTensorInfo([c.length],"int32",c),h=e.makeTensorInfo([u.length],n.dtype,u);return[d,h]}const qN={kernelName:nf,backendName:"cpu",kernelFunc:jN};function KN(s){const{inputs:t,backend:e,attrs:n}=s,{shape:i,values:a,defaultValue:o,rowPartitionTensors:r}=t,{rowPartitionTypes:l}=n,c=e.data.get(i.dataId).values,u=e.data.get(a.dataId).values,d=e.data.get(o.dataId).values,h=r.map(g=>e.data.get(g.dataId).values),p=r.map(g=>g.shape),[m,f]=wg(c,i.shape,u,a.shape,a.dtype,d,o.shape,h,p,l);return e.makeTensorInfo(m,a.dtype,f)}const ZN={kernelName:af,backendName:"cpu",kernelFunc:KN};function JN(s){const{backend:t,attrs:e}=s,{start:n,stop:i,dtype:a,step:o}=e,r=kg(n,i,o,a);return t.makeTensorInfo([r.length],a,r)}const XN={kernelName:of,backendName:"cpu",kernelFunc:JN};const YN=wt(za,s=>1/s),QN={kernelName:za,backendName:"cpu",kernelFunc:YN};function tC(s){const{inputs:t,backend:e,attrs:n}=s,{images:i}=t,{alignCorners:a,halfPixelCenters:o,size:r}=n;Q(i,"resizeBilinear");const l=ct(i.shape),[c,u]=r,[d,h,p,m]=i.shape,f=e.data.get(i.dataId).values,g=new Float32Array(st([d,c,u,m])),w=[a&&c>1?h-1:h,a&&u>1?p-1:p],b=[a&&c>1?c-1:c,a&&u>1?u-1:u];let k=0;const y=w[0]/b[0],I=w[1]/b[1];for(let S=0;S<d;S++)for(let v=0;v<c;v++){let N;o?N=y*(v+.5)-.5:N=y*v;const C=Math.max(0,Math.floor(N)),D=N-C,E=Math.min(h-1,Math.ceil(N)),V=S*l[0]+C*l[1],M=S*l[0]+E*l[1];for(let L=0;L<u;L++){let F;o?F=I*(L+.5)-.5:F=I*L;const $=Math.max(0,Math.floor(F)),W=F-$,R=Math.min(p-1,Math.ceil(F)),_=V+$*l[2],G=M+$*l[2],P=V+R*l[2],U=M+R*l[2];for(let H=0;H<m;H++){const q=f[_+H],j=f[G+H],Z=f[P+H],Y=f[U+H],et=q+(Z-q)*W,tt=j+(Y-j)*W,at=et+(tt-et)*D;g[k++]=at}}}return e.makeTensorInfo([d,c,u,m],"float32",g)}const eC={kernelName:Ac,backendName:"cpu",kernelFunc:tC};function sC(s){const{inputs:t,backend:e,attrs:n}=s,{images:i,dy:a}=t,{alignCorners:o}=n;Q([a,i],"resizeBilinearGrad");const r=ct(i.shape),[l,c,u,d]=i.shape,[,h,p]=a.shape,m=new Float32Array(l*c*u*d),f=[o&&h>1?c-1:c,o&&p>1?u-1:u],g=[o&&h>1?h-1:h,o&&p>1?p-1:p],w=f[0]/g[0],b=f[1]/g[1],k=e.data.get(a.dataId).values;let y=0;for(let I=0;I<l;I++){const S=I*r[0];for(let v=0;v<h;v++){const N=v*w,C=Math.floor(N),D=Math.min(Math.ceil(N),c-1),E=S+C*r[1],V=S+D*r[1],M=N-C,L=1-M;for(let F=0;F<p;F++){const $=F*b,W=Math.floor($),R=Math.min(Math.ceil($),u-1),_=$-W,G=1-_,P=E+W*r[2],U=E+R*r[2],H=V+W*r[2],q=V+R*r[2],j=L*G,Z=L*_,Y=M*G,et=M*_;for(let tt=0;tt<d;tt++){const at=k[y++];m[P+tt]+=at*j,m[U+tt]+=at*Z,m[H+tt]+=at*Y,m[q+tt]+=at*et}}}}return e.makeTensorInfo([l,u,c,d],"float32",m)}const nC={kernelName:Dc,backendName:"cpu",kernelFunc:sC};function iC(s){const{inputs:t,backend:e,attrs:n}=s,{images:i}=t,{alignCorners:a,halfPixelCenters:o,size:r}=n;Q(i,"resizeNearestNeighbor");const l=ct(i.shape),[c,u]=r,[d,h,p,m]=i.shape,f=e.data.get(i.dataId).values,g=new Float32Array(d*c*u*m),w=[a&&c>1?h-1:h,a&&u>1?p-1:p],b=[a&&c>1?c-1:c,a&&u>1?u-1:u],k=w[0]/b[0],y=w[1]/b[1];let I=0;for(let S=0;S<d;S++){const v=S*l[0];for(let N=0;N<c;N++){const C=o?k*(N+.5):k*N;let D=Math.min(h-1,a?Math.round(C):Math.floor(C));o&&(D=Math.max(0,D));const E=v+D*l[1];for(let V=0;V<u;V++){const M=o?y*(V+.5):y*V;let L=Math.min(p-1,a?Math.round(M):Math.floor(M));o&&(L=Math.max(0,L));const F=E+L*l[2];for(let $=0;$<m;$++){const W=f[F+$];g[I++]=W}}}}return e.makeTensorInfo([d,c,u,m],i.dtype,g)}const aC={kernelName:zc,backendName:"cpu",kernelFunc:iC};function oC(s){const{inputs:t,backend:e,attrs:n}=s,{images:i,dy:a}=t,{alignCorners:o}=n;Q([a,i],"resizeNearestNeighborGrad");const r=ct(i.shape),l=ct(a.shape),[c,u,d,h]=i.shape,[,p,m]=a.shape,f=new Float32Array(c*u*d*h),g=e.data.get(a.dataId).values,w=[o&&p>1?u-1:u,o&&m>1?d-1:d],b=[o&&p>1?p-1:p,o&&m>1?m-1:m],k=w[0]/b[0],y=w[1]/b[1],I=1/k,S=1/y,v=Math.ceil(I)*2+2,N=Math.ceil(S)*2+2;for(let C=0;C<c;C++){const D=C*r[0];for(let E=0;E<u;E++){const V=D+E*r[1],M=Math.floor(E*I),L=Math.floor(M-v/2);for(let F=0;F<d;F++){const $=V+F*r[2],W=Math.floor(F*S),R=Math.floor(W-N/2);for(let _=0;_<h;_++){let G=0;for(let P=0;P<v;P++){const U=P+L;if(U<0||U>=p)continue;const H=D+U*l[1],q=U*k,j=Math.min(u-1,o?Math.round(q):Math.floor(q));if(E===j)for(let Z=0;Z<N;Z++){const Y=Z+R;if(Y<0||Y>=m)continue;const et=H+Y*l[2],tt=Y*y,at=Math.min(d-1,o?Math.round(tt):Math.floor(tt));F===at&&(G+=g[et+_])}}f[$+_]=G}}}}return e.makeTensorInfo(i.shape,i.dtype,f)}const rC={kernelName:Fc,backendName:"cpu",kernelFunc:oC};function lC(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{dims:a}=n;Q(i,"reverse");const o=i.shape.length,r=Lt(a,i.shape);if(o===0)return Ss({inputs:{x:i},backend:e});const l=new Zt(i.shape,i.dtype),c=e.bufferSync(i);for(let u=0;u<l.size;u++){const d=l.indexToLoc(u),h=d.slice();r.forEach(p=>h[p]=i.shape[p]-1-h[p]),l.set(c.get(...h),...d)}return e.makeTensorInfo(l.shape,l.dtype,l.values)}const cC={kernelName:$c,backendName:"cpu",kernelFunc:lC};const uC={kernelName:rf,backendName:"cpu",kernelFunc:({inputs:s,attrs:t,backend:e})=>{const{image:n}=s,{radians:i,fillValue:a,center:o}=t,r=e,l=es(n.dtype,st(n.shape)),[c,u,d,h]=n.shape,[p,m]=Ig(o,u,d),f=255,g=Math.sin(i),w=Math.cos(i),b=r.data.get(n.dataId).values;for(let y=0;y<c;y++){const I=y*d*u*h;for(let S=0;S<u;S++){const v=S*(d*h);for(let N=0;N<d;N++){const C=N*h;for(let D=0;D<h;D++){const E=[c,S,N,D],V=E[2],M=E[1];let L=(V-p)*w-(M-m)*g,F=(V-p)*g+(M-m)*w;L=Math.round(L+p),F=Math.round(F+m);let $=a;if(typeof a!="number"&&(D===3?$=f:$=a[D]),L>=0&&L<d&&F>=0&&F<u){const R=F*(d*h),_=L*h,G=I+R+_+D;$=b[G]}const W=I+v+C+D;l[W]=$}}}}return{dataId:r.write(l,n.shape,n.dtype),shape:n.shape,dtype:n.dtype}}};const hC=wt(Ma,s=>{const t=Math.floor(s);return s-t<.5?Math.floor(s):s-t>.5?Math.ceil(s):t%2===0?t:t+1}),dC={kernelName:Ma,backendName:"cpu",kernelFunc:hC};function pC(s){const{inputs:t,backend:e,attrs:n}=s,{indices:i,updates:a}=t,{shape:o}=n,{sliceRank:r,numUpdates:l,sliceSize:c,strides:u,outputSize:d}=Ja(a,i,o),h=!0,p=e.bufferSync(i),m=e.bufferSync(a),f=Ds(p,m,o,d,c,l,r,u,0,h);return e.makeTensorInfo(o,f.dtype,f.values)}const fC={kernelName:lf,backendName:"cpu",kernelFunc:pC};function mC(s,t){let e=0,n=s.length,i=0;for(;e<n;)i=Math.floor((e+n)/2),s[i]<t?e=i+1:n=i;return n}function gC(s,t){let e=0,n=s.length,i=0;for(;e<n;)i=Math.floor((e+n)/2),s[i]<=t?e=i+1:n=i;return n}function bC(s,t,e,n,i,a){const o=Ka("int32",e*i);for(let r=0;r<e;++r){const l=s.slice(r*n,(r+1)*n),c=r*i;for(let u=0;u<i;++u)o[c+u]=a==="left"?mC(l,t[u+c]):gC(l,t[u+c])}return o}function yC(s){const{inputs:t,backend:e,attrs:n}=s,{sortedSequence:i,values:a}=t,{side:o}=n,r=e.data.get(i.dataId).values,l=e.data.get(a.dataId).values,c=bC(r,l,i.shape[0],i.shape[1],a.shape[1],o);return e.makeTensorInfo(a.shape,"int32",c)}const wC={kernelName:cf,backendName:"cpu",kernelFunc:yC};function kC(s){const{inputs:t,backend:e}=s,{condition:n,t:i,e:a}=t;Q([n,i,a],"select");const o=n.shape.length,r=e.data.get(n.dataId).values,l=e.data.get(i.dataId).values,c=e.data.get(a.dataId).values,u=ui(i.dtype,a.dtype),d=rs(st(i.shape),u);let h=0;const p=o===0||o>1||i.shape.length===1?1:st(i.shape.slice(1));for(let m=0;m<r.length;m++)for(let f=0;f<p;f++)r[m]===1?d[h++]=l[m]:d[h++]=c[m];return e.makeTensorInfo(i.shape,u,d)}const IC={kernelName:Mc,backendName:"cpu",kernelFunc:kC};const xC=vu,SC=Nu,vC=wt(Ra,s=>s>=0?SC*s:xC*(Math.exp(s)-1)),NC={kernelName:Ra,backendName:"cpu",kernelFunc:vC};const CC=wt(Ea,s=>s<0?-1:s>0?1:0),TC={kernelName:Ea,backendName:"cpu",kernelFunc:CC};const AC=wt(La,s=>Math.sin(s)),DC={kernelName:La,backendName:"cpu",kernelFunc:AC};const zC=wt(Oa,s=>Math.sinh(s)),FC={kernelName:Oa,backendName:"cpu",kernelFunc:zC};const $C=11920928955078125e-23,Ll=Math.log($C)+2,MC=wt(_a,s=>{const t=s>-Ll,e=s<Ll,n=Math.exp(s);let i;return e?i=n:t?i=s:i=Math.log(1+n),i}),RC={kernelName:_a,backendName:"cpu",kernelFunc:MC};function EC(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{blockShape:a,paddings:o}=n;Q([i],"spaceToBatchND");const r=st(a),l=[[0,0]];l.push(...o);for(let S=1+a.length;S<i.shape.length;++S)l.push([0,0]);const c=kd.kernelFunc({inputs:{x:i},backend:e,attrs:{paddings:l,constantValue:0}}),u=Cu(c.shape,a,r,!1),d=Tu(u.length,a.length,!1),h=Au(c.shape,a,r,!1),f=xt({inputs:{x:c},backend:e,attrs:{shape:u}}),b=ee({inputs:{x:f},backend:e,attrs:{perm:d}}),I=xt({inputs:{x:b},backend:e,attrs:{shape:h}});return e.disposeIntermediateTensorInfo(c),e.disposeIntermediateTensorInfo(f),e.disposeIntermediateTensorInfo(b),I}const LC={kernelName:Ec,backendName:"cpu",kernelFunc:EC};function OC(s){const{inputs:t,backend:e}=s,{indices:n,values:i,denseShape:a,defaultValue:o}=t;if(a.shape.length!==1)throw new Error(`Dense shape must be a vector, saw:
        ${a.shape}`);if(n.shape.length!==2)throw new Error(`Indices must be a matrix, saw:
        ${n.shape}`);if(i.shape.length!==1)throw new Error(`Values must be a vector, saw:
        ${i.shape}`);if(o.shape.length!==0)throw new Error(`Default value must be a scalar, saw:
        ${o.shape}`);const r=e.data.get(n.dataId).values,l=e.data.get(i.dataId).values,c=e.data.get(a.dataId).values,u=e.data.get(o.dataId).values[0],[d,h,p,m,f]=xg(r,n.shape,n.dtype,l,i.dtype,c,u);return[e.makeTensorInfo(h,n.dtype,d),e.makeTensorInfo([h[0]],i.dtype,p),e.makeTensorInfo([m.length],"bool",new Uint8Array(m.map(g=>Number(g)))),e.makeTensorInfo([f.length],n.dtype,new Int32Array(f))]}const _C={kernelName:uf,backendName:"cpu",kernelFunc:OC};function WC(s){const{inputs:t,backend:e}=s,{inputIndices:n,inputShape:i,newShape:a}=t;if(n.shape.length!==2)throw new Error(`Input indices should be a matrix but received shape
        ${n.shape}`);if(i.shape.length!==1)throw new Error(`Input shape should be a vector but received shape
        ${i.shape}`);if(a.shape.length!==1)throw new Error(`Target shape should be a vector but received shape ${a.shape}`);const o=Array.from(e.data.get(i.dataId).values),r=e.data.get(n.dataId).values,l=Array.from(e.data.get(a.dataId).values),[c,u,d]=Sg(r,n.shape,n.dtype,o,l);return[e.makeTensorInfo(u,n.dtype,c),e.makeTensorInfo([d.length],a.dtype,new Int32Array(d))]}const VC={kernelName:hf,backendName:"cpu",kernelFunc:WC};function BC(s){const{inputs:t,backend:e}=s,{data:n,indices:i,segmentIds:a}=t;if(n.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(i.shape.length!==1)throw new Error(`Indices should be a vector but received shape
          ${i.shape}`);if(a.shape.length!==1)throw new Error(`Segment ids should be a vector but received shape
          ${a.shape}`);if(i.shape[0]!==a.shape[0])throw new Error("segmentIds and indices should have same size.");const o=e.data.get(n.dataId).values,r=e.data.get(i.dataId).values,l=e.data.get(a.dataId).values,[c,u]=$u(o,n.shape,n.dtype,r,l,!0);return e.makeTensorInfo(u,n.dtype,c)}const PC={kernelName:df,backendName:"cpu",kernelFunc:BC};function GC(s){const{inputs:t,backend:e}=s,{data:n,indices:i,segmentIds:a}=t;if(n.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(i.shape.length!==1)throw new Error(`Indices should be a vector but received shape
         ${i.shape}`);if(a.shape.length!==1)throw new Error(`Segment ids should be a vector but received shape
         ${a.shape}`);if(i.shape[0]!==a.shape[0])throw new Error("segmentIds and indices should have same size.");const o=e.data.get(n.dataId).values,r=e.data.get(i.dataId).values,l=e.data.get(a.dataId).values,[c,u]=$u(o,n.shape,n.dtype,r,l);return e.makeTensorInfo(u,n.dtype,c)}const HC={kernelName:pf,backendName:"cpu",kernelFunc:GC};function UC(s){const{inputs:t,backend:e,attrs:n}=s,{sparseIndices:i,sparseValues:a,defaultValue:o}=t,{outputShape:r}=n,{sliceRank:l,numUpdates:c,sliceSize:u,strides:d,outputSize:h}=Ja(a,i,r),p=!1,m=e.bufferSync(i);let f;switch(a.dtype){case"bool":{const g=e.bufferSync(a),w=!!e.data.get(o.dataId).values[0];f=Ds(m,g,r,h,u,c,l,d,w,p);break}case"float32":{const g=e.bufferSync(a),w=e.data.get(o.dataId).values[0];f=Ds(m,g,r,h,u,c,l,d,w,p);break}case"int32":{const g=e.bufferSync(a),w=e.data.get(o.dataId).values[0];f=Ds(m,g,r,h,u,c,l,d,w,p);break}case"string":{const g=e.bufferSync(a),w=Uc(e.data.get(o.dataId).values[0]);f=Ds(m,g,r,h,u,c,l,d,w,p);break}default:throw new Error(`Unsupported type ${a.dtype}`)}return e.makeTensorInfo(r,f.dtype,f.values)}const jC={kernelName:ff,backendName:"cpu",kernelFunc:UC};function qC(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{numOrSizeSplits:a,axis:o}=n,r=Lt(o,i.shape)[0],l=vg(i,a,r),c=new Array(i.shape.length).fill(0),u=i.shape.slice();return l.map(d=>{const h=[...u];h[r]=d;const p=Es({inputs:{x:i},backend:e,attrs:{begin:c,size:h}});return c[r]+=d,p})}const KC={kernelName:Lc,backendName:"cpu",kernelFunc:qC};const ZC={kernelName:Oc,backendName:"cpu",kernelFunc:({inputs:s,backend:t})=>{const{x:e}=s,n=t;Q(e,"square");const i=n.data.get(e.dataId).values,a=new Float32Array(i.length);for(let r=0;r<i.length;++r){const l=i[r];a[r]=l*l}return{dataId:n.write(a,e.shape,e.dtype),shape:e.shape,dtype:e.dtype}}};const JC=wt(Wa,(s,t)=>{const e=t;return isNaN(s)?NaN:s>0?1:e.alpha}),XC={kernelName:Wa,backendName:"cpu",kernelFunc:JC};function YC(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{begin:a,end:o,strides:r,beginMask:l,endMask:c,ellipsisMask:u,newAxisMask:d,shrinkAxisMask:h}=n;Q(i,"stridedSlice");const{finalShapeSparse:p,finalShape:m,isIdentity:f,sliceDim0:g,isSimpleSlice:w,begin:b,end:k,strides:y}=Ng(i.shape,a,o,r,l,c,u,d,h);let I;if(f)I=xt({inputs:{x:i},backend:e,attrs:{shape:m}});else if(g||w){K(i.shape.length>=1,()=>`Input must have rank at least 1, got: ${i.shape.length}`);const S=Cg(b,k,y),v=Es({inputs:{x:i},backend:e,attrs:{begin:b,size:S}});I=xt({inputs:{x:v},backend:e,attrs:{shape:m}}),e.disposeIntermediateTensorInfo(v)}else{const S=e.bufferSync(i),v=Tg(p,S,y,b);I=e.makeTensorInfo(m,v.dtype,v.values)}return I}const QC={kernelName:mf,backendName:"cpu",kernelFunc:YC};function tT(s){const{inputs:t,backend:e,attrs:n}=s,{separator:i,nGramWidths:a,leftPad:o,rightPad:r,padWidth:l,preserveShortSequences:c}=n,{data:u,dataSplits:d}=t,h=e.data.get(u.dataId).values,p=e.data.get(d.dataId).values,[m,f]=Ag(h,p,i,a,o,r,l,c);return[e.makeTensorInfo([m.length],"string",m),e.makeTensorInfo(d.shape,"int32",f)]}const eT={kernelName:gf,backendName:"cpu",kernelFunc:tT};function sT(s){const{inputs:t,backend:e,attrs:n}=s,{skipEmpty:i}=n,{input:a,delimiter:o}=t;if(a.dtype!=="string")throw new Error("Input must be of datatype string");if(a.shape.length!==1)throw new Error(`Input must be a vector, got shape: ${a.shape}`);if(o.shape.length!==0)throw new Error(`Delimiter must be a scalar, got shape: ${o.shape}`);const r=e.data.get(a.dataId).values,l=e.data.get(o.dataId).values[0],[c,u,d]=Dg(r,l,i),h=u.length;return[e.makeTensorInfo([h,2],"int32",c),e.makeTensorInfo([h],"string",u),e.makeTensorInfo([2],"int32",new Int32Array(d))]}const nT={kernelName:bf,backendName:"cpu",kernelFunc:sT};function iT(s){const{inputs:t,backend:e,attrs:n}=s,{numBuckets:i}=n,{input:a}=t;if(a.dtype!=="string")throw new Error("Input must be of datatype string");if(i<=0)throw new Error("Number of buckets must be at least 1");const o=e.data.get(a.dataId).values,r=zg(o,i);return e.makeTensorInfo(a.shape,"int32",r)}const aT={kernelName:yf,backendName:"cpu",kernelFunc:iT};const oT=wt(Va,s=>Math.tan(s)),rT={kernelName:Va,backendName:"cpu",kernelFunc:oT};const lT=wt(Ba,s=>Math.tanh(s)),cT={kernelName:Ba,backendName:"cpu",kernelFunc:lT};function uT(s){const{inputs:t,backend:e}=s,{tensor:n,indices:i,updates:a}=t,{sliceRank:o,numUpdates:r,sliceSize:l,strides:c,outputSize:u}=Ja(a,i,n.shape),d=!1,h=e.bufferSync(i),p=e.bufferSync(a),m=e.bufferSync(n),f=Ds(h,p,n.shape,u,l,r,o,c,m,d);return e.makeTensorInfo(n.shape,f.dtype,f.values)}const hT={kernelName:wf,backendName:"cpu",kernelFunc:uT};function dT(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{reps:a}=n;Q(i,"tile");const o=Fg(e.bufferSync(i),a);return e.makeTensorInfo(o.shape,o.dtype,o.values)}const pT={kernelName:Wc,backendName:"cpu",kernelFunc:dT};function fT(s){const{inputs:t,backend:e,attrs:n}=s,{x:i}=t,{k:a,sorted:o}=n;Q(i,"topk");const r=e.data.get(i.dataId).values,[l,c]=$g(r,i.shape,i.dtype,a,o);return[e.makeTensorInfo(l.shape,l.dtype,l.values),e.makeTensorInfo(c.shape,c.dtype,c.values)]}const mT={kernelName:kf,backendName:"cpu",kernelFunc:fT};function gT(s){const{inputs:t,attrs:e,backend:n}=s,{image:i,transforms:a}=t,{interpolation:o,fillMode:r,fillValue:l,outputShape:c}=e,[u,d,h,p]=i.shape,[m,f]=c??[d,h],g=[u,m,f,p],w=ct(i.shape),b=w[0],k=w[1],y=w[2],I=ct(g),S=I[0],v=I[1],N=I[2],C=es(i.dtype,st(g));C.fill(l);const D=n.data.get(i.dataId).values,E=n.data.get(a.dataId).values;for(let M=0;M<u;++M){const L=a.shape[0]===1?E:E.subarray(M*8,M*8+8);for(let F=0;F<m;++F)for(let $=0;$<f;++$)for(let W=0;W<p;++W){let R;const _=L[6]*$+L[7]*F+1;if(_===0)continue;const G=(L[0]*$+L[1]*F+L[2])/_,P=(L[3]*$+L[4]*F+L[5])/_,U=Ol(G,h,r),H=Ol(P,d,r);switch(o){case"nearest":R=xT(D,d,h,b,k,y,M,H,U,W,l);break;case"bilinear":R=ST(D,d,h,b,k,y,M,H,U,W,l);break;default:throw new Error(`Error in Transform: Expect 'nearest' or 'bilinear', but got ${o}`)}const q=M*S+F*v+$*N+W;C[q]=R}return n.makeTensorInfo(g,i.dtype,C)}return{dataId:n.write(C,g,i.dtype),shape:i.shape,dtype:i.dtype}}const bT={kernelName:If,backendName:"cpu",kernelFunc:gT};function Ol(s,t,e){switch(e){case"reflect":return yT(s,t);case"wrap":return wT(s,t);case"nearest":return IT(s,t);default:return kT(s)}}function yT(s,t){let e=s;if(e<0)if(t<=1)e=0;else{const n=2*t;e<n&&(e=n*Math.trunc(-e/n)+e),e=e<-t?e+n:-e-1}else if(e>t-1)if(t<=1)e=0;else{const n=2*t;e-=n*Math.trunc(e/n),e>=t&&(e=n-e-1)}return Xa(0,e,t-1)}function wT(s,t){let e=s;if(e<0)if(t<=1)e=0;else{const n=t-1;e+=t*(Math.trunc(-e/n)+1)}else if(e>t-1)if(t<=1)e=0;else{const n=t-1;e-=t*Math.trunc(e/n)}return Xa(0,e,t-1)}function kT(s,t){return s}function IT(s,t){return Xa(0,s,t-1)}function on(s,t,e,n,i,a,o,r,l,c,u){const d=o*n+r*i+l*a+c;return 0<=r&&r<t&&0<=l&&l<e?s[d]:u}function xT(s,t,e,n,i,a,o,r,l,c,u){const d=Math.round(r),h=Math.round(l);return on(s,t,e,n,i,a,o,d,h,c,u)}function ST(s,t,e,n,i,a,o,r,l,c,u){const d=Math.floor(r),h=Math.floor(l),p=d+1,m=h+1,f=(m-l)*on(s,t,e,n,i,a,o,d,h,c,u)+(l-h)*on(s,t,e,n,i,a,o,d,m,c,u),g=(m-l)*on(s,t,e,n,i,a,o,p,h,c,u)+(l-h)*on(s,t,e,n,i,a,o,p,m,c,u);return(p-r)*f+(r-d)*g}function vT(s){const{inputs:t,attrs:e,backend:n}=s,{axis:i}=e,{x:a}=t;Q(a,"unique");const o=n.data.get(a.dataId).values,{outputValues:r,outputShape:l,indices:c}=Mg(o,i,a.shape,a.dtype);return[n.makeTensorInfo(l,a.dtype,r),n.makeTensorInfo([c.length],"int32",c)]}const NT={kernelName:xf,backendName:"cpu",kernelFunc:vT};function CT(s){const{inputs:t,backend:e,attrs:n}=s,{value:i}=t;let{axis:a}=n;a<0&&(a+=i.shape.length);const o=i.shape.length,r=i.shape[a],l=new Array(o-1);let c=0;for(let p=0;p<o;p++)p!==a&&(l[c++]=i.shape[p]);const u=new Array(o).fill(0),d=i.shape.slice();d[a]=1;const h=new Array(r);for(let p=0;p<h.length;p++){u[a]=p;const m=Es({inputs:{x:i},backend:e,attrs:{begin:u,size:d}});h[p]=xt({inputs:{x:m},backend:e,attrs:{shape:l}}),e.disposeIntermediateTensorInfo(m)}return h}const TT={kernelName:Vc,backendName:"cpu",kernelFunc:CT};function AT(s){const{inputs:t,backend:e,attrs:n}=s,{x:i,segmentIds:a}=t,{numSegments:o}=n;Q(i,"unsortedSegmentSum");const r=i.shape.length,l=a.shape.length,c=[],u=[],d=r-l;let h=a;for(let m=0;m<d;++m){const f=si({inputs:{input:h},backend:e,attrs:{dim:m+1}});h=f,u.push(f)}for(let m=0;m<o;++m){const f=qc(m,"int32"),g=e.makeTensorInfo([],"int32",f),w=Rg({inputs:{a:g,b:h},backend:e}),b=ro({inputs:{x:w},backend:e,attrs:{dtype:"float32"}}),k=lo({inputs:{a:b,b:i},backend:e}),y=$n({inputs:{x:k},backend:e,attrs:{axis:0,keepDims:!1}});c.push(y),u.push(g),u.push(w),u.push(b),u.push(k),u.push(y)}const p=wd({inputs:c,backend:e,attrs:{axis:0}});return u.forEach(m=>e.disposeIntermediateTensorInfo(m)),p}const DT={kernelName:Bc,backendName:"cpu",kernelFunc:AT};const zT=[vS,Eg,CS,AS,Lg,zS,$S,RS,LS,_S,VS,PS,HS,qS,ZS,YS,t1,s1,i1,xS,o1,l1,u1,Og,d1,_g,Wg,f1,Vg,g1,y1,w1,I1,S1,N1,T1,D1,F1,M1,E1,O1,W1,B1,G1,H1,j1,K1,J1,X1,Y1,Q1,ev,iv,mS,ov,Bg,fv,Pg,mv,Gg,Iv,xv,vv,Hg,Ug,Cv,Av,zv,$v,jg,qg,Kg,Rv,b1,Lv,_v,Vv,gS,Zg,Jg,Pv,Xg,Hv,qv,Zv,Yv,tN,sN,nN,Yg,aN,rN,cN,hN,pN,mN,bN,Qg,wN,xN,NN,tb,eb,AN,FN,RN,sb,LN,_N,WN,kd,GN,yS,nb,UN,qN,ZN,XN,ib,la,QN,wS,kS,IS,eC,nC,aC,rC,cC,uC,dC,ab,fC,wC,IC,NC,ob,TC,DC,FC,rb,SN,RC,LC,_C,VC,PC,HC,jC,KC,lb,ZC,cb,ub,XC,QC,eT,nT,aT,hb,sv,rT,cT,hT,pT,mT,bT,db,NT,TT,DT,ON];for(const s of zT)Sf(s);const FT="4.22.0";const nA={"tfjs-core":Nb,"tfjs-backend-cpu":fS,"tfjs-backend-webgl":pb,"tfjs-data":id,"tfjs-layers":Ro,"tfjs-converter":z0,tfjs:FT};export{Fd as Abs,ua as Acos,ha as Acosh,Ad as AdadeltaOptimizer,zd as AdagradOptimizer,Td as AdamOptimizer,Dd as AdamaxOptimizer,$d as Add,Gl as AddN,vp as All,Np as Any,Hl as ArgMax,Ul as ArgMin,da as Asin,pa as Asinh,ma as Atan,fa as Atan2,ga as Atanh,Zl as AvgPool,ql as AvgPool3D,jl as AvgPool3DGrad,Kl as AvgPoolGrad,Jl as BatchMatMul,Xl as BatchToSpaceND,Cp as Bincount,oA as BitwiseAnd,Tp as BroadcastArgs,Md as BroadcastTo,T0 as Callback,Ek as CallbackList,Rd as Cast,Ed as Ceil,ba as ClipByValue,rA as Complex,Yl as ComplexAbs,Ql as Concat,tc as Conv2D,Dp as Conv2DBackpropFilter,ec as Conv2DBackpropInput,nc as Conv3D,sc as Conv3DBackpropFilterV2,zp as Conv3DBackpropInputV2,wa as Cos,ka as Cosh,Fp as CropAndResize,$p as Cumprod,ic as Cumsum,_k as CustomCallback,yp as DataStorage,Rp as DenseBincount,Ep as DepthToSpace,ac as DepthwiseConv2dNative,Lp as DepthwiseConv2dNativeBackpropFilter,Op as DepthwiseConv2dNativeBackpropInput,_p as Diag,oc as Dilation2D,Ki as Dilation2DBackpropFilter,Zi as Dilation2DBackpropInput,Wp as Draw,lA as ENV,A0 as EarlyStopping,Vp as Einsum,Ia as Elu,rc as EluGrad,cA as Environment,uA as Equal,xa as Erf,Ld as Exp,lc as ExpandDims,Od as Expm1,Bp as FFT,Pp as Fill,Hp as FlipLeftRight,_d as Floor,Wd as FloorDiv,hA as FromPixels,cc as FusedBatchNorm,Up as FusedConv2D,jp as FusedDepthwiseConv2D,yz as GPGPUContext,qp as GatherNd,uc as GatherV2,lD as GraphModel,dA as Greater,Vd as GreaterEqual,Ok as History,Kp as IFFT,Bd as Identity,Ap as Imag,Mt as InputSpec,Sa as IsFinite,va as IsInf,Na as IsNan,bp as KernelBackend,pc as LRN,dc as LRNGrad,ek as LayerVariable,Qe as LayersModel,hc as LeakyRelu,pA as Less,fA as LessEqual,Zp as LinSpace,Pd as Log,Ca as Log1p,Gd as LogSoftmax,Kc as LogicalAnd,Zc as LogicalNot,Jc as LogicalOr,mA as LogicalXor,gA as LowerBound,Oi as MathBackendCPU,wz as MathBackendWebGL,bA as MatrixBandPart,fc as Max,yc as MaxPool,gc as MaxPool3D,mc as MaxPool3DGrad,bc as MaxPoolGrad,Jp as MaxPoolWithArgmax,Hd as Maximum,wc as Mean,kc as Min,Ud as Minimum,Ic as MirrorPad,Ta as Mod,Nd as MomentumOptimizer,Xp as Multinomial,jd as Multiply,qd as Neg,Yp as NonMaxSuppressionV3,Qp as NonMaxSuppressionV4,tf as NonMaxSuppressionV5,yA as NotEqual,wA as OP_SCOPE_SUFFIX,xc as OneHot,Sc as OnesLike,cp as Optimizer,Cb as OptimizerConstructors,vc as Pack,Nc as PadV2,kA as Pool,Aa as Pow,Cc as Prelu,Kd as Prod,Cd as RMSPropOptimizer,$e as RNN,sf as RaggedGather,nf as RaggedRange,af as RaggedTensorToTensor,of as Range,IA as Rank,xA as Real,Da as RealDiv,za as Reciprocal,cD as Reduction,$a as Relu,Fa as Relu6,Tc as Reshape,Ac as ResizeBilinear,Dc as ResizeBilinearGrad,zc as ResizeNearestNeighbor,Fc as ResizeNearestNeighborGrad,$c as Reverse,rf as RotateWithOffset,Ma as Round,Zd as Rsqrt,vd as SGDOptimizer,lf as ScatterNd,cf as SearchSorted,Mc as Select,Ra as Selu,_s as Sequential,Jd as Sigmoid,Ea as Sign,La as Sin,Oa as Sinh,Xd as Slice,Rc as Softmax,_a as Softplus,Ec as SpaceToBatchND,uf as SparseFillEmptyRows,hf as SparseReshape,df as SparseSegmentMean,pf as SparseSegmentSum,ff as SparseToDense,Lc as SplitV,Yd as Sqrt,Oc as Square,Qd as SquaredDifference,SA as StaticRegexReplace,Wa as Step,mf as StridedSlice,gf as StringNGrams,bf as StringSplit,yf as StringToHashBucketFast,tp as Sub,_c as Sum,ze as SymbolicTensor,Va as Tan,Ba as Tanh,re as Tensor,Zt as TensorBuffer,wf as TensorScatterUpdate,Wc as Tile,kf as TopK,If as Transform,ep as Transpose,xf as Unique,Vc as Unpack,Bc as UnsortedSegmentSum,vA as UpperBound,NA as Variable,Pc as ZerosLike,Sp as _FusedMatMul,fs as abs,Af as acos,Df as acosh,X as add,uD as addN,cu as all,Xi as any,hn as argMax,zf as argMin,Ff as asin,$f as asinh,Mf as atan,Rf as atan2,Ef as atanh,uu as avgPool,Rm as avgPool3d,op as backend,kz as backend_util,hD as basicLSTMCell,Lf as batchNorm,zm as batchNorm2d,Fm as batchNorm3d,$m as batchNorm4d,lu as batchToSpaceND,dD as bincount,pD as bitwiseAnd,fD as booleanMaskAsync,mD as broadcastArgs,np as broadcastTo,CA as broadcast_util,gD as browser,Bt as buffer,eA as callbacks,J as cast,Of as ceil,te as clipByValue,lp as clone,TA as complex,xn as concat,km as concat1d,wm as concat2d,ym as concat3d,bm as concat4d,BT as constraints,hu as conv1d,Pn as conv2d,du as conv2dTranspose,Dm as conv3d,Tm as conv3dTranspose,AA as copyRegisteredKernels,Qa as cos,ru as cosh,bD as cosineWindow,Ji as cumprod,su as cumsum,DA as customGrad,sA as data,sl as denseBincount,zA as deprecationWarn,_f as depthToSpace,pu as depthwiseConv2d,yD as deregisterOp,FA as device_util,wD as diag,Wf as dilation2d,$A as disableDeprecationWarnings,gt as dispose,MA as disposeVariables,ut as div,Vf as divNoNan,Bf as dot,Im as dropout,kD as einsum,Pa as elu,RA as enableDebugMode,EA as enableProdMode,ID as enclosingPowerOfTwo,tl as engine,xD as ensureShape,We as env,ge as equal,fu as erf,Pf as euclideanNorm,ks as exp,Ve as expandDims,Gf as expm1,xm as eye,Hf as fft,rp as fill,LA as findBackend,OA as findBackendFactory,Ya as floor,ip as floorDiv,Iz as forceHalfFloat,SD as fused,eo as gather,vD as gatherND,xz as gather_util,_A as getBackend,WA as getGradient,VA as getKernel,BA as getKernelsForBackend,Sz as gpgpu_util,PA as grad,GA as grads,ke as greater,Hs as greaterEqual,Uf as ifft,ND as imag,Ce as image,CD as inTopKAsync,PT as initializers,AI as input,TD as io,jf as irfft,qf as isFinite,Kf as isInf,Zf as isNaN,Oe as keep,VT as kernel_impls,XT as layers,Gc as leakyRelu,au as less,hi as lessEqual,Sm as linalg,AD as linspace,DD as loadGraphModel,zD as loadGraphModelSync,GT as loadLayersModel,Jf as localResponseNormalization,ss as log,bu as log1p,Xf as logSigmoid,mu as logSoftmax,gu as logSumExp,ws as logicalAnd,ou as logicalNot,Yf as logicalOr,Qf as logicalXor,FD as losses,$D as lowerBound,pe as matMul,WT as math,Rs as max,yu as maxPool,Mm as maxPool3d,MD as maxPoolWithArgmax,bs as maximum,Ot as mean,Yr as memory,RD as meshgrid,YT as metrics,wu as min,so as minimum,tm as mirrorPad,em as mod,HT as model,QT as models,oo as moments,ED as movingAverage,A as mul,LD as multiRNNCell,OD as multinomial,Ut as neg,_m as nextFrame,sm as norm,Gn as notEqual,Bn as oneHot,Is as ones,le as onesLike,gs as op,_D as outerProduct,to as pad,WD as pad1d,VD as pad2d,BD as pad3d,PD as pad4d,nm as pool,ri as pow,Hc as prelu,HA as print,im as prod,UA as profile,GD as raggedGather,HD as raggedRange,UD as raggedTensorToTensor,jD as rand,qD as randomGamma,gm as randomNormal,KD as randomStandardNormal,mi as randomUniform,ZD as randomUniformInt,Em as range,jA as ready,JD as real,am as reciprocal,Ip as registerBackend,jT as registerCallbackConstructor,sp as registerGradient,Sf as registerKernel,XD as registerOp,tA as regularizers,Ps as relu,ap as relu6,qA as removeBackend,B as reshape,un as reverse,YD as reverse1d,QD as reverse2d,tz as reverse3d,ez as reverse4d,lm as rfft,cm as round,nu as rsqrt,zt as scalar,sz as scatterND,KA as scatter_util,nz as searchSorted,ku as selu,Iu as separableConv2d,UT as sequential,ZA as serialization,JA as setBackend,XA as setPlatform,vz as setWebGLContext,iz as setdiff1dAsync,Nz as shared,li as sigmoid,um as sign,az as signal,tu as sin,eu as sinh,Le as slice,ao as slice1d,xu as slice2d,io as slice3d,Hn as slice4d,Cz as slice_util,no as softmax,di as softplus,Yc as spaceToBatchND,oz as sparse,rz as sparseToDense,lz as spectral,_e as split,Be as sqrt,Gt as square,hm as squaredDifference,pi as squeeze,Us as stack,ii as step,dm as stridedSlice,cz as string,pt as sub,lt as sum,YA as sumOutType,pm as tan,fi as tanh,Ga as tensor,dn as tensor1d,nl as tensor2d,uz as tensor3d,hz as tensor4d,dz as tensor5d,pz as tensor6d,fz as tensorScatterUpdate,QA as tensor_util,_T as test_util,T as tidy,hs as tile,tD as time,fm as topk,Ts as train,ht as transpose,Su as truncatedNormal,mm as unique,eD as unregisterGradient,sD as unregisterKernel,iu as unsortedSegmentSum,cn as unstack,ui as upcastType,mz as upperBound,nD as util,iD as valueAndGrad,aD as valueAndGrads,vm as variable,oD as variableGrads,nA as version,z0 as version_converter,Nb as version_core,fS as version_cpu,Ro as version_layers,pb as version_webgl,Tz as webgl,Az as webgl_util,De as where,gz as whereAsync,Qt as zeros,Dt as zerosLike};
